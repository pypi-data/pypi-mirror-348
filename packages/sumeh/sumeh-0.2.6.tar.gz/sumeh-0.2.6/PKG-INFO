Metadata-Version: 2.3
Name: sumeh
Version: 0.2.6
Summary: Quality Check and Config Management Tool
License: Apache-2.0
Author: Demetrius Albuquerque
Author-email: demetrius.albuquerque@yahoo.com.br
Requires-Python: >=3.10,<4.0
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Topic :: Software Development :: Libraries
Provides-Extra: aws
Provides-Extra: bigquery
Provides-Extra: dev
Provides-Extra: mysql
Provides-Extra: postgresql
Provides-Extra: pyspark
Requires-Dist: boto3 (>=1.38.17,<2.0.0) ; extra == "aws"
Requires-Dist: cuallee (>=0.15.2,<0.16.0)
Requires-Dist: google-cloud-bigquery (==3.32.0) ; extra == "bigquery"
Requires-Dist: mysql-connector-python (>=9.3.0,<10.0.0) ; extra == "mysql"
Requires-Dist: pandas (>=2.2.0,<3.0.0) ; extra == "aws" or extra == "mysql" or extra == "postgresql" or extra == "bigquery"
Requires-Dist: psycopg2-binary (>=2.9.1,<3.0.0) ; extra == "postgresql"
Requires-Dist: python-dateutil (>=2.8.0,<3.0.0)
Project-URL: Homepage, https://github.com/maltzsama/sumeh
Project-URL: Repository, https://github.com/maltzsama/sumeh
Description-Content-Type: text/markdown

![Python](https://img.shields.io/badge/python-3.10%2B-blue.svg)
![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)

# <h1 style="display: flex; align-items: center; gap: 0.5rem;"><img src="https://raw.githubusercontent.com/maltzsama/sumeh/refs/heads/main/docs/img/sumeh.svg" alt="Logo" style="height: 40px; width: auto; vertical-align: middle;" /> <span>Sumeh DQ</span> </h1>

Sumeh is a unified data quality validation framework supporting multiple backends (PySpark, Dask, Polars, DuckDB) with centralized rule configuration.

## ğŸš€ Installation

```bash
# Using pip
pip install sumeh

# Or with conda-forge
conda install -c conda-forge sumeh
```

**Prerequisites:**  
- Python 3.10+  
- One or more of: `pyspark`, `dask[dataframe]`, `polars`, `duckdb`, `cuallee`

## ğŸ” Core API

- **`report(df, rules, name="Quality Check")`**  
  Apply your validation rules over any DataFrame (Pandas, Spark, Dask, Polars, or DuckDB).  
- **`validate(df, rules)`** *(per-engine)*  
  Returns a DataFrame with a `dq_status` column listing violations.  
- **`summarize(qc_df, rules, total_rows)`** *(per-engine)*  
  Consolidates violations into a summary report.

## âš™ï¸ Supported Engines

Each engine implements the `validate()` + `summarize()` pair:

| Engine                | Module                                  | Status          |
|-----------------------|-----------------------------------------|-----------------|
| PySpark               | `sumeh.engine.pyspark_engine`           | âœ… Fully implemented |
| Dask                  | `sumeh.engine.dask_engine`              | âœ… Fully implemented |
| Polars                | `sumeh.engine.polars_engine`            | âœ… Fully implemented |
| DuckDB                | `sumeh.engine.duckdb_engine`            | âœ… Fully implemented |
| Pandas                | `sumeh.engine.pandas_engine`            | ğŸ”§ Stub implementation |
| BigQuery (SQL)        | `sumeh.engine.bigquery_engine`          | ğŸ”§ Stub implementation |

## ğŸ— Configuration Sources

Load rules from CSV, S3, MySQL, Postgres, BigQuery table, or AWS Glue:

```python
from sumeh.services.config import (
    get_config_from_csv,
    get_config_from_s3,
    get_config_from_mysql,
    get_config_from_postgresql,
    get_config_from_bigquery,
    get_config_from_glue_data_catalog,
)

rules = get_config_from_csv("rules.csv", delimiter=";")
```

## ğŸƒâ€â™‚ï¸ Typical Workflow

```python
from sumeh import report
from sumeh.engine.polars_engine import validate, summarize
import polars as pl

# 1) Load data
df = pl.read_csv("data.csv")

# 2) Run validation
qc_df = validate(df, rules)

# 3) Generate summary
total = df.height
report = summarize(qc_df, rules, total)
print(report)
```

Or simply:

```python
from sumeh import report

report = report(df, rules, name="My Check")
```

## ğŸ“‹ Rule Definition Example

```json
{
  "field": "customer_id",
  "check_type": "is_complete",
  "threshold": 0.99,
  "value": null,
  "execute": true
}
```

**Supported Validation Rules**

The following data quality checks are available:

| Test                             | Description                                                                                                         |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------- |
| **is\_complete**                 | Filters rows where the specified column is null.                                                                    |
| **are\_complete**                | Filters rows where any of the specified columns is null.                                                            |
| **is\_unique**                   | Identifies rows with duplicate values in the specified column.                                                      |
| **are\_unique**                  | Identifies rows with duplicate combinations of the specified columns.                                               |
| **is\_primary\_key**             | Alias of `is_unique` (checks uniqueness of a single column).                                                        |
| **is\_composite\_key**           | Alias of `are_unique` (checks uniqueness across multiple columns).                                                  |
| **is\_equal**                    | Filters rows where the specified column is not equal (null-safe) to the given value.                                |
| **is\_equal\_than**              | Alias of `is_equal`.                                                                                                |
| **is\_between**                  | Filters rows where the specified column is not within the given numeric range.                                      |
| **is\_greater\_than**            | Filters rows where the specified column is less than or equal to the threshold value.                               |
| **is\_greater\_or\_equal\_than** | Filters rows where the specified column is less than the threshold value.                                           |
| **is\_less\_than**               | Filters rows where the specified column is greater than or equal to the threshold value.                            |
| **is\_less\_or\_equal\_than**    | Filters rows where the specified column is greater than the threshold value.                                        |
| **is\_positive**                 | Filters rows where the specified column is less than zero.                                                          |
| **is\_negative**                 | Filters rows where the specified column is greater than or equal to zero.                                           |
| **is\_contained\_in**            | Filters rows where the specified column is not in the provided list of values.                                      |
| **not\_contained\_in**           | Filters rows where the specified column is in the provided list of values.                                          |
| **has\_pattern**                 | Filters rows where the specified column does not match the given regular-expression pattern.                        |
| **is\_legit**                    | Filters rows where the specified column is null or does not match a non-whitespace pattern (`\S*`).                 |
| **has\_min**                     | Filters rows where the specified column is below the minimum threshold.                                             |
| **has\_max**                     | Filters rows where the specified column exceeds the maximum threshold.                                              |
| **has\_mean**                    | Returns all rows if the mean of the specified column exceeds the threshold; otherwise empty.                        |
| **has\_std**                     | Returns all rows if the standard deviation of the specified column exceeds the threshold; otherwise empty.          |
| **has\_sum**                     | Returns all rows if the sum of the specified column exceeds the threshold; otherwise empty.                         |
| **has\_cardinality**             | Returns all rows if the distinct count of the specified column exceeds the threshold; otherwise empty.              |
| **has\_infogain**                | Uses distinct-count as a proxy for information gain; returns all rows if it exceeds the threshold; otherwise empty. |
| **has\_entropy**                 | Uses distinct-count as a proxy for entropy; returns all rows if it exceeds the threshold; otherwise empty.          |
| **satisfies**                    | Filters rows where the given SQL expression (via `expr(value)`) is not satisfied.                                   |
| **validate\_schema**             | Compares the actual schema of a DataFrame against an expected schema and returns a match flag and errors.           |
| **validate**                     | Applies a list of named validation rules and returns aggregated and raw result DataFrames.                          |

---

### Date-related checks

| Test                       | Description                                                                                      |
| -------------------------- | ------------------------------------------------------------------------------------------------ |
| **validate\_date\_format** | Filters rows where the specified column does not match the expected date format or is null.      |
| **is\_future\_date**       | Filters rows where the specified date column is after todayâ€™s date.                              |
| **is\_past\_date**         | Filters rows where the specified date column is before todayâ€™s date.                             |
| **is\_date\_after**        | Filters rows where the specified date column is before the date provided in the rule.            |
| **is\_date\_before**       | Filters rows where the specified date column is after the date provided in the rule.             |
| **is\_date\_between**      | Filters rows where the specified date column is not within the given startâ€“end range.            |
| **all\_date\_checks**      | Filters rows where the specified date column is before todayâ€™s date (similar to `is_past_date`). |



## ğŸ“‚ Project Layout

```
sumeh/
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ sumeh
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py
â”‚   â”œâ”€â”€ core.py
â”‚   â”œâ”€â”€ engine
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ bigquery_engine.py
â”‚   â”‚   â”œâ”€â”€ dask_engine.py
â”‚   â”‚   â”œâ”€â”€ duckdb_engine.py
â”‚   â”‚   â”œâ”€â”€ polars_engine.py
â”‚   â”‚   â””â”€â”€ pyspark_engine.py
â”‚   â””â”€â”€ services
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ index.html
â”‚       â””â”€â”€ utils.py
â””â”€â”€ tests
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ mock
    â”‚   â”œâ”€â”€ config.csv
    â”‚   â””â”€â”€ data.csv
    â”œâ”€â”€ test_dask_engine.py
    â”œâ”€â”€ test_duckdb_engine.py
    â”œâ”€â”€ test_polars_engine.py
    â”œâ”€â”€ test_pyspark_engine.py
    â””â”€â”€ test_sumeh.py
```

## ğŸ“ˆ Roadmap

- [ ] Complete BigQuery engine implementation
- [ ] Complete Pandas engine implementation
- âœ… Enhanced documentation
- [ ] More validation rule types
- [ ] Performance optimizations

## ğŸ¤ Contributing

1. Fork & create a feature branch  
2. Implement new checks or engines, following existing signatures  
3. Add tests under `tests/`  
4. Open a PR and ensure CI passes

## ğŸ“œ License

Licensed under the [Apache License 2.0](LICENSE).

