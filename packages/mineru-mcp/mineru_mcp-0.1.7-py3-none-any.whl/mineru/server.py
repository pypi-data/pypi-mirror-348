"""MinerU Fileè½¬Markdownè½¬æ¢çš„FastMCPæœåŠ¡å™¨å®ç°ã€‚"""

import re
import json
import signal
import os  # æ·»åŠ å¯¼å…¥
import contextlib
from pathlib import Path
from typing import Dict, Any, List, Annotated
from pydantic import Field
import aiohttp

from fastmcp import FastMCP
from . import config
from .api import MinerUClient
from .language import get_language_list


# åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„ lifespan ä¸Šä¸‹æ–‡ç®¡ç†å™¨
@contextlib.asynccontextmanager
async def lifespan(app=None):
    # å¯åŠ¨é˜¶æ®µ
    print("MinerU Fileè½¬Markdownè½¬æ¢æœåŠ¡å¯åŠ¨...")
    try:
        yield  # åº”ç”¨è¿è¡Œé˜¶æ®µ
    finally:
        # å…³é—­é˜¶æ®µï¼Œæ— è®ºå¦‚ä½•éƒ½ä¼šæ‰§è¡Œ
        global _client_instance
        if _client_instance is not None:
            # æ¸…ç†å®¢æˆ·ç«¯èµ„æº
            _client_instance = None
        print("\nğŸ˜Š æ„Ÿè°¢ä½¿ç”¨MinerUæœåŠ¡ï¼æœåŠ¡æ­£åœ¨é€€å‡º...")


# åˆå§‹åŒ– FastMCP æœåŠ¡å™¨
mcp = FastMCP(
    name="MinerU File to Markdown Conversion",
    instructions="""
    ä¸€ä¸ªå°†æ–‡æ¡£è½¬åŒ–å·¥å…·ï¼Œå¯ä»¥å°†æ–‡æ¡£è½¬åŒ–æˆMarkdownã€Latexã€Docxç­‰æ ¼å¼ï¼Œæ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼ï¼ŒåŒ…æ‹¬PDFã€Wordã€Excelã€PPTä»¥åŠå›¾ç‰‡æ ¼å¼ï¼ˆJPGã€PNGã€JPEGï¼‰ã€‚

    ä½¿ç”¨å‰å¿…é¡»å…ˆè°ƒç”¨status://apiæ£€æŸ¥å½“å‰APIçŠ¶æ€ï¼Œè°¨æ…ç›´æ¥ä½¿ç”¨ï¼ï¼ï¼

    ç³»ç»Ÿå·¥å…·:
    convert_file_url: è½¬æ¢URLä¸­çš„æ–‡ä»¶
    convert_file_path: è½¬æ¢æœ¬åœ°æ–‡ä»¶
    local_parse_file: ä½¿ç”¨æœ¬åœ°è‡ªå·±æ­å»ºçš„APIè§£ææ–‡ä»¶
    get_ocr_languages: è·å–OCRæ”¯æŒçš„è¯­è¨€åˆ—è¡¨
    read_converted_file: è¯»å–è½¬æ¢åçš„æ–‡ä»¶å†…å®¹
    """,
    lifespan=lifespan,  # ä½¿ç”¨è‡ªå®šä¹‰ lifespan
)


# æ³¨å†Œä¿¡å·å¤„ç†å™¨
def handle_signals():
    def signal_handler(sig, frame):
        print("\nğŸ˜Š æ„Ÿè°¢ä½¿ç”¨MinerUæœåŠ¡ï¼æœåŠ¡æ­£åœ¨é€€å‡º...")
        os._exit(0)  # ä½¿ç”¨ os._exit(0) å¼ºåˆ¶é€€å‡ºè¿›ç¨‹ï¼Œä¸æ‰§è¡Œä»»ä½•æ¸…ç†ä»£ç 

    # ç›´æ¥æ³¨å†Œå¼ºåˆ¶é€€å‡ºçš„å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)


# Singleton instance for the client
_client_instance = None


def get_client() -> MinerUClient:
    """è·å– MinerUClient çš„å•ä¾‹å®ä¾‹ã€‚å¦‚æœå°šæœªåˆå§‹åŒ–ï¼Œåˆ™è¿›è¡Œåˆå§‹åŒ–ã€‚"""
    global _client_instance
    if _client_instance is None:
        _client_instance = MinerUClient()  # Initialization happens here
    return _client_instance


# Markdown æ–‡ä»¶çš„è¾“å‡ºç›®å½•
output_dir = config.DEFAULT_OUTPUT_DIR


def set_output_dir(dir_path: str):
    """è®¾ç½®è½¬æ¢åæ–‡ä»¶çš„è¾“å‡ºç›®å½•ã€‚"""
    global output_dir
    output_dir = dir_path
    config.ensure_output_dir(output_dir)
    return output_dir


def parse_list_input(input_str: str) -> List[str]:
    """
    è§£æå¯èƒ½åŒ…å«ç”±é€—å·æˆ–æ¢è¡Œç¬¦åˆ†éš”çš„å¤šä¸ªé¡¹ç›®çš„å­—ç¬¦ä¸²è¾“å…¥ã€‚

    Args:
        input_str: å¯èƒ½åŒ…å«å¤šä¸ªé¡¹ç›®çš„å­—ç¬¦ä¸²

    Returns:
        è§£æå‡ºçš„é¡¹ç›®åˆ—è¡¨
    """
    if not input_str:
        return []

    # æŒ‰é€—å·ã€æ¢è¡Œç¬¦æˆ–ç©ºæ ¼åˆ†å‰²
    items = re.split(r"[,\n\s]+", input_str)

    # ç§»é™¤ç©ºé¡¹ç›®å¹¶å¤„ç†å¸¦å¼•å·çš„é¡¹ç›®
    result = []
    for item in items:
        item = item.strip()
        # å¦‚æœå­˜åœ¨å¼•å·ï¼Œåˆ™ç§»é™¤
        if (item.startswith('"') and item.endswith('"')) or (
            item.startswith("'") and item.endswith("'")
        ):
            item = item[1:-1]

        if item:
            result.append(item)

    return result


@mcp.tool()
async def convert_file_url(
    url: Annotated[
        str,
        Field(
            description='æ–‡ä»¶URLï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼: - å•ä¸ªURL: "https://example.com/document.pdf" - å¤šä¸ªURL(é€—å·åˆ†éš”): "https://example.com/doc1.pdf, https://example.com/doc2.docx" - å­—å…¸é…ç½®: {"url": "https://example.com/document.pdf", "is_ocr": true} - å­—å…¸åˆ—è¡¨: [{"url": "url1", "is_ocr": true}, {"url": "url2", "is_ocr": false}] (æ”¯æŒpdfã€pptã€pptxã€docã€docxä»¥åŠå›¾ç‰‡æ ¼å¼jpgã€jpegã€png)'
        ),
    ],
    enable_ocr: Annotated[bool, Field(description="å¯ç”¨OCRè¯†åˆ«")] = False,
    enable_formula: Annotated[bool, Field(description="å¯ç”¨å…¬å¼è¯†åˆ«")] = True,
    enable_table: Annotated[bool, Field(description="å¯ç”¨è¡¨æ ¼è¯†åˆ«")] = True,
    language: Annotated[
        str, Field(description='æ–‡æ¡£è¯­è¨€ï¼Œé»˜è®¤"auto"ï¼Œå¯é€‰"zh"ä¸­æ–‡,"en"è‹±æ–‡ç­‰')
    ] = "auto",
    extra_formats: Annotated[
        List[str] | None,
        Field(description='é¢å¤–å¯¼å‡ºæ ¼å¼ï¼Œä¾‹å¦‚["docx", "html", "latex"]'),
    ] = None,
    page_ranges: Annotated[
        str | None,
        Field(
            description='æŒ‡å®šé¡µç èŒƒå›´ï¼Œæ ¼å¼ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ã€‚ä¾‹å¦‚ï¼š"2,4-6"ï¼šè¡¨ç¤ºé€‰å–ç¬¬2é¡µã€ç¬¬4é¡µè‡³ç¬¬6é¡µï¼›"2--2"ï¼šè¡¨ç¤ºä»ç¬¬2é¡µä¸€ç›´é€‰å–åˆ°å€’æ•°ç¬¬äºŒé¡µã€‚'
        ),
    ] = None,
) -> Dict[str, Any]:
    """
    **ä½¿ç”¨å‰å¿…é¡»å…ˆè°ƒç”¨status://apiæ£€æŸ¥å½“å‰APIçŠ¶æ€ï¼Œè°¨æ…ç›´æ¥ä½¿ç”¨ï¼ï¼ï¼**
    ä»URLè½¬æ¢æ–‡ä»¶åˆ°Markdownæ ¼å¼ã€‚æ”¯æŒå•ä¸ªæˆ–å¤šä¸ªURLå¤„ç†ã€‚

    è¿”å›:
        æˆåŠŸ: {"status": "success", "result_path": "è¾“å‡ºç›®å½•è·¯å¾„"}
        å¤±è´¥: {"status": "error", "error": "é”™è¯¯ä¿¡æ¯"}

    ç¤ºä¾‹:
        # åŸºæœ¬ç”¨æ³•
        result = await convert_file_url(url="https://example.com/document.pdf")

        # å¤„ç†å¤šä¸ªURL
        result = await convert_file_url(url="https://example.com/doc1.pdf, https://example.com/doc2.pdf")

        # é«˜çº§é€‰é¡¹
        result = await convert_file_url(
            url="https://example.com/document.pdf",
            enable_ocr=True,
            language="en",
            extra_formats=["docx", "html"],
            page_ranges="1-5,8,10-15"
        )
    """
    urls_to_process = None

    # æ£€æŸ¥æ˜¯å¦ä¸ºå­—å…¸æˆ–å­—å…¸åˆ—è¡¨æ ¼å¼çš„URLé…ç½®
    if isinstance(url, dict):
        # å•ä¸ªURLé…ç½®å­—å…¸
        urls_to_process = url
    elif isinstance(url, list) and len(url) > 0 and isinstance(url[0], dict):
        # URLé…ç½®å­—å…¸åˆ—è¡¨
        urls_to_process = url
    elif isinstance(url, str):
        # æ£€æŸ¥æ˜¯å¦ä¸º JSON å­—ç¬¦ä¸²æ ¼å¼çš„å¤šURLé…ç½®
        if url.strip().startswith("[") and url.strip().endswith("]"):
            try:
                # å°è¯•è§£æ JSON å­—ç¬¦ä¸²ä¸ºURLé…ç½®åˆ—è¡¨
                url_configs = json.loads(url)
                if not isinstance(url_configs, list):
                    raise ValueError("JSON URLé…ç½®å¿…é¡»æ˜¯åˆ—è¡¨æ ¼å¼")

                urls_to_process = url_configs
            except json.JSONDecodeError:
                # ä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œç»§ç»­ä½¿ç”¨å­—ç¬¦ä¸²è§£ææ–¹å¼
                pass

    if urls_to_process is None:
        # è§£ææ™®é€šURLåˆ—è¡¨
        urls = parse_list_input(url)

        if not urls:
            raise ValueError("æœªæä¾›æœ‰æ•ˆçš„ URL")

        if len(urls) == 1:
            # å•ä¸ªURLå¤„ç†
            urls_to_process = {"url": urls[0], "is_ocr": enable_ocr}
        else:
            # å¤šä¸ªURLï¼Œè½¬æ¢ä¸ºURLé…ç½®åˆ—è¡¨
            urls_to_process = []
            for url_item in urls:
                urls_to_process.append(
                    {
                        "url": url_item,
                        "is_ocr": enable_ocr,
                    }
                )

    # ä½¿ç”¨submit_file_url_taskå¤„ç†URLs
    try:
        result_path = await get_client().process_file_to_markdown(
            lambda urls, o: get_client().submit_file_url_task(
                urls,
                o,
                enable_formula=enable_formula,
                enable_table=enable_table,
                language=language,
                extra_formats=extra_formats,
                page_ranges=page_ranges,
            ),
            urls_to_process,
            enable_ocr,
            output_dir,
            enable_formula=enable_formula,
            enable_table=enable_table,
            language=language,
            extra_formats=extra_formats,
            page_ranges=page_ranges,
        )
        return {"status": "success", "result_path": result_path}
    except Exception as e:
        return {"status": "error", "error": str(e)}


@mcp.tool()
async def convert_file_path(
    file_path: Annotated[
        str,
        Field(
            description='æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼: - å•ä¸ªè·¯å¾„: "/path/to/file.pdf" - å¤šä¸ªè·¯å¾„(é€—å·åˆ†éš”): "/path/to/file1.pdf, /path/to/file2.pdf" - å­—å…¸é…ç½®: {"path": "/path/to/file.pdf", "is_ocr": true} - å­—å…¸åˆ—è¡¨: [{"path": "/path/file1.pdf", "is_ocr": true}, {"path": "/path/file2.pdf", "is_ocr": false}] (æ”¯æŒpdfã€pptã€pptxã€docã€docxä»¥åŠå›¾ç‰‡æ ¼å¼jpgã€jpegã€png)'
        ),
    ],
    enable_ocr: Annotated[bool, Field(description="å¯ç”¨OCRè¯†åˆ«")] = False,
    enable_formula: Annotated[bool, Field(description="å¯ç”¨å…¬å¼è¯†åˆ«")] = True,
    enable_table: Annotated[bool, Field(description="å¯ç”¨è¡¨æ ¼è¯†åˆ«")] = True,
    language: Annotated[
        str, Field(description='æ–‡æ¡£è¯­è¨€ï¼Œé»˜è®¤"auto"ï¼Œå¯é€‰"zh"ä¸­æ–‡,"en"è‹±æ–‡ç­‰')
    ] = "auto",
    extra_formats: Annotated[
        List[str] | None,
        Field(description='é¢å¤–å¯¼å‡ºæ ¼å¼ï¼Œä¾‹å¦‚["docx", "html", "latex"]'),
    ] = None,
    page_ranges: Annotated[
        str | None,
        Field(
            description='æŒ‡å®šé¡µç èŒƒå›´ï¼Œæ ¼å¼ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ã€‚ä¾‹å¦‚ï¼š"2,4-6"ï¼šè¡¨ç¤ºé€‰å–ç¬¬2é¡µã€ç¬¬4é¡µè‡³ç¬¬6é¡µï¼›"2--2"ï¼šè¡¨ç¤ºä»ç¬¬2é¡µä¸€ç›´é€‰å–åˆ°å€’æ•°ç¬¬äºŒé¡µã€‚'
        ),
    ] = None,
) -> Dict[str, Any]:
    """
    **ä½¿ç”¨å‰å¿…é¡»å…ˆè°ƒç”¨status://apiæ£€æŸ¥å½“å‰APIçŠ¶æ€ï¼Œè°¨æ…ç›´æ¥ä½¿ç”¨ï¼ï¼ï¼**
    å°†æœ¬åœ°æ–‡ä»¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ã€‚æ”¯æŒå•ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶æ‰¹é‡å¤„ç†ã€‚

    è¿”å›:
        æˆåŠŸ: {"status": "success", "result_path": "è¾“å‡ºç›®å½•è·¯å¾„"}
        å¤±è´¥: {"status": "error", "error": "é”™è¯¯ä¿¡æ¯"}

    ç¤ºä¾‹:
        # åŸºæœ¬ç”¨æ³•
        result = await convert_file_path(file_path="/path/to/document.pdf")

        # å¤„ç†å¤šä¸ªæ–‡ä»¶
        result = await convert_file_path(file_path="/path/to/file1.pdf, /path/to/file2.pdf")

        # é«˜çº§é€‰é¡¹
        result = await convert_file_path(
            file_path="/path/to/document.pdf",
            enable_ocr=True,
            language="zh",
            extra_formats=["docx"],
            page_ranges="1-10,15,20-30"
        )
    """

    files_to_process = None

    # æ£€æŸ¥æ˜¯å¦ä¸ºå­—å…¸æˆ–å­—å…¸åˆ—è¡¨æ ¼å¼çš„æ–‡ä»¶é…ç½®
    if isinstance(file_path, dict):
        # å•ä¸ªæ–‡ä»¶é…ç½®å­—å…¸
        files_to_process = file_path
    elif (
        isinstance(file_path, list)
        and len(file_path) > 0
        and isinstance(file_path[0], dict)
    ):
        # æ–‡ä»¶é…ç½®å­—å…¸åˆ—è¡¨
        files_to_process = file_path
    elif isinstance(file_path, str):
        # æ£€æŸ¥æ˜¯å¦ä¸º JSON å­—ç¬¦ä¸²æ ¼å¼çš„å¤šæ–‡ä»¶é…ç½®
        if file_path.strip().startswith("[") and file_path.strip().endswith("]"):
            try:
                # å°è¯•è§£æ JSON å­—ç¬¦ä¸²ä¸ºæ–‡ä»¶é…ç½®åˆ—è¡¨
                file_configs = json.loads(file_path)
                if not isinstance(file_configs, list):
                    raise ValueError("JSON æ–‡ä»¶é…ç½®å¿…é¡»æ˜¯åˆ—è¡¨æ ¼å¼")

                files_to_process = file_configs
            except json.JSONDecodeError:
                # ä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œç»§ç»­ä½¿ç”¨å­—ç¬¦ä¸²è§£ææ–¹å¼
                pass

    if files_to_process is None:
        # è§£ææ™®é€šæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        file_paths = parse_list_input(file_path)

        if not file_paths:
            raise ValueError("æœªæä¾›æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„")

        if len(file_paths) == 1:
            # å•ä¸ªæ–‡ä»¶å¤„ç†
            files_to_process = {
                "path": file_paths[0],
                "is_ocr": enable_ocr,
            }
        else:
            # å¤šä¸ªæ–‡ä»¶è·¯å¾„ï¼Œè½¬æ¢ä¸ºæ–‡ä»¶é…ç½®åˆ—è¡¨
            files_to_process = []
            for i, path in enumerate(file_paths):
                files_to_process.append(
                    {
                        "path": path,
                        "is_ocr": enable_ocr,
                    }
                )

    # ä½¿ç”¨submit_file_taskå¤„ç†æ–‡ä»¶
    try:
        result_path = await get_client().process_file_to_markdown(
            lambda files, o: get_client().submit_file_task(
                files,
                o,
                enable_formula=enable_formula,
                enable_table=enable_table,
                language=language,
                extra_formats=extra_formats,
                page_ranges=page_ranges,
            ),
            files_to_process,
            enable_ocr,
            output_dir,
            enable_formula=enable_formula,
            enable_table=enable_table,
            language=language,
            extra_formats=extra_formats,
            page_ranges=page_ranges,
        )
        return {"status": "success", "result_path": result_path}
    except Exception as e:
        return {"status": "error", "error": str(e)}


@mcp.tool()
async def local_parse_file(
    file_path: Annotated[
        str,
        Field(
            description="è¦è§£æçš„æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒ pdfã€pptã€pptxã€docã€docxä»¥åŠå›¾ç‰‡æ ¼å¼jpgã€jpegã€png"
        ),
    ],
    parse_method: Annotated[str, Field(description="è§£ææ–¹æ³•")] = "auto",
    is_json_md_dump: Annotated[
        bool, Field(description="ä»¥JSONæ ¼å¼å¯¼å‡ºMarkdown")
    ] = False,
    output_dir: Annotated[
        str | None,
        Field(
            description="è¾“å‡ºç›®å½•è·¯å¾„(è¿™é‡Œä¸æ˜¯MCPæ‰€åœ¨ä¸»æœºçš„è¾“å‡ºç›®å½•ï¼Œè€Œæ˜¯æœ¬åœ°APIæ‰€åœ¨æœåŠ¡å™¨çš„è¾“å‡ºç›®å½•)"
        ),
    ] = None,
    return_layout: Annotated[bool, Field(description="æ˜¯å¦è¿”å›å¸ƒå±€ä¿¡æ¯")] = False,
    return_info: Annotated[bool, Field(description="æ˜¯å¦è¿”å›åŸºæœ¬ä¿¡æ¯")] = False,
    return_content_list: Annotated[bool, Field(description="æ˜¯å¦è¿”å›å†…å®¹åˆ—è¡¨")] = False,
    return_images: Annotated[bool, Field(description="æ˜¯å¦è¿”å›å›¾ç‰‡")] = False,
) -> Dict[str, Any]:
    """
    **ä½¿ç”¨å‰å¿…é¡»å…ˆè°ƒç”¨status://apiæ£€æŸ¥å½“å‰APIçŠ¶æ€ï¼Œè°¨æ…ç›´æ¥ä½¿ç”¨ï¼ï¼ï¼**
    æ ¹æ®ç¯å¢ƒå˜é‡è®¾ç½®ä½¿ç”¨æœ¬åœ°æˆ–è¿œç¨‹APIè§£ææ–‡ä»¶ã€‚

    è¿”å›:
        æˆåŠŸ: {"status": "success", "result": å¤„ç†ç»“æœ} æˆ– {"status": "success", "result_path": "è¾“å‡ºç›®å½•è·¯å¾„"}
        å¤±è´¥: {"status": "error", "error": "é”™è¯¯ä¿¡æ¯"}

    ç¤ºä¾‹:
        # åŸºæœ¬ç”¨æ³•
        result = await local_parse_file(file_path="/path/to/document.pdf")

        # é«˜çº§ç”¨æ³•
        result = await local_parse_file(
            file_path="/path/to/document.pdf",
            parse_method="auto",
            is_json_md_dump=True,
            output_dir="/path/to/output",
            return_layout=True
        )
    """
    file_path = Path(file_path)

    # é»˜è®¤å’Œç¯å¢ƒå˜é‡é…ç½®ä¸€è‡´ï¼Œä½†æ˜¯è¦æ³¨æ„ï¼Œè¿™é‡Œoutput_diræ˜¯æœ¬åœ°APIæ‰€åœ¨æœåŠ¡å™¨çš„
    # è¾“å‡ºç›®å½•è€Œä¸æ˜¯MCPæ‰€åœ¨ä¸»æœºçš„è¾“å‡ºç›®å½•
    if output_dir is None:
        output_dir = config.DEFAULT_OUTPUT_DIR

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not file_path.exists():
        return {"status": "error", "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}

    try:
        # æ ¹æ®ç¯å¢ƒå˜é‡å†³å®šä½¿ç”¨æœ¬åœ°APIè¿˜æ˜¯è¿œç¨‹API
        if config.USE_LOCAL_API:
            config.logger.info(f"ä½¿ç”¨æœ¬åœ°API: {config.LOCAL_MINERU_API_BASE}")
            return await _parse_file_local(
                file_path=str(file_path),
                parse_method=parse_method,
                is_json_md_dump=is_json_md_dump,
                output_dir=output_dir,
                return_layout=return_layout,
                return_info=return_info,
                return_content_list=return_content_list,
                return_images=return_images,
            )
        else:
            return {"status": "error", "error": "è¿œç¨‹APIæœªé…ç½®"}
    except Exception as e:
        config.logger.error(f"è§£ææ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return {"status": "error", "error": str(e)}


@mcp.tool()
async def get_ocr_languages() -> Dict[str, Any]:
    """
    è·å– OCR æ”¯æŒçš„è¯­è¨€åˆ—è¡¨ã€‚

    Returns:
        Dict[str, Any]: åŒ…å«æ‰€æœ‰æ”¯æŒçš„OCRè¯­è¨€åˆ—è¡¨çš„å­—å…¸
    """
    try:
        # ä»languageæ¨¡å—è·å–è¯­è¨€åˆ—è¡¨
        languages = get_language_list()
        return {"status": "success", "languages": languages}
    except Exception as e:
        return {"status": "error", "error": str(e)}


@mcp.tool()
async def read_converted_file(
    file_path: Annotated[str, Field(description="è¦è¯»å–çš„æ–‡ä»¶è·¯å¾„")],
) -> Dict[str, Any]:
    """
    è¯»å–è§£æåçš„æ–‡ä»¶å†…å®¹ã€‚ä¸»è¦æ”¯æŒMarkdownå’Œå…¶ä»–æ–‡æœ¬æ–‡ä»¶æ ¼å¼ã€‚

    è¿”å›:
        æˆåŠŸ: {"status": "success", "content": "æ–‡ä»¶å†…å®¹"}
        å¤±è´¥: {"status": "error", "error": "é”™è¯¯ä¿¡æ¯"}

    ç¤ºä¾‹:
        # åŸºæœ¬ç”¨æ³•
        result = await read_converted_file(file_path="/path/to/converted.md")

    > æ³¨æ„ï¼šå¦‚æœæ–‡ä»¶æ˜¯Markdownæ ¼å¼,ä¸€èˆ¬è°ƒç”¨è¿œç¨‹APIè·å¾—çš„è§£æç»“æœçš„è·¯å¾„æ˜¯./downloads/xxx/æ–‡ä»¶å/full.md æˆ– ./downloads/xxx/full.txt
    """
    try:
        target_file = Path(file_path)
        parent_dir = target_file.parent
        suffix = target_file.suffix.lower()

        # æ”¯æŒçš„æ–‡æœ¬æ–‡ä»¶æ ¼å¼
        text_extensions = [".md", ".txt", ".json", ".html", ".tex", ".latex"]

        if suffix not in text_extensions:
            return {
                "status": "error",
                "error": f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {suffix}ã€‚ç›®å‰ä»…æ”¯æŒä»¥ä¸‹æ ¼å¼: {', '.join(text_extensions)}",
            }

        if not target_file.exists():
            if not parent_dir.exists():
                return {"status": "error", "error": f"ç›®å½• {parent_dir} ä¸å­˜åœ¨"}

            # é€’å½’æœç´¢æ‰€æœ‰å­ç›®å½•ä¸‹çš„åŒåç¼€æ–‡ä»¶
            similar_files_paths = [
                str(f) for f in parent_dir.rglob(f"*{suffix}") if f.is_file()
            ]

            if similar_files_paths:
                if len(similar_files_paths) == 1:
                    # å¦‚æœåªæ‰¾åˆ°ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æ¥è¯»å–å¹¶è¿”å›å†…å®¹
                    alternative_file = similar_files_paths[0]
                    try:
                        with open(alternative_file, "r", encoding="utf-8") as f:
                            content = f.read()
                        return {
                            "status": "success",
                            "content": content,
                            "message": f"æœªæ‰¾åˆ°æ–‡ä»¶ {target_file.name}ï¼Œä½†æ‰¾åˆ°äº† {Path(alternative_file).name}ï¼Œå·²è¿”å›å…¶å†…å®¹",
                        }
                    except Exception as e:
                        return {
                            "status": "error",
                            "error": f"å°è¯•è¯»å–æ›¿ä»£æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}",
                        }
                else:
                    # å¦‚æœæ‰¾åˆ°å¤šä¸ªæ–‡ä»¶ï¼Œæä¾›å»ºè®®åˆ—è¡¨
                    suggestion = f"ä½ æ˜¯å¦åœ¨æ‰¾: {', '.join(similar_files_paths)}?"
                    return {
                        "status": "error",
                        "error": f"æ–‡ä»¶ {target_file.name} ä¸å­˜åœ¨ã€‚åœ¨ {parent_dir} åŠå…¶å­ç›®å½•ä¸‹æ‰¾åˆ°ä»¥ä¸‹åŒç±»å‹æ–‡ä»¶ã€‚{suggestion}",
                    }
            else:
                return {
                    "status": "error",
                    "error": f"æ–‡ä»¶ {target_file.name} ä¸å­˜åœ¨ï¼Œä¸”åœ¨ç›®å½• {parent_dir} åŠå…¶å­ç›®å½•ä¸‹æœªæ‰¾åˆ°å…¶ä»– {suffix} æ–‡ä»¶ã€‚",
                }

        # ä»¥æ–‡æœ¬æ¨¡å¼è¯»å–
        with open(target_file, "r", encoding="utf-8") as f:
            content = f.read()
        return {"status": "success", "content": content}

    except Exception as e:
        config.logger.error(f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return {"status": "error", "error": str(e)}


@mcp.resource("status://api")
def api_status() -> str:
    """å±•ç¤º API çŠ¶æ€ä¿¡æ¯ã€‚"""
    api_config = config.validate_api_config()

    # æ·»åŠ æœ¬åœ°APIé…ç½®ä¿¡æ¯
    api_config["use_local_api"] = config.USE_LOCAL_API
    if config.USE_LOCAL_API:
        api_config["local_api_base"] = config.LOCAL_MINERU_API_BASE

    # æ ¼å¼åŒ–ä¸ºæ˜“è¯»æ ¼å¼
    status_lines = [
        "# MinerU API é…ç½®çŠ¶æ€",
        "",
        f"- API åŸºç¡€ URL: {api_config['api_base']}",
        f"- API å¯†é’¥è®¾ç½®: {'å·²è®¾ç½®' if api_config['api_key_set'] else 'æœªè®¾ç½®'}",
        f"- è¾“å‡ºç›®å½•: {api_config['output_dir']}",
        f"- ä½¿ç”¨æœ¬åœ° API: {'æ˜¯' if api_config['use_local_api'] else 'å¦'}",
    ]

    # ä»…å½“ä½¿ç”¨æœ¬åœ°APIæ—¶æ˜¾ç¤ºæœ¬åœ°APIåŸºç¡€URL
    if api_config["use_local_api"]:
        status_lines.append(f"- æœ¬åœ° API åŸºç¡€ URL: {api_config['local_api_base']}")

    return "\n".join(status_lines)


@mcp.resource("help://usage")
def usage_help() -> str:
    """æä¾› MinerU MCP æœåŠ¡ä½¿ç”¨è¯´æ˜çš„å¸®åŠ©æ–‡æ¡£ã€‚"""
    return """
# MinerU-MCP æœåŠ¡ä½¿ç”¨è¯´æ˜

MinerU-MCP æ˜¯ä¸€ä¸ªæ¡¥æ¥ MinerU File è½¬ Markdown API çš„ MCP æœåŠ¡ã€‚æ”¯æŒæœ¬åœ°APIå’Œè¿œç¨‹APIä¸¤ç§æ¨¡å¼ã€‚

## å·¥å…·é€‰æ‹©æŒ‡å—

åœ¨ä½¿ç”¨ä»»ä½•å·¥å…·å‰ï¼Œ**è¯·å…ˆæ£€æŸ¥å½“å‰APIçŠ¶æ€**ï¼š
```
await client.get_resource("status://api")
```

### APIæ¨¡å¼ä¸æ¨èå·¥å…·

1. **è¿œç¨‹APIæ¨¡å¼** (USE_LOCAL_API=false)ï¼š
   - æ¨èå·¥å…·: `convert_file_url`, `convert_file_path`
   - ä¸æ¨èå·¥å…·: `local_parse_file` (è™½ç„¶å¯ç”¨ï¼Œä½†åœ¨è¿œç¨‹æ¨¡å¼ä¸‹ä¸æ˜¯æœ€ä¼˜é€‰æ‹©)

2. **æœ¬åœ°APIæ¨¡å¼** (USE_LOCAL_API=true)ï¼š
   - æ¨èå·¥å…·: `local_parse_file`
   - ä¸æ¨èå·¥å…·: `convert_file_url`, `convert_file_path` (è¿™äº›å·¥å…·å§‹ç»ˆä½¿ç”¨è¿œç¨‹API)

## å¯ç”¨çš„å·¥å…·

### 1. convert_file_url [ä»…é™è¿œç¨‹API]

ä» URL è½¬æ¢æ–‡ä»¶åˆ° Markdown æ ¼å¼ã€‚**æ³¨æ„ï¼šæ­¤å·¥å…·å§‹ç»ˆä½¿ç”¨è¿œç¨‹APIï¼Œä¸ç¯å¢ƒè®¾ç½®æ— å…³**ã€‚

**åŸºæœ¬ç”¨æ³•**:
```
await client.call("convert_file_url", url="https://example.com/document.pdf")
```

**é€‰é¡¹**:
- `url`: æ–‡ä»¶çš„URL (å¿…éœ€)
- `enable_ocr`: æ˜¯å¦å¯ç”¨OCR (é»˜è®¤: False)
- `enable_formula`: æ˜¯å¦å¯ç”¨å…¬å¼è¯†åˆ« (é»˜è®¤: True)
- `enable_table`: æ˜¯å¦å¯ç”¨è¡¨æ ¼è¯†åˆ« (é»˜è®¤: True)
- `language`: æ–‡æ¡£è¯­è¨€ (é»˜è®¤: "auto")
- `extra_formats`: é¢å¤–å¯¼å‡ºæ ¼å¼ (é»˜è®¤: None)
- `page_ranges`: æŒ‡å®šé¡µç èŒƒå›´ï¼Œå¦‚ "1-5,8,10-15" (é»˜è®¤: None)

**æ”¯æŒçš„æ–‡ä»¶æ ¼å¼**:
- æ–‡æ¡£: PDF, DOCX, DOC, PPT, PPTX
- å›¾ç‰‡: JPG, JPEG, PNG

### 2. convert_file_path [ä»…é™è¿œç¨‹API]

ä»æœ¬åœ°æ–‡ä»¶è·¯å¾„è½¬æ¢æ–‡ä»¶åˆ° Markdown æ ¼å¼ã€‚**æ³¨æ„ï¼šæ­¤å·¥å…·å§‹ç»ˆä½¿ç”¨è¿œç¨‹APIï¼Œä¸ç¯å¢ƒè®¾ç½®æ— å…³**ã€‚

**åŸºæœ¬ç”¨æ³•**:
```
await client.call("convert_file_path", file_path="/path/to/document.pdf")
```

**é€‰é¡¹**:
- `file_path`: æ–‡ä»¶çš„è·¯å¾„ (å¿…éœ€)
- `enable_ocr`: æ˜¯å¦å¯ç”¨OCR (é»˜è®¤: False)
- `enable_formula`: æ˜¯å¦å¯ç”¨å…¬å¼è¯†åˆ« (é»˜è®¤: True)
- `enable_table`: æ˜¯å¦å¯ç”¨è¡¨æ ¼è¯†åˆ« (é»˜è®¤: True)
- `language`: æ–‡æ¡£è¯­è¨€ (é»˜è®¤: "auto")
- `extra_formats`: é¢å¤–å¯¼å‡ºæ ¼å¼ (é»˜è®¤: None)
- `page_ranges`: æŒ‡å®šé¡µç èŒƒå›´ï¼Œå¦‚ "1-5,8,10-15" (é»˜è®¤: None)

**æ”¯æŒçš„æ–‡ä»¶æ ¼å¼**:
- æ–‡æ¡£: PDF, DOCX, DOC, PPT, PPTX
- å›¾ç‰‡: JPG, JPEG, PNG

### 3. local_parse_file [æœ¬åœ°APIä¼˜å…ˆ]

æ ¹æ®ç¯å¢ƒå˜é‡é…ç½®ï¼Œä½¿ç”¨æœ¬åœ°æˆ–è¿œç¨‹APIè§£ææ–‡ä»¶ã€‚**å½“USE_LOCAL_API=trueæ—¶ä½¿ç”¨æœ¬åœ°APIï¼Œå¦åˆ™ä½¿ç”¨è¿œç¨‹API**ã€‚

**åŸºæœ¬ç”¨æ³•**:
```
await client.call("local_parse_file", file_path="/path/to/document.pdf")
```

**é€‰é¡¹**:
- `file_path`: æ–‡ä»¶çš„è·¯å¾„ (å¿…éœ€)
- `parse_method`: è§£ææ–¹æ³• (é»˜è®¤: "auto")
- `is_json_md_dump`: æ˜¯å¦ä»¥JSONæ ¼å¼å¯¼å‡ºMarkdown (é»˜è®¤: False)
- `output_dir`: è¾“å‡ºç›®å½• (é»˜è®¤: None)
- `return_layout`: æ˜¯å¦è¿”å›å¸ƒå±€ä¿¡æ¯ (é»˜è®¤: False)
- `return_info`: æ˜¯å¦è¿”å›ä¿¡æ¯ (é»˜è®¤: False)
- `return_content_list`: æ˜¯å¦è¿”å›å†…å®¹åˆ—è¡¨ (é»˜è®¤: False)
- `return_images`: æ˜¯å¦è¿”å›å›¾ç‰‡ (é»˜è®¤: False)

**æ”¯æŒçš„æ–‡ä»¶æ ¼å¼**:
- æ–‡æ¡£: PDF, DOCX, DOC, PPT, PPTX
- å›¾ç‰‡: JPG, JPEG, PNG

### 4. get_ocr_languages

è·å–OCRæ”¯æŒçš„è¯­è¨€åˆ—è¡¨ã€‚

**åŸºæœ¬ç”¨æ³•**:
```
await client.call("get_ocr_languages")
```

### 5. read_converted_file

è¯»å–è§£æåçš„æ–‡ä»¶å†…å®¹ï¼Œä¸»è¦æ”¯æŒMarkdownå’Œå…¶ä»–æ–‡æœ¬æ–‡ä»¶æ ¼å¼ã€‚

**åŸºæœ¬ç”¨æ³•**:
```
await client.call("read_converted_file", file_path="/path/to/converted.md")
```

**é€‰é¡¹**:
- `file_path`: æ–‡ä»¶çš„è·¯å¾„ (å¿…éœ€)

**æ”¯æŒçš„æ–‡ä»¶æ ¼å¼**:
- Markdown (.md)
- æ–‡æœ¬æ–‡ä»¶ (.txt)
- JSONæ–‡ä»¶ (.json)
- HTMLæ–‡ä»¶ (.html)
- TeX/LaTeXæ–‡ä»¶ (.tex, .latex)

## ç¯å¢ƒå˜é‡é…ç½®

- `MINERU_API_KEY`: MinerU APIçš„å¯†é’¥ï¼ˆå¿…éœ€ï¼‰
- `MINERU_API_BASE`: MinerU APIçš„åŸºç¡€URLï¼ˆé»˜è®¤ä¸º "https://mineru.net"ï¼‰
- `OUTPUT_DIR`: ç»“æœè¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä¸º "./downloads"ï¼‰
- `USE_LOCAL_API`: æ˜¯å¦ä½¿ç”¨æœ¬åœ°APIï¼ˆtrue/falseï¼‰
- `LOCAL_MINERU_API_BASE`: æœ¬åœ°APIåŸºç¡€URLï¼ˆé»˜è®¤ä¸º "http://localhost:8080"ï¼‰

## èµ„æº

- `status://api`: æ˜¾ç¤ºå½“å‰APIé…ç½®çŠ¶æ€ï¼ˆ**é‡è¦ï¼šåœ¨ä½¿ç”¨å·¥å…·å‰è¯·å…ˆæ£€æŸ¥æ­¤çŠ¶æ€**ï¼‰
- `help://usage`: æ˜¾ç¤ºæ­¤å¸®åŠ©æ–‡æ¡£
"""


@mcp.prompt()
def conversion_prompt(
    input_content: Annotated[
        str, Field(description="ç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼Œå¯èƒ½åŒ…å«æ–‡ä»¶è·¯å¾„æˆ–URL")
    ] = "",
) -> str:
    """
    åˆ›å»ºæ–‡ä»¶è½¬Markdownå¤„ç†æç¤ºï¼ŒæŒ‡å¯¼AIå¦‚ä½•ä½¿ç”¨è½¬æ¢å·¥å…·ã€‚

    Returns:
        æŒ‡å¯¼AIä½¿ç”¨è½¬æ¢å·¥å…·çš„æç¤ºå­—ç¬¦ä¸²
    """
    return f"""
Please convert the following file(s) to Markdown format according to the request below:

{input_content}

First, check the current API mode using the status resource:
```
await client.get_resource("status://api")
```

Then select the appropriate tool based on API mode and input type:

For Remote API mode (USE_LOCAL_API=false):
- If it is a URL or multiple URLs, use the convert_file_url tool
- If it is a local file path or multiple file paths, use the convert_file_path tool

For Local API mode (USE_LOCAL_API=true):
- Prefer local_parse_file tool for all local file conversions
- Note that convert_file_url and convert_file_path will still use the remote API regardless of local mode

If both URLs and local files are included, please use the above tools separately for each part.

Tool usage guidelines:
1. Batch processing is supported - you can convert multiple URLs or file paths
at once (separated by commas, spaces, or newlines)
2. OCR is disabled by default, but can be enabled for better handling of scanned files
3. The converted Markdown files will be saved in the specified output directory
4. For URLs, the system will automatically download and clean up temporary files after processing

After conversion, you can read the contents of the converted file using:
```
result = await client.call("read_converted_file", file_path="/path/to/converted.md")
```
This tool supports reading Markdown (.md), text (.txt), JSON (.json), HTML (.html), and TeX/LaTeX (.tex, .latex) files.

Advanced parameters available:
- enable_ocr: Whether to enable OCR (default: False)
- enable_formula: Whether to enable formula recognition (default: True)
- enable_table: Whether to enable table recognition (default: True)
- language: Document language code or 'auto' for automatic detection
- extra_formats: Additional export formats (options: ['docx', 'html', 'latex'])
- page_ranges: Specify page ranges, e.g., "1-5,8,10-15" (selects pages 1-5, 8, and 10-15)

Supported file formats:
- Documents: PDF, DOCX, DOC, PPT, PPTX
- Images: JPG, JPEG, PNG

Example input formats:
- URL: https://example.com/document.pdf
- Local file: /path/to/document.pdf
- Multiple URLs: https://example.com/doc1.pdf, https://example.com/doc2.pdf
- Multiple files: /path/to/doc1.pdf, /path/to/doc2.pdf

If you have special requirements for the conversion process, please specify the relevant parameters when using the tool.
"""


async def _parse_file_local(
    file_path: str,
    parse_method: str = "auto",
    is_json_md_dump: bool = False,
    output_dir: str = None,
    return_layout: bool = False,
    return_info: bool = False,
    return_content_list: bool = False,
    return_images: bool = False,
) -> Dict[str, Any]:
    """
    ä½¿ç”¨æœ¬åœ°APIè§£ææ–‡ä»¶ã€‚

    Args:
        file_path: è¦è§£æçš„æ–‡ä»¶è·¯å¾„
        parse_method: è§£ææ–¹æ³•
        is_json_md_dump: æ˜¯å¦ä»¥JSONæ ¼å¼å¯¼å‡ºMarkdown
        output_dir: è¾“å‡ºç›®å½•
        return_layout: æ˜¯å¦è¿”å›å¸ƒå±€ä¿¡æ¯
        return_info: æ˜¯å¦è¿”å›ä¿¡æ¯
        return_content_list: æ˜¯å¦è¿”å›å†…å®¹åˆ—è¡¨
        return_images: æ˜¯å¦è¿”å›å›¾ç‰‡

    Returns:
        Dict[str, Any]: åŒ…å«è§£æç»“æœçš„å­—å…¸
    """
    # API URLè·¯å¾„
    api_url = f"{config.LOCAL_MINERU_API_BASE}/file_parse"

    # ä½¿ç”¨Pathå¯¹è±¡ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®
    file_path_obj = Path(file_path)
    if not file_path_obj.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    # è¯»å–æ–‡ä»¶äºŒè¿›åˆ¶æ•°æ®
    with open(file_path_obj, "rb") as f:
        file_data = f.read()

    # æ„å»ºURLæŸ¥è¯¢å‚æ•°
    params = {
        "parse_method": parse_method,
        "is_json_md_dump": str(is_json_md_dump).lower(),
        "return_layout": str(return_layout).lower(),
        "return_info": str(return_info).lower(),
        "return_content_list": str(return_content_list).lower(),
        "return_images": str(return_images).lower(),
    }

    # å¦‚æœæä¾›äº†è¾“å‡ºç›®å½•ï¼Œæ·»åŠ åˆ°å‚æ•°ä¸­
    if output_dir:
        params["output_dir"] = output_dir

    # å‡†å¤‡ç”¨äºä¸Šä¼ æ–‡ä»¶çš„è¡¨å•æ•°æ®
    file_type = file_path_obj.suffix.lower()
    form_data = aiohttp.FormData()
    form_data.add_field(
        "file", file_data, filename=file_path_obj.name, content_type=file_type
    )

    config.logger.debug(f"å‘é€æœ¬åœ°APIè¯·æ±‚åˆ°: {api_url}")
    config.logger.debug(f"è¯·æ±‚å‚æ•°: {params}")
    config.logger.debug(f"ä¸Šä¼ æ–‡ä»¶: {file_path_obj.name} (å¤§å°: {len(file_data)} å­—èŠ‚)")

    # å‘é€è¯·æ±‚
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(api_url, data=form_data, params=params) as response:
                if response.status != 200:
                    error_text = await response.text()
                    config.logger.error(
                        f"APIè¿”å›é”™è¯¯çŠ¶æ€ç : {response.status}, é”™è¯¯ä¿¡æ¯: {error_text}"
                    )
                    raise RuntimeError(f"APIè¿”å›é”™è¯¯: {response.status}, {error_text}")

                result = await response.json()

                config.logger.debug(f"æœ¬åœ°APIå“åº”: {result}")

                # å¤„ç†å“åº”
                if "error" in result:
                    return {"status": "error", "error": result["error"]}

                return {"status": "success", "result": result}
    except aiohttp.ClientError as e:
        error_msg = f"ä¸æœ¬åœ°APIé€šä¿¡æ—¶å‡ºé”™: {str(e)}"
        config.logger.error(error_msg)
        raise RuntimeError(error_msg)


def run_server(mode=None):
    """è¿è¡Œ FastMCP æœåŠ¡å™¨ã€‚"""
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    config.ensure_output_dir(output_dir)

    # æ£€æŸ¥æ˜¯å¦è®¾ç½®äº† API å¯†é’¥
    if not config.MINERU_API_KEY:
        print("è­¦å‘Š: MINERU_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ã€‚")
        print("ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è®¾ç½®: export MINERU_API_KEY=your_api_key")

    try:
        # è¿è¡ŒæœåŠ¡å™¨
        if mode:
            mcp.run(mode)
        else:
            mcp.run()
    except KeyboardInterrupt:
        print("\nğŸ˜Š æ„Ÿè°¢ä½¿ç”¨MinerUæœåŠ¡ï¼æœåŠ¡æ­£åœ¨ä¼˜é›…é€€å‡º...")
    except Exception as e:
        print(f"\nâŒ æœåŠ¡å¼‚å¸¸é€€å‡º: {str(e)}")
