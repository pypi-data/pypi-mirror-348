2011 utförde en grupp forskare en vetenskaplig studie för att få ett omöjligt resultat: att man kan bli yngre av att lyssna på vissa låtar. 
Studien omfattade riktiga människor, sanningsenligt rapporterade data, och vanligt förekommande statistiska analyser. Så, hur gick de tillväga? 
Svaret finns i en statistisk metod som forskare ofta använder för att ta reda på om deras resultat betyder något eller om de är slumpmässiga. Hela poängen med musikstudien var att visa på vilka sätt den här metoden kan missbrukas. 
Ett känt tankeexperiment förklarar metoden: Det finns åtta muggar te. I fyra av dem har mjölken hällts i först, i fyra av dem har teet hällts i först. En deltagare ska avgöra vilken som är vilken utifrån smaken. Det finns 70 olika sätt att sortera muggarna i grupper om fyra, och bara ett sätt är rätt. 
Så, kan hon känna skillnad? Det är studiens frågeställning. För att analysera hennes val ställer vi upp en nollhypotes: Att hon inte kan känna skillnad. Om hon inte kan känna skillnad, kommer hon ändå att svara rätt 1 gång av 70, på ren tur. 1 av 70 är ungefär 0,014. Den siffran kallas p-värdet. Inom många områden ses ett p-värde på 0,05 eller lägre som statistiskt säkerställt, vilket innebär att det finns grund för att avfärda nollhypotesen. Baserat på p-värdet 0,014 kan de avfärda nollhypotesen att hon inte kan känna skillnad. 
Trots att p-värde ofta används av forskare och tidskrifter för att utvärdera vetenskapliga resultat, så är de väldigt förvirrande, även för många vetenskapsmän. Det beror delvis på att det enda p-värdet egentligen säger är sannolikheten för att få ett visst resultat, förutsatt att nollhypotesen stämmer. Så om hon sorterar teerna rätt, är p-värdet sannolikheten för att hon ska göra det förutsatt att hon inte kan känna skillnad. Men det omvända är inte sant: P-värdet säger inget om sannolikheten att hon kan känna skillnad, vilket är det vi försöker ta reda på. 
Men om p-värdet inte besvarar studiens frågeställning, varför används det inom vetenskapen? Jo, även om p-värdet inte direkt anger sannolikheten för att resultaten är slumpmässiga, så ger det oftast en ganska tillförlitlig indikation. Åtminstone när det används på rätt sätt. Och det är där många forskare, och hela forskningsområden, har stött på problem. De flesta riktiga studier är mer komplexa än te-experimentet. Forskare kan testa sina frågeställningar på många olika sätt, och vissa av de sätten kanske ger ett statistiskt säkerställt resultat, medan andra inte gör det. Det kan verka som en god idé att testa alla möjligheter. Men det är det inte, för med varje ytterligare test, ökar risken för falskt positivt resultat. Att söka ett lågt p-värde och sedan enbart presentera den analysen, kallas ofta för p-hacking. Det är som att kasta pil tills man träffar bullseye och sedan säga att man bara kastade den pilen som träffade mitt i prick. 
Det var precis så musikforskarna gjorde. De spelade olika låtar för tre deltagargrupper och samlade in massor av information om dem. Analysen som publicerades tog bara med två av de tre grupperna. Av all insamlad information, tog analysen bara med deltagarens fars ålder för att “kontrollera för baslinjevariationer i deltagarnas ålder.” De pausade också experimentet efter var tionde deltagare och fortsatte om p-värdet var högre än 0,05, men avbröt när det var lägre. De kunde se att de deltagare som hörde den ena låten var 1,5 år yngre än de som hörde den andra låten, med ett p-värde på 0,04. 
Det är oftast mycket svårare än så att upptäcka p-hacking eftersom vi inte vet att resultaten är omöjliga. Hela poängen med att utföra experiment är att lära sig nya saker. Som tur är, finns det ett enkelt sätt att göra p-värden mer tillförlitliga: Förregistrering av en plan för experimentet och analyserna på förhand, som andra kan granska, så att forskare inte kan byta analysmetod tills de får det önskade resultatet. Och i den sanna, vetenskapliga utforskningens anda, finns det ett nytt forskningsfält där vetenskapen vetenskapar sig själv: Studier av vetenskapliga metoder i syfte att förbättra dem. 
