Menschen sind lustig. Wir versuchen ständig, die Welt um uns herum zu verstehen und zu interpretieren. Ich lebe in einem Haus mit zwei schwarzen Katzen und wirklich, immer, wenn ich einen schwarzen, zusammengeballten Pullover sehe, denke ich, es sei eine Katze. 
Es sind nicht nur Dinge, die wir sehen. Manchmal schreiben wir mehr Intelligenz zu, als eigentlich vorhanden sein könnte. Vielleicht haben Sie die Hunde auf TikTok gesehen. Sie haben Tasten, auf denen „Gassi“ oder „Belohnung“ stehen. Sie können sie drücken, um mit ihren Besitzern zu kommunizieren und ihre Besitzer glauben, dass sie sie verwenden, um beeindruckende Dinge zu kommunizieren. Doch wissen die Hunde was sie sagen? 
Vielleicht haben Sie die Geschichte vom klugen Hans, dem Pferd, gehört. Er konnte rechnen. Nicht nur einfache Matheaufgaben, sondern wirklich komplizierte, wie: Wenn der achte Tag des Monats auf einen Dienstag fällt, welches Datum ist dann am darauffolgenden Freitag? Ziemlich beeindruckend für ein Pferd. Leider hat Hans nicht gerechnet, aber was er tat, war genauso beeindruckend. Hans hatte gelernt, die Leute im Raum zu beobachten, um zu erkennen, wann er mit dem Huf klopfen sollte. Also teilte er seine Antworten mit, indem er mit dem Huf tippte. Wenn Sie also die Antwort kennen, auf: “Wenn der achte Tag des Monats auf einen Dienstag fällt, welches Datum ist der darauffolgende Freitag?“, ändern Sie unbewusst Ihre Haltung, sobald das Pferd die richtigen 18 Schläge gegeben hat. Hans konnte also nicht rechnen, er hatte gelernt, die Leute im Raum zu beobachten, die rechnen konnten, was für ein Pferd immer noch ziemlich beeindruckend ist. Aber das ist ein altes Bild, und wir würden heute nicht auf Clever Hans reinfallen. Oder doch? 
Nun, ich arbeite in der KI, und ich kann Ihnen sagen, die Dinge sind verrückt. Es gab mehrere Beispiele dafür, dass Menschen davon überzeugt waren, dass KI sie versteht. Im Jahr 2022 dachte ein Google-Ingenieur, dass Googles KI empfindungsfähig sei. Vielleicht haben Sie ein wirklich menschliches Gespräch mit etwas wie ChatGPT geführt. Doch die Modelle, die wir heute trainieren, sind viel besser als die Modelle, die wir vor fünf Jahren hatten. Es ist wirklich bemerkenswert. 
Lassen Sie uns also in diesem superverrückten Moment die superverrückte Frage stellen: Versteht uns die KI oder erleben wir unseren eigenen Clever Hans-Moment? 
Manche Philosophen glauben, dass Computer Sprache niemals verstehen werden. Um dies zu veranschaulichen, entwickelten sie etwas, das sie das chinesische Raum-Argument nennen. Im chinesischen Raum gibt es eine hypothetische Person, die kein Chinesisch versteht, aber sie hat eine Reihe von Anweisungen bei sich, die ihm sagen, wie er auf Chinesisch auf jeden chinesischen Satz reagieren soll. So funktioniert das chinesische Zimmer: Ein Zettel kommt durch einen Schlitz in der Tür herein, auf dem etwas auf Chinesisch geschrieben steht. Die Person nutzt die Anweisungen, um herauszufinden, wie sie reagieren soll, schreibt die Antwort auf ein Blatt Papier und schickt sie durch die Tür zurück. Für jemanden, der Chinesisch spricht und vor diesem Raum steht, mag es so aussehen, als ob die Person im Raum Chinesisch spricht. Wir wissen jedoch, dass dies nicht der Fall ist, da keine Chinesischkenntnisse erforderlich sind, um den Anweisungen zu folgen. Die Durchführung dieser Aufgabe zeigt nicht, dass Sie Chinesisch sprechen. 
Was sagt uns das über KI? Nun, wenn Sie und ich außerhalb des Raums stehen, wenn wir mit einer dieser KIs wie ChatGPT sprechen, sind wir die Person, die außerhalb des Raums steht. Wir geben englische Sätze ein, wir bekommen englische Sätze zurück. Es sieht wirklich so aus, als würden uns die Models verstehen. Es sieht wirklich so aus, als ob sie Englisch sprechen. Doch in Wahrheit folgen diese Modelle nur einer Reihe von Anweisungen, wenn auch komplexe. Woher wissen wir, ob KI uns versteht? 
Um diese Frage zu beantworten, 
gehen wir zurück in das chinesische Zimmer. Sagen wir, wir haben zwei chinesische Zimmer. In dem einen ist jemand, der tatsächlich Chinesisch spricht, und in dem anderen Raum ist unser Betrüger. Bekommt die Person, die tatsächlich Chinesisch spricht, ein Blatt Papier auf dem etwas auf Chinesisch steht, kann sie es lesen, kein Problem. Aber bekommt unser Betrüger es wieder, muss er anhand der Anweisungen herausfinden, wie er reagieren soll. Von außen mag es unmöglich sein, diese beiden Räume zu unterscheiden, aber wir wissen, dass drinnen etwas ganz anderes passiert. Um das zu veranschaulichen, nehmen wir an, in den Köpfen unserer beiden Leute, in unseren beiden Räumen, befindet sich ein kleiner Notizblock. Alles, was sie sich merken müssen, um die Aufgabe zu erledigen, muss auf den Notizblock geschrieben werden. Könnten wir sehen, was auf dem Notizblock geschrieben steht, würden wir bemerken, wie unterschiedlich sie an die Aufgabe herangehen. Obwohl die Eingabe und die Ausgabe dieser beiden Räume genau dieselbe ist, ist der Prozess, von der Eingabe zur Ausgabe zu gelangen, völlig anders. 
Was sagt uns das über KI? Auch hier gilt: Wenn KI, selbst wenn sie einen völlig plausiblen Dialog generiert, Fragen so beantwortet, wie wir es erwarten, kann sie immernoch eine Art Betrüger sein. Wenn wir wissen wollen, ob KI Sprache so versteht wie wir, müssen wir wissen, was sie tut. Wir müssen reingehen, um zu sehen, was sie tut. Ist es ein Betrüger oder nicht? Wir müssen sein Notizblock sehen und in der Lage sein, es mit dem Notizblock von jemandem zu vergleichen, der Sprache tatsächlich versteht. Aber Notitzblöcke im Gehirn können wir nicht wirklich sehen, oder? 
Ja, wir können Notizblöcke in Gehirnen sehen. Mit etwas wie fMRT oder EEG können wir Schnappschüsse des Gehirns machen, während es liest. Leute lesen also Wörter oder Geschichten und wir machen Fotos von ihrem Gehirn. Diese Gehirnbilder sind verschwommene, unscharfe Bilder vom Notizblock des Gehirns. Sie zeigen uns ein wenig, wie das Gehirn Informationen verarbeitet und darstellt, beim Lesen. 
Hier sind drei Gehirnbilder, aufgenommen, während eine Person die Wörter „Wohnung“,  „Haus“ und „Sellerie“ las. Sie können mit bloßem Auge sehen, dass das Gehirnbild für „Wohnung“ und „Haus“ einander ähnlicher ist als das Gehirnbild für „Sellerie“. Sie wissen natürlich, dass Wohnungen und Häuser sich mehr ähneln als Sellerie, allein die Worte. Anders ausgedrückt: Das Gehirn verwendet seinen Notizblock, beim Lesen der Wörter „Wohnung“ und „Haus“ auf eine Weise, die ähnlicher ist als wenn Sie das Wort „Sellerie“ lesen. Der Notizblock zeigt uns ein wenig, wie das Gehirn die Sprache darstellt. Es ist kein perfektes Bild dessen, was das Gehirn tut, aber es ist gut genug. 
Wir haben also Notizblöcke für das Gehirn. Jetzt brauchen wir ein Notizblock für KI. In vielen KIs befindet sich ein neuronales Netzwerk. In einem neuronalen Netzwerk befindet sich ein Haufen kleiner Neuronen. Hier sind die Neuronen diese kleinen grauen Kreise. Wir wüssten gerne was der Notizblock eines neuronalen Netzwerks ist. Wenn wir ein Wort in ein neuronales Netzwerk eingeben, berechnet jedes der kleinen Neuronen eine Zahl, die ich hier mit Farben darstelle. Jedes Neuron berechnet also diese Zahl, und die Zahlen sagen uns etwas darüber, wie das neuronale Netzwerk Sprache verarbeitet. Zusammengenommen zeichnen uns all diese Kreise ein Bild davon, wie das neuronale Netzwerk Sprache darstellt, und zeigen uns den Notizblock des neuronalen Netzwerks. 
Wunderbar. Jetzt haben wir zwei Notizblöcke, eines aus dem Gehirn und eines aus der KI. Wir wollen wissen: Macht KI so etwas wie das Gehirn? Wie können wir das testen? 
Folgendes haben sich Forscher ausgedacht. Wir trainieren ein neues Modell. Das neue Modell sieht sich die Notizen neuronaler Netzwerke für ein bestimmtes Wort an und versucht, die Notizen im Gehirn für dasselbe Wort vorherzusagen. Wir können es übrigens für zwei machen. Also trainieren wir ein neues Modell. Es sucht auf dem Notizblock des neuronalen Netzwerks nach einem Wort und versucht, die Notiz des Gehirns vorherzusagen. Wenn das Gehirn und die KI nichts gleich machen, nichts gemeinsam haben, können wir die Vorhersageaufgabe nicht bewältigen. Wir können nicht das eine vom anderen vorhrsagen. 
Wir sind an einer Weggabelung angelangt und Sie wissen vermutlich, dass ich Ihnen eins von zwei Dingen sagen werde. Ich sage, dass KI fantastisch ist, oder ich sage, dass KI ein Betrug ist. Forscher wie ich erinnern Sie gerne daran, dass KI nichts mit dem Gehirn zu tun hat. Und das stimmt. Aber könnte es sein, dass die KI  und das Gehirn etwas gemeinsam haben? 
Wir haben diese Aufgabe zur Vorhersage von Notizen gemacht und in 75 Prozent ist der vorhergesagte neuronale Netzwerk-Notizblock, für ein bestimmtes Wort, dem echten neuronalen Netzwerk-Notitzblock für dieses Wort ähnlicher als dem neuronalen Netzwerk-Notizblock für ein anderes zufällig ausgewähltes Wort — 75 Prozent sind viel besser als Zufall. Was ist mit komplizierteren Dingen, nicht nur Wörter, sondern Sätze oder Geschichten? Auch diese Vorhersage funktioniert. Wir können Notizen im neuronalen Netzwerk vom Gehirn aus vorhersagen und umgekehrt. Unglaublich. Bedeutet das also, dass neuronale Netzwerke und KI Sprache genauso verstehen wie wir? Ehrlich gesagt, nein. Obwohl die Notizblock-Vorhersageaufgaben eine Genauigkeit aufweisen, die über der Wahrscheinlichkeit liegt, sind die zugrunde liegenden Korrelationen immer noch schwach. Obwohl neuronale Netzwerke vom Gehirn inspiriert sind, haben sie nicht die gleiche Struktur und Komplexität, die wir im Gehirn sehen. Neuronale Netzwerke gibt es auch nicht auf der Welt. Ein neuronales Netzwerk hat noch nie eine Tür geöffnet, einen Sonnenuntergang gesehen oder ein Baby weinen gehört. Kann ein neuronales Netzwerk,  das auf der Welt nicht existiert die Welt nicht wirklich erlebt hat, Sprache über die Welt verstehen? 
Trotzdem haben sich Experimente zur Vorhersage von Notizblöcken gehalten — mehrere Experimente zur Bildgebung des Gehirns, mehrere neuronale Netzwerke. Wir fanden heraus, dass die neuronalen Netzwerke, je genauer sie werden, auch anfangen, ihr Notizblock so zu verwenden, dass es hirnähnlicher wird. Es ist nicht nur Sprache. Wir haben ähnliche Ergebnisse bei Navigation und Vision erzielt. 
KI macht also nicht genau das, was das Gehirn tut, aber sie ist auch nicht völlig zufällig. Wenn wir also von meinem Standpunkt aus wissen wollen, ob KI Sprache wirklich so versteht wie wir, müssen wir in den chinesischen Raum gehen. Wir müssen wissen, was die KI tut, und wir müssen es mit dem vergleichen können, was Menschen tun, wenn sie Sprache verstehen. 
KI bewegt sich so schnell. Heute frage ich Sie, ob KI Sprache versteht. Das könnte in zehn Jahren wie eine dumme Frage erscheinen. Oder in zehn Monaten. 
(Lachen) 
Aber eines bleibt wahr. Wir sind bedeutungsstiftende Menschen, wir werden weiterhin nach Sinn suchen und die Welt um uns herum interpretieren. Wir müssen uns daran erinnern, dass es sehr leicht ist, sich täuschen zu lassen, wenn wir uns nur die Eingabe und Ausgabe von KI ansehen. Wir müssen in den metaphorischen Raum der KI gelangen, um zu sehen, was passiert. Es ist was darin ist, das zählt. 
Danke. 
(Applaus) 
