La gente es graciosa. Constantemente tratamos  de entender e interpretar el mundo que nos rodea. Vivo en una casa con dos gatos negros, y déjenme decirles, cada vez que un sweater negro descartado se interpone a mi visión, creo que es un gato. 
No se trata solamente de lo que vemos. A menudo atribuimos más inteligencia de la que en realidad existe. Quizá vieron los perros de TikTok. Tienen estos pequeños botones que dicen cosas como “caminar” o “recompensa”. Pueden presionarlos para comunicarse con sus dueños, y los dueños creen que ellos lo usan para comunicar cosas impresionantes. ¿Pero los perros saben lo que dicen? 
O quizá escucharon la historia del caballo Sabio Hans, que sabía sobre matemáticas. No solo sobre problemas matemáticos, sino problemas realmente complicados, como “si el octavo día del mes cae martes, ¿cuál es la fecha del siguiente viernes?“. Impresionante para ser un caballo. Desafortunadamente, Hans no resolvía problemas matemáticos, pero lo que hacía era igual de impresionante. Hans había aprendido a observar a la gente de la sala para determinar cuándo debía  agitar su pezuña. Así que comunicaba sus respuestas agitando su pezuña. Sucede que si sabes cuál es la respuesta a ”si el octavo día del mes cae martes, ¿cuál es la fecha del siguiente viernes?“ inconscientemente cambiarás tu postura una vez que el caballo haya agitado la pezuña 18 veces. Hans no sabía sobre matemáticas, pero había aprendido a observar a quienes sí sabían sobre matemáticas, lo cual sigue siendo impresionante para un caballo. Pero esto es algo desactualizado, y hoy no caeríamos ante el Sabio Hans. ¿O sí? 
Bueno, yo trabajo con la IA, y déjenme decirles, las cosas son bravas. Ha habido múltiples ejemplos sobre personas completamente convencidas de que la IA las entendía. En 2022, un ingeniero de Google pensó que la IA de Google tenía sentimientos. Y quizá hayan tenido una conversación muy humana con algo como ChatGPT. Pero los modelos que entrenamos hoy son mucho mejores que los que teníamos incluso cinco años atrás. Es algo destacable. 
Así que en esta época tan llamativa, hagámonos la pregunta más llamativa: ¿La IA nos entiende, o nos estamos comportando como el Sabio Hans? 
Según algunos filósofos, las computadoras nunca entenderán el lenguaje. Para ilustrar esto, desarrollaron algo a lo que llamaron “la habitación china”. En esta habitación china, hay una persona, una persona hipotética, que no entiende chino, pero que cuenta con una serie de instrucciones que le indican cómo responder en chino a cualquier oración en chino. Así es como funciona la habitación china. Ingresa un papel  por una ranura de la puerta, tiene algo escrito en chino. La persona usa las instrucciones para ver cómo responder. Escribe la respuesta en un trozo de papel y luego la envía de nuevo por la puerta. A alguien que habla chino, que está detrás de la puerta, le parecerá que la persona dentro habla chino. Pero nosotros sabemos que no, porque no se necesita saber chino para seguir las instrucciones. Tu desenvolvimiento en esta tarea no prueba que sepas chino. 
¿Qué nos dice esto sobre la IA? Bueno, cuando tú y yo nos situamos fuera de la sala, cuando hablamos con una IA como ChatGPT, somos la persona que se ubica fuera de la sala. La alimentamos con oraciones en inglés, y obtenemos de vuelta oraciones en inglés. Parece que el modelo nos entiende. Parece que sabe inglés. Pero en realidad estos modelos están siguiendo una compleja serie de instrucciones. ¿Cómo sabemos si la IA nos entiende? 
Para responder esa pregunta, volvamos a la habitación china. Digamos que tenemos dos habitaciones. En una habitación china hay alguien que realmente habla chino, y en la otra está nuestra impostora. Cuando la persona que habla chino recibe el papel que dice algo en chino, puede leerlo, sin problemas. Pero cuando la recibe el impostor, tiene que recurrir a las instrucciones para responder. Desde fuera, puede parecer imposible distinguir entre ambas habitaciones, pero sabemos que en el interior están ocurriendo cosas diferentes. Para ilustrar eso, digamos que dentro de las mentes de nuestras dos personas, dentro de nuestras dos habitaciones, hay un bloc de notas. Y todo lo que deben recordar para resolver esta tarea tiene que ser escrito en ese bloc de notas. Si pudiéramos ver lo que escriben en el bloc de notas, podríamos determinar qué tan distinto se comportan ambos. Entonces, aunque la tarea y el resultado de ambas habitaciones sean idénticos, el proceso por el cual se llega  al resultado puede ser diferente. 
De nuevo, ¿qué nos dice esto sobre la IA? Insisto, incluso si la IA genera diálogos plausibles, responde preguntas tal como esperamos, podría seguir siendo una impostora. Si queremos saber si la IA comprende el lenguaje como nosotros, tenemos que saber qué está haciendo. Debemos contemplar su interior para ver qué está haciendo. ¿Es una impostora o no? Debemos ver su bloc de notas, y compararlo con el bloc de notas de alguien que sí comprende el lenguaje. Pero al igual que los blocs del cerebro, no son algo que podamos ver, ¿verdad? 
Bueno, resulta que sí podemos observar esos blocs en el cerebro. Utilizando algo como IRMf o EEG, podemos obtener pequeñas instantáneas del cerebro mientras está leyendo. Alguien lee palabras o historias y luego toma una foto de su cerebro. Y esas imágenes del cerebro son borrosas, son imágenes difusas  del bloc de notas del cerebro. Informan sobre cómo el cerebro procesa y representa la información al leer. 
Aquí hay tres imágenes del cerebro tomadas mientras una persona leía “apartamento”, “casa” y “apio”. Se puede observar que las imágenes correspondientes a “apartamento” y “casa” se parecen más entre sí que lo que se parecen con “apio”. Obviamente los apartamentos y las casas son más parecidos entre sí que con el apio. En otras palabras, el cerebro usa su bloc de notas al leer “apartamento” y “casa” de manera más parecida que al leer “apio”. El bloc de notas nos dice algo sobre cómo el cerebro representa el lenguaje. No es una imagen perfecta, pero es buena. 
Bueno, contamos con un bloc de notas para el cerebro. Ahora necesitamos uno para la IA. Dentro de muchas IAs hay redes neuronales. Y dentro de cada red neuronal se encuentran pequeñas neuronas. Estas neuronas son como  pequeños círculos grises. Y lo que queremos conocer es el bloc de notas de una red neuronal. Bueno, cuando ingresamos una palabra en una red neuronal, cada una de estas neuronas computa un número. Represento aquí esos números con colores. Cada neurona computa  este pequeño número, y todos esos números nos dicen algo sobre cómo la red neuronal procesa el lenguaje. En conjunto, estos círculos constituyen una imagen sobre cómo la red neuronal representa el lenguaje, y proporcionan el bloc de notas de la red neuronal. 
Bien. Ahora tenemos dos blocs, uno del cerebro y otro de la IA. Lo que queremos saber es: ¿la IA hace algo similar al cerebro? ¿Cómo lo comprobamos? 
Esto es lo que dicen los investigadores. Vamos a entrenar un nuevo modelo. Este nuevo modelo observará el bloc de notas de una red neuronal para una palabra específica y tratará de predecir el bloc del cerebro para esa misma palabra. Podemos hacerlo con dos. Entrenemos un nuevo modelo. Observará el bloc de la red neuronal para una palabra específica y tratará de predecir el del cerebro. Si el cerebro y la IA no hacen lo mismo, si no tienen nada en común, no podrá realizar la predicción. No será posible predecir uno a partir de otro. 
Llegado este punto, probablemente se dieron cuenta de que voy a decirles una cosa de dos. Voy a decirles que la IA es increíble, o voy a decirles que la IA  es una impostora. A los investigadores como yo nos gusta recordarles que la IA no se parece al cerebro. Y eso es cierto. ¿Pero no podrían tener algo en común? 
Hicimos esta prueba de predicción y resulta que el 75 % de las veces la predicción del bloc de una red neuronal para una palabra específica se parece más al verdadero bloc de la red para esa palabra que al bloc de la red neuronal para otra palabra escogida al azar... 75 % es una gran posibilidad. ¿Qué pasa con cosas más complicadas, no solo palabras, sino frases, incluso historias? De nuevo, esta predicción del bloc funciona. Podemos predecir el bloc de la red desde el cerebro y viceversa. Increíble. ¿Eso significa que las redes neuronales y la IA comprenden el lenguaje como nosotros? Bueno, realmente no. Si bien estas predicciones de blocs demuestran buenos resultados, las correlaciones subyacentes son débiles. Y si bien las redes neuronales están inspiradas en el cerebro, no tienen la misma estructura ni complejidad del cerebro. Las redes neuronales  tampoco existen en el mundo. Una red neuronal nunca abrió una puerta, ni vio el amanecer, ni oyó el llanto de un bebé. ¿Una red neuronal que no existe en el mundo, que no ha experimentado el mundo, puede entender el lenguaje sobre el mundo? 
Estos experimentos de predicciones de blocs han sostenido muchos experimentos sobre imágenes cerebrales, sobre redes neuronales. También nos dimos cuenta de que a medida que la redes mejoran, comienzan a usar sus blocs de manera más parecida a la del cerebro. Y no se trata solo del lenguaje. Hay resultados similares en la navegación y la visión. 
La IA no sabe exactamente lo que hace el cerebro, pero tampoco es algo  completamente al azar. Así que desde mi perspectiva, si queremos saber si la IA comprende el lenguaje como nosotros, necesitamos ingresar en la habitación china. Necesitamos saber lo que hace la IA, y necesitamos compararlo con lo que hace la gente cuando comprende el lenguaje. 
La IA avanza muy rápido. Hoy les pregunto si la IA comprende el lenguaje, y en diez años será una pregunta tonta. O en diez meses. 
(Risas) 
Pero algo seguirá siendo cierto. Nosotros construimos significados, y como humanos lo seguiremos haciendo y seguiremos interpretando el mundo. Y necesitaremos recordar que si solamente observamos  lo que ingresa y sale en la IA, es muy fácil ser engañado. Necesitamos entrar en la sala metafórica de la IA para observar lo que sucede. Lo de dentro es lo que importa. 
Gracias. 
(Aplausos) 
