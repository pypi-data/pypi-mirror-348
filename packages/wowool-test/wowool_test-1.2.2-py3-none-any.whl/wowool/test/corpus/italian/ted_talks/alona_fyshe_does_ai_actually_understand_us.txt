Le persone sono strane. Cerchiamo costantemente di capire  e interpretare il mondo intorno a noi. Vivo in una casa con due gatti neri e vi dico questo, ogni volta che con la coda dell’occhio  vedo una felpa nera arrotolata penso sia un gatto. 
Non capita solo con le cose che vediamo. A volte attribuiamo alle cose  più  intelligenza di quanta ne abbiano in realtà. Forse avete visto dei cani su TikTok che hanno questi piccoli pulsanti che dicono cose come “walk” o “treat.” Possono premerli per comunicare con i loro padroni, e i loro padroni pensano che li usino per comunicare cose davvero notevoli. Ma i cani capiscono  quello che stanno dicendo? 
Forse avete sentito la storia del cavallo Hans l’Intelligente, che sapeva fare i calcoli. Non solo problemi semplici di matematica, ma anche quelli molto complicati, per esempio, se l’ottavo giorno del mese cade di martedì qual è la data del venerdì successivo? È veramente notevole per un cavallo. Sfortunatamente, Hans non faceva i calcoli, quello che faceva, però, era egualmente notevole. Hans aveva imparato a osservare le persone nella stanza per capire quando battere con lo zoccolo. Comunicava le risposte  battendo con lo zoccolo. Si è capito che se sai la risposta a “se l’ottavo giorno del mese è un martedì qual è la data del venerdì successivo” cambierai la tua postura subconsciamente una volta che il cavallo avrà  correttamente battuto 18 volte. Hans non sapeva fare i calcoli, ma aveva imparato a osservare le persone nella stanza che sapevano farlo, cosa comunque notevole per un cavallo. Ma questa è una vecchia storia e oggi non ci faremmo ingannare da Hans l’Intelligente. O mi sbaglio? 
Comunque, io mi occupo di IA, e lasciate che ve lo dica,  ci sono situazioni folli. Ci sono stati vari esempi di persone che erano davvero convinte che l’IA le capisse. Nel 2022, un ingegnere di Google suppose che l’IA di Google fosse senziente. E forse avete avuto  conversazioni molto umane con qualcosa come ChatGPT. Ma i modelli che addestriamo oggi sono di gran lunga migliori dei modelli che avevamo cinque anni fa. È veramente straordinario. 
Quindi in questo momento super folle, facciamoci una domanda folle: L’IA ci capisce, o stiamo rivivendo la storia di Hans l’Intelligente? 
Alcuni filosofi pensano che i computer non comprenderanno mai il linguaggio. Per capire meglio, hanno sviluppato  l’esperimento mentale della Stanza cinese. Nella stanza cinese c’è una persona, un’ipotetica persona, che non capisce il cinese, ma che ha con sé una serie di istruzioni che le dicono come rispondere in cinese a qualsiasi frase cinese. Ecco come funziona. Un foglio di carta entra attraverso una fessura nella porta e ha sopra scritto qualcosa in cinese. La persona usa le istruzioni  per capire come rispondere, scrive la risposta su un foglio e lo rimanda indietro attraverso la porta. Per qualcuno che parli cinese, fuori dalla stanza, potrebbe sembrare che la persona  all’interno parli cinese. Ma noi sappiamo che non è così. Perché non serve conoscere il cinese per seguire delle istruzioni. L’esecuzione di questo compito non dimostra che si conosce il cinese. 
E questo cosa ci dice sull’IA? Beh, quando io e voi  siamo fuori dalla stanza, quando noi parliamo con una  di queste IA come ChatGPT, siamo noi la persona fuori dalla stanza. Inseriamo frasi in inglese e riceviamo risposte in inglese. Sembra davvero che i modelli ci capiscano. Sembra davvero che conoscano l’inglese. Ma in realtà, questi modelli stanno solo seguendo  una serie di istruzioni, benché complesse. Come facciamo a sapere se l’IA ci capisce? 
Per rispondere torniamo alla Stanza cinese. Mettiamo di avere due Stanze cinesi. In una c’è qualcuno che parla davvero cinese e nell’altra c’è il nostro impostore. Quando la persona che parla davvero cinese riceve un foglio con qualcosa in cinese, riesce a leggerlo senza problemi. Quando è il nostro impostore a riceverlo, deve usare le istruzioni per capire come rispondere. Da fuori sembra impossibile  distinguere le due stanze, ma noi sappiamo che all’interno  accadono due cose molto diverse. Per spiegarlo, immaginiamo che nella mente  delle nostre due persone, nelle due stanze,  ci sia un blocchetto. Tutto quello che devono ricordarsi per eseguire questo compito deve essere scritto in questo blocchetto. Se potessimo vedere cosa è scritto in quel blocchetto, riusciremmo a capire quanto siano diversi i loro approcci al compito. Quindi, anche se l’input e l’output delle due stanze sono identici, il processo che porta dall’input all’output è completamente diverso. 
Quindi, questo cosa ci dice sull’IA? Anche se l’IA genera dialoghi estremamente plausibili e risponde alle domande proprio come ci aspetteremmo, potrebbe comunque essere  una sorta di impostore. Se vogliamo sapere se l’IA capisce il linguaggio come noi, dobbiamo sapere cosa sta facendo. Dobbiamo entrare e vedere cosa sta facendo. È o no un impostore? Dobbiamo vedere il suo blocchetto e confrontarlo con quello di qualcuno che capisce davvero la lingua. Ma come i blocchetti nel cervello, non è qualcosa che possiamo  davvero vedere, no? 
Si è scoperto che possiamo in qualche modo vedere i blocchetti nei cervelli. Usando la fMRI o l’EEG, possiamo fare delle istantanee del cervello mentre sta leggendo. Facciamo foto ai cervelli delle persone mentre leggono parole o storie. Quelle sono immagini mosse, fuori fuoco dei blocchetti del cervello. Ci mostrano come il cervello elabora e rappresenta le informazioni mentre leggi. 
Qui vedete tre immagini del cervello 
registrate mentre una persona leggeva le parole <i>appartamento</i>, <i>casa</i> e <i>sedano</i>. Potete vedere a occhio nudo che le immagini per <i>appartamento </i>e <i>casa</i> sono molto più simili tra loro di quanto lo siano con l’immagine per <i>sedano</i>. E voi sapete che appartamenti e case  sono più simili tra loro di quanto lo siano con un sedano,  solo le parole. Detto diversamente, quando leggiamo <i>appartamento </i>e <i>casa</i> il cervello usa il blocchetto in un modo più simile di quando leggiamo la parola <i>sedano</i>. Il blocchetto ci dice qualcosa in più su come il cervello rappresenta la lingua. Non è una rappresentazione perfetta di cosa fa il cervello, ma è sufficiente. 
Ok, quindi abbiamo  un blocchetto per il cervello. Adesso ci serve un blocchetto per l’IA. All’interno di molte IA c’è una rete neurale. E all’interno della rete neurale ci sono tanti di questi piccoli neuroni. Qui nell’immagini i neuroni sono questi piccoli cerchi grigi. Noi vorremmo sapere: qual è il blocchetto della rete neurale? Quando inseriamo una parola in una rete neurale, ogni piccolo neurone calcola un numero. Li rappresento qui come colori. Quindi, ogni neurone calcola un numero. E quei numeri ci dicono qualcosa su come la rete neurale elabora la lingua. Tutti i piccoli cerchi insieme ci mostrano come la reta neurale rappresenta la lingua e ci mostrano il blocchetto della rete neurale. 
Bene, adesso abbiamo due blocchetti, uno del cervello e uno dell’IA 
e vogliamo sapere: l’IA fa qualcosa di simile  a quello che fa il cervello? Come lo verifichiamo? 
Ecco cosa hanno scoperto i ricercatori. Dobbiamo addestrare un nuovo modello. Questo nuovo modello cercherà nel blocchetto della rete neurale una parola specifica e cercherà di prevedere il blocchetto del cervello per la stessa parola. Possiamo anche fare il contrario. Quindi addestriamo un nuovo modello, che guardando una parola specifica nel blocchetto della rete neurale cercherà di prevedere  il blocchetto del cervello. Se il cervello e l’IA non fanno nulla allo stesso modo, se non hanno niente in comune, non sarà possibile fare questa previsione. Non sarà possibile prevedere  uno partendo dall’altro. 
Abbiamo raggiunto un bivio e, come potete immaginare,  vi sto per dire una delle due cose: o che l’IA è fantastica o che l’IA è un impostore. I ricercatori come me amano ricordarvi che l’IA non è come il cervello. Ed è vero. Ma non potrebbe anche essere che l’IA e il cervello abbiano qualcosa in comune? 
Abbiamo quindi fatto questa previsione del blocchetto, e il 75% delle volte il blocchetto della rete neurale previsto per una specifica parola è più simile al vero blocchetto della rete neurale per quella parola che al blocchetto della rete neurale per un’altra parola casuale. E il 75% è molto meglio del semplice caso. Cosa succede per cose più complicate, non semplici parole, ma frasi o addirittura storie? Anche in questo caso la previsione del blocchetto funziona. Possiamo prevedere il blocchetto di una rete neurale dal cervello e viceversa. Incredibile. Questo significa che reti le neurali e l’IA capiscono il linguaggio come noi? In realtà no. Sebbene queste previsioni del blocchetto mostrino un’accuratezza superiore al caso, le correlazioni sottostanti sono ancora piuttosto deboli. E sebbene le reti neurali si ispirino al cervello, non hanno lo stesso tipo di struttura e complessità che vediamo nel cervello. E poi le reti neurali non esistono nel mondo. Una rete neurale non ha mai aperto una porta né visto un tramonto, o sentito  il pianto di un bambino. Può una rete neurale, che non esiste nel mondo e che non ne ha esperienza, capire davvero il linguaggio  che descrive il mondo? 
Comunque, questi esperimenti  di previsione sono continuati: molteplici esperimenti di imaging cerebrale, molteplici reti neurali. E abbiamo scoperto che quando le reti neurali diventano più accurate, iniziano a usare il loro blocchetto in modo più simile al cervello. Non solo in ambito linguistico. Ci sono risultati simili nella navigazione e nella visione. 
Quindi l’IA non fa esattamente quello che fa il cervello, ma non è neanche del tutto casuale. Dal mio punto di vista, se vogliamo sapere se l’IA capisce davvero il linguaggio come lo capiamo noi, dobbiamo entrare nella Stanza cinese. Dobbiamo poter sapere cosa fa l’IA e poterlo confrontare con quello che le persone fanno quando comprendono il linguaggio. 
L’IA si sviluppa rapidamente. Oggi vi sto chiedendo se l’IA comprende il linguaggio, ma potrà essere una domanda sciocca tra dieci anni o anche solo dieci mesi. 
(Risate) 
Ma una cosa rimarrà vera. Noi umani interpretiamo gli eventi e continueremo sempre a cercare il significato e a interpretare il mondo che ci circonda. E dovremo sempre tenere a mente che se guardiamo solo l’input e l’output dell’IA sarà facile essere ingannati. Dobbiamo entrare nella metaforica stanza dell’IA per vedere cosa sta succedendo. È quello che c’è dentro che conta. 
Grazie. 
(Applausi) 
