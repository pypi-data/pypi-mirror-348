Les gens sont drôles. Nous cherchons constamment à comprendre et interpréter le monde qui nous entoure. Je vis dans une maison avec deux chats noirs, et j’avoue que chaque fois que j’aperçois un pull noir enroulé quelque part, je pense que c'est un chat. 
Les apparences sont trompeuses. Parfois, nous attribuons plus d’intelligence qu’il n’y en a réellement. Les chiens sur TikTok, par exemple. On a inscrit sur des petits boutons : « marche » ou « friandise ». Les chiens les poussent pour communiquer avec leur maître. Ceux-ci pensent que leur chien les utilise pour communiquer des choses impressionnantes. Mais les chiens savent-ils ce qu’ils disent ? 
Ou peut-être connaissez-vous l’histoire de Clever Hans, le cheval, qui savait calculer. Pas seulement des problèmes simples, mais aussi des choses compliquées, par exemple, si le huitième jour du mois tombe un mardi, quelle est la date du vendredi suivant ? C’est impressionnant pour un cheval. Hélas, Hans ne faisait pas des mathématiques, mais ce qu'il faisait était tout aussi impressionnant. Hans avait appris à observer les personnes présentes pour savoir quand il devait taper avec son sabot. Il communiquait ses réponses en tapant sur son sabot. En fait, si vous connaissiez la réponse à : « si le huitième jour du mois tombe un mardi, quelle est la date du vendredi suivant ? », vous changerez inconsciemment de posture une fois que le cheval avait tapé 18 fois. Hans ne savait donc pas faire des calculs, mais il avait appris à observer les personnes qui savaient calculer. Et ça, c’est quand-même impressionnant pour un cheval. C’est une vieille photo, et nous ne nous laisserions plus avoir par Clever Hans de nos jours. Quoi que... 
Je travaille dans le domaine de l’IA, et sincèrement, c’est hallucinant. Il existe de nombreux exemples où les personnes sont totalement convaincues que l'IA les comprend. En 2022, un ingénieur de Google pensait que l’IA de Google ressentait les émotions. Vous avez peut-être eu une conversation vraiment humaine avec ChatGPT ou une IA similaire. Mais les systèmes d’aujourd’hui sont bien meilleurs que ceux que nous avions il y a cinq ans. C'est vraiment remarquable. 
Alors, à cette époque absolument hallucinante, posons-nous la question la plus folle : L’IA nous comprend-elle, ou sommes-nous en train de revisiter Clever Hans ? 
Selon certains philosophes, 
les ordinateurs ne comprendront jamais le langage. Pour illustrer ça, ils ont développé ce qu’ils ont appelé : « la chambre chinoise. » Dans la chambre chinoise, il y une personne hypothétique, qui ne comprend pas le chinois, mais qui dispose d’un ensemble d’instructions qui lui indiquent comment répondre en chinois à n’importe quelle phrase en chinois. Voici comment ça fonctionne. On insère une feuille de papier par une fente, et il y a quelque chose d’écrit dessus, en chinois. La personne utilise ses instructions pour produire sa réponse. Il écrit la réponse sur une feuille et il rend sa réponse de l’autre côté de la porte. Pour un sinophone à l’extérieur de cette chambre, il semble que la personne à l’intérieur de la pièce parle chinois. Or nous savons que ce n’est pas le cas, car aucune connaissance du chinois n’est requise pour suivre les règles. Les résultats ne sont pas significatifs de notre connaissance du chinois. 
Qu’est-ce que cela nous dit sur l’IA ? Eh bien, lorsque vous et moi sommes à l’extérieur de la chambre, lorsque nous parlons à l’une de ces IA comme ChatGPT, nous sommes la personne à l’extérieur. Nous alimentons en phrases en anglais, nous recevons des phrases en anglais. On dirait vraiment que les systèmes nous comprennent/ On dirait vraiment qu’ils connaissent l’anglais. Mais sous le capot, ces modèles ne suivent finalement qu’un ensemble de règles, quoique complexes. Comment savoir si l'IA nous comprend ? 
Pour répondre à cette question, revenons à la chambre chinoise. Imaginons avoir deux chambres chinoises. Dans une pièce chinoise se trouve quelqu'un qui parle réellement chinois, et dans l’autre pièce, se trouve notre imposteur. Lorsque la personne sinophone reçoit une feuille sur laquelle est écrit quelque chose en chinois, elle peut le lire, on est cool. Mais quand c’est notre imposteur il doit utiliser ses instructions pour produire sa réponse. De l’extérieur, il est certes impossible de distinguer ces deux chambres, mais nous savons qu’il s’y passe quelque chose de totalement différent. Pour illustrer cela, imaginons que dans l’esprit de nos deux personnes, à l’intérieur de nos deux chambres, se trouve un bloc-notes sur lequel se trouve tout ce dont ils ont besoin pour accomplir cette tâche. Si nous pouvions voir ce qui était écrit sur ce bloc-notes, nous pourrions constater à quel point leur approche est différente. Même si les entrants et les sortants es deux chambres sont identiques, le processus pour passer de l'entrée à la sortie est complètement différent. 
À nouveau, qu’est-ce que ça nous dit sur l’IA ? Encore une fois, si l’IA, même en générant un dialogue tout à fait plausible, en répondant aux questions selon nos attentes, elle peut tout de même être un imposteur. Si nous voulons savoir si l'IA comprend le langage comme nous, nous devons savoir ce qu'elle fait. Nous devons entrer dans la chambre. Est-ce un imposteur, ou pas ? Nous avons besoin de voir son bloc-notes et de le comparer au bloc-notes de celui qui comprend réellement la langue. Mais comme des blocs-notes dans le cerveau, on n’y a pas accès. 
Eh bien, il s’avère que nous pouvons accéder aux blocs-notes du cerveau. Avec des équipements comme l’IRMf ou l’EEG, nous pouvons prendre une sorte de photos du cerveau pendant qu’il lit. On demande à des gens de lire des mots ou des histoires et on prend des photos de leur cerveau. Et ces images cérébrales sont comme des images floues du bloc-notes de notre cerveau. Elles nous en disent un peu plus sur la façon dont le cerveau traite et représente l’information pendant qu’on la lit. 
Voici trois images cérébrales prises pendant la lecture des mots : « appartement », « maison » et « céleri ». On peut observer à l’œil nu que les images pour « appartement » et « maison » se ressemblent davantage qu’elles ne sont similaires à « céleri ». Nous savons tous qu’un appartement et une maison sont plus proches qu’ils ne le sont du céleri. Autrement dit, le cerveau utilise son propre bloc-notes pour lire les mots « appartement » et « maison » d’une manière plus similaire que dans la lecture de « céleri ». Le bloc-notes nous en dit un peu plus sur notre représentation mentale de la langue. Ce n’est pas une image parfaite de ce que fait le cerveau, mais c’est suffisant. 
Nous avons donc des blocs-notes pour le cerveau. Nous avons maintenant besoin d’un bloc-notes pour l’IA. On trouve un réseau neuronal dans de nombreuses IA. Et à l’intérieur de ce réseau neuronal, on a un tas de petits neurones. Ici, les neurones sont représentés par les cercles gris. Et nous souhaitons savoir quel est le bloc-notes du réseau neuronal. Eh bien, lorsque nous  encodons un mot dans un réseau neuronal, chacun des petits neurones calcule un nombre. Ce sont les petits chiffres représentés avec des couleurs. Chaque neurone calcule donc ce petit nombre, et ces nombres nous renseignent sur la façon dont le réseau neuronal traite le langage. Pris ensemble, tous ces petits cercles nous brossent un tableau comment le réseau neuronal représente le langage et nous donnent le bloc-notes du réseau neuronal. 
OK, super. Nous avons deux blocs-notes, celui du cerveau et celui de l’IA. Et nous voulons savoir si l’IA fait quelque chose d’identique au cerveau. Comment tester cela ? 
Voici le protocole des chercheurs : Nous allons entraîner un nouveau modèle, qui va ensuite examiner le bloc-notes du réseau neuronal pour un mot en particulier, et essayer de prédire le bloc-notes du cerveau pour le même mot. On peut le faire, d’ailleurs, autour de deux. Donc, on entraîne notre nouveau modèle. Il va observer le bloc-notes du réseau neuronal pour un mot précis et tenter de prédire celui du cerveau. Si le cerveau et l’IA n’ont rien en commun, cette prédiction ne sera pas possible. Il ne sera pas possible de prédire l’un au départ de l’autre. 
Nous sommes donc à un carrefour. Vous devinez sans doute que je vais vous dire l’une des deux choses suivantes. Soit, je vous dis que l’IA est incroyable, soit je vous dis que l’IA est un imposteur. Les chercheurs comme moi adorent rappeler que l'IA n'a rien à voir avec le cerveau. Et c'est vrai. Mais se pourrait-il que l’IA et le cerveau aient néanmoins quelque chose en commun ? 
On a fait tourner notre test de prédiction et il s'avère que 75 % du temps, le bloc-notes du réseau neuronal prédit pour un mot précis ressemble davantage au bloc-notes du [cerveau] pour ce mot qu’au bloc-notes du réseau de neuronal pour un autre mot choisi au hasard. 75 %, c'est bien mieux que le hasard. Qu’en est-il des choses plus compliquées que des mots : des phrases ou des histoires ? Encore une fois, notre test de prédiction fonctionne. Nous pouvons prédire le bloc-notes du réseau neuronal à partir du cerveau, et vice versa. C’est incroyable. Cela signifie-t-il que les réseaux de neuronaux et l’IA comprennent le langage comme nous ? Eh bien, à vrai dire, non. Bien que ces prédictions soient d’une précision supérieure au hasard, les corrélations sous-jacentes restent assez faibles. Certes, les réseaux neuronaux sont inspirés par le cerveau, mais ils n’ont pas la même structure et complexité que le cerveau. Les réseaux neuronaux n’existent pas non plus dans le monde. Un réseau neuronal n’a jamais ouvert de porte, admiré un coucher de soleil, entendu un bébé pleurer. Un réseau de neurones qui n’a pas de vie dans le monde, n’en a pas fait son expérience. peut-il vraiment comprendre le langage du monde ? 
Pourtant, ces expériences de prédiction ont résisté à de multiples expériences d’imagerie cérébrale, de multiples réseaux neuronaux. De plus, à mesure que les réseaux neuronaux deviennent plus précis, ils utilisent leur bloc-notes d’une manière qui se rapproche de celle du cerveau. Il n’y pas que le langage. Nous constatons des résultats similaires en termes de navigation et de vision. 
L'IA ne fait donc pas exactement ce que fait le cerveau, mais ce n’est pas non plus complètement aléatoire. Donc, de mon point de vue, si nous voulons savoir si l’IA comprend vraiment le langage comme nous, nous devons entrer dans la salle chinoise. Nous devons savoir ce que fait l'IA, et nous devons être en mesure  de comparer cela à ce que font les gens lorsqu’ils comprennent une langue. 
L'IA évolue si vite. Aujourd’hui, la question de savoir si l’IA comprend un langage pourra sembler stupide dans dix ans. Ou dix mois. 
(Rires) 
Mais une chose restera vraie. Les humains sont des créatures de sens, et nous continuerons à chercher un sens et à interpréter notre monde. Nous devons nous rappeler que sur base des seuls entrants et sortants de l’IA, il est très facile de se laisser berner. Nous devons entrer dans la salle métaphorique de l’IA pour voir ce qu’il s’y passe. C’est l’intérieur qui compte. 
Merci. 
(Applaudissements) 
