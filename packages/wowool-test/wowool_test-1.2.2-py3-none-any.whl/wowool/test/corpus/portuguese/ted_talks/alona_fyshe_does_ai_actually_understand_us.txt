As pessoas são engraçadas. Estamos constantemente a tentar compreender e interpretar o mundo à nossa volta. Vivo numa casa com dois gatos pretos e deixem-me que vos diga sempre que vejo pelo canto do olho uma camisola preta e amarrotada, penso que é um gato. 
Não são só as coisas que vemos. Por vezes, atribuímos mais inteligência  do que a que existe realmente. Talvez tenham visto os cães no TikTok. Eles têm aqueles botões que dizem coisas como ”passear” ou “biscoito”. Podem levá-los a comunicar algumas coisas com os donos e os donos pensam que eles os utilizam para comunicar algumas coisas impressionantes. Mas os cães saberão o que é que os botões dizem? 
Ou talvez já tenham ouvido a história do cavalo Hans Esperto, que sabia fazer contas. Não eram só problemas simples de matemática, eram mesmo complicados, por exemplo: “Se o oitavo dia do mês cai numa terça-feira, “em que data é a sexta-feira  da semana seguinte?” É muito impressionante para um cavalo. Infelizmente, Hans não sabia de matemática, mas o que fazia era igualmente impressionante. Hans tinha aprendido a observar as pessoas na sala para saber quando devia bater com o casco no chão. Era como comunicava as respostas, batendo com o casco no chão. Acontece que quem sabia a resposta à pergunta “se o oitavo dia do mês é terça-feira, “qual é a data da sexta-feira  da semana seguinte?”, sem querer, mudava de posição quando Hans  batia com o casco 18 vezes. Afinal, Hans não sabia fazer contas, mas aprendera a observar as pessoas que sabiam fazer contas, o que, repito, continua a ser impressionante para um cavalo. Mas isto é uma foto antiga e hoje o Hans Esperto não nos enganaria. Ou enganaria? (Risos) 
Eu trabalho em IA e, digo-vos, as coisas estão feias. Tem havido imensos exemplos de pessoas totalmente convencidas de que a IA as compreende. Em 2022, um engenheiro da Google pensou que a IA da Google era sensível. E vocês já podem ter tido uma conversa parecida com um ser humano com uma coisa como o ChatGPT. Mas os modelos que treinamos hoje são muito melhores do que os modelos que tínhamos há cinco anos. É impressionante. 
Neste momento super louco, vamos fazer uma pergunta super louca: Será que a IA nos compreende ou estamos a ter um momento de Hans Esperto? 
Alguns filósofos acham que os computadores nunca compreenderão a linguagem. Para ilustrar isso, desenvolveram uma coisa a que chamam o argumento do quarto chinês. No quarto chinês há uma pessoa, uma pessoa hipotética, que não percebe chinês, mas tem consigo  um conjunto de instruções que lhe dizem como responder em chinês a qualquer pergunta em chinês. Eis como funciona o quarto chinês. Enfiam um papel por uma ranhura na porta, que tem escrito qualquer coisa em chinês. A pessoa usa as instruções que tem para saber como há de responder. Escreve a resposta na folha de papel e depois devolve-a pela ranhura na porta. Para alguém que fala chinês e que está fora do quarto, pode parecer que a pessoa dentro do quarto fala chinês. Mas nós sabemos que isso não é verdade porque ela não precisa de saber chinês para seguir as instruções. O êxito desta tarefa não prova que ela sabe chinês. 
Então o que é que isto nos diz sobre a IA? Quando vocês ou eu estamos do lado de fora do quarto, quando falamos com uma dessas IA como o caso do ChatGPT, somos a pessoa que está fora do quarto. Estamos a fornecer frases em inglês e recebemos respostas em inglês. Parece mesmo que os modelos nos compreendem. Parece mesmo que sabem inglês. Mas, se investigarmos, estes modelos estão apenas a seguir uma série de instruções, muito complexas. Como é que sabemos se a IA nos compreende? 
Para responder a esta pergunta, voltemos ao quarto chinês. Digamos que temos dois quartos chineses. Num dos quartos está alguém que fala chinês, e no outro quarto está o nosso impostor. Quando a pessoa que fala chinês recebe um papel que tem escrito qualquer coisa em chinês, consegue lê-lo, sem problemas. Mas, quando o impostor o recebe, tem de usar o conjunto de instruções para saber como há de responder. Do lado de fora, pode ser impossível distinguir esses dois quartos, mas sabemos que lá dentro está a acontecer uma coisa diferente. Para ilustrar isso, digamos que os cérebros das duas pessoas que estão nos dois quartos, são um pequeno bloco de notas. Para cumprirem a sua tarefa, só têm de se lembrar de tudo o que tem de ser escrito nesse bloco de notas. Se pudéssemos ver o que foi escrito nesse bloco de notas, veríamos como é diferente a sua abordagem à tarefa. Embora o <i>input </i>e o <i>output</i> nesses dois quartos seja exatamente o mesmo, o processo de passar do <i>input</i> para o <i>output </i>é totalmente diferente. 
Portanto, o que é que isto nos diz sobre a IA? Se a IA, mesmo que gere um diálogo totalmente plausível, responde a perguntas tal como seria de esperar, não deixa de ser uma espécie de impostor. Se queremos saber se a IA compreende a linguagem, tal como nós, é preciso saber  o que é que está a fazer. É preciso entrar lá dentro para ver o que está a acontecer. É um impostor ou não? Precisamos de ver o bloco de notas e precisamos de o comparar com o bloco de notas de alguém que saiba falar a língua. Mas, tal como os blocos de notas do cérebro, isso é uma coisa que não podemos ver, não é? 
Acontece que podemos ver  o bloco de notas dos cérebros. Usando uma coisa  como o fMRI ou o EEG, podemos tirar pequenos instantâneos do cérebro enquanto ele está a ler. Assim, pomos as pessoas a ler palavras ou histórias e tiramos fotos do cérebro delas. Essas imagens do cérebro são imagens difusas, desfocadas do bloco de notas do cérebro. Dizem-nos algumas coisas sobre como o cérebro está a processar e a representar informações enquanto leem. 
Estas são três imagens de um cérebro 
tiradas enquanto uma pessoa lê as palavras “apartamento”,  “casa” e ”aipo”. Vemos a olho nu que as imagens do cérebro para “apartamento” e “casa” têm mais semelhança uma com a outra do que com a imagem do cérebro para “aipo”. Sabemos que apartamentos e casas têm mais parecenças do que têm com aipo, mas são só palavras. Dito de outra maneira, o cérebro usa o seu bloco de notas quando lê as palavras  “apartamento” e “casa” de forma mais semelhante do que quando lê a palavra “aipo”. O bloco de notas diz-nos mais coisas sobre como o cérebro representa a linguagem. Não é uma imagem perfeita do que o cérebro está a fazer, mas é suficientemente boa. 
Portanto, temos blocos de notas para o cérebro. Agora precisamos de um bloco de notas para a IA. No interior de muitas IAs há uma rede neural. No interior duma rede neural há um grupo destes pequenos neurónios. Aqui os neurónios são estes pequenos círculos cinzentos. Gostaríamos de saber o que é um bloco de notas duma rede neural? Quando introduzimos uma palavra numa rede neural, cada um dos pequenos neurónios calcula um número. Esses pequenos números estão representados aqui com cores. Cada neurónio calcula este pequeno número, e esses números dizem-nos qualquer coisa sobre como a rede neural está a processar a linguagem. Em conjunto, todos estes pequenos círculos dão-nos uma imagem de como a rede neural está a representar a linguagem e dão-nos o bloco de notas da rede neural. 
Ótimo. Agora temos dois blocos de notas, um do cérebro e outro da IA. Queremos saber se a IA faz o mesmo que o cérebro está a fazer. Como podemos testar isso? 
Isto é o que os investigadores descobriram. Vamos treinar um novo modelo. Esse modelo novo vai olhar para o bloco de notas da rede neural para uma determinada palavra e tentar prever o bloco de notas do cérebro para a mesma palavra. Podemos fazer isto para as duas coisas. Portanto, vamos treinar um novo modelo. Ele vai olhar para o bloco de notas da rede neural, para uma certa palavra e tentar prever o bloco de notas do cérebro. Se o cérebro e a IA não estão a fazer a mesma coisa, se não têm nada em comum, não podemos fazer esta tarefa de previsão. Não será possível prever uma a partir da outra. 
Assim, chegámos a uma bifurcação e, provavelmente, vocês podem dizer que eu vou dizer uma de duas coisas. Vou dizer que a IA é fantástica, ou vou dizer que a IA é uma impostora. Os investigadores como eu adoram lembrar-vos que a IA é muito diferente do cérebro. E isso é verdade. Mas pode acontecer que haja alguma coisa em comum entre a IA e o cérebro? 
Fizemos esta tarefa de previsão do bloco de notas e acontece que 75% das vezes a previsão do bloco de notas  da rede neural para uma certa palavra é mais semelhante ao verdadeiro bloco de notas da rede neural para a mesma palavra do que é para o bloco de notas  da rede neural para qualquer outra palavra escolhida ao acaso. 75% é muito melhor do que o acaso. E para coisas mais complicadas, para frases, e histórias até? De novo, esta tarefa de previsão do bloco de notas funciona. Conseguimos prever o bloco de notas da rede neural a partir do cérebro e vice-versa. Espantoso! Então, isso significa que as redes neurais e a IA compreendem a linguagem, tal como nós compreendemos? Na verdade, não. Embora estas tarefas de previsão dos blocos de notas mostre um rigor para além do acaso, as correlações subjacentes ainda são muito fracas. E embora as redes neurais sejam inspiradas pelo cérebro, não têm o mesmo tipo de estrutura e de complexidade que vemos no cérebro. As redes neurais também não existem no mundo. Uma rede neural nunca abriu uma porta nem viu um pôr-do-sol, nunca ouviu um bebé chorar. Poderá uma rede neural que não existe no mundo, que nunca experimentou realmente o mundo, compreender a linguagem sobre o mundo? 
Contudo, estas experiências de previsão do bloco de notas têm resistido — experiências  de imagiologia cerebral, múltiplas redes neuronais. Também descobrimos que, à medida que as redes neurais ficam mais precisas, também começam a usar  o seu bloco de notas de uma forma mais parecida com o cérebro. E não é apenas a linguagem. Temos visto resultados semelhantes na navegação e na visão. 
A IA não está a fazer exatamente o que o cérebro faz, mas também não é totalmente ao acaso. Do meu ponto de vista, se queremos saber se a IA compreende a linguagem, tal como nós, temos de entrar no quarto chinês. Precisamos de saber o que a IA está a fazer e precisamos de poder comparar isso com o que as pessoas fazerm quando compreendem a linguagem. 
A IA está a avançar muito depressa. Hoje, pergunto-vos se a IA compreende a linguagem. Isto pode parecer uma pergunta idiota daqui a 10 anos. Ou daqui a 10 meses. 
(Risos) 
Mas uma coisa continua a ser verdade. Somos seres humanos criadores de significados e vamos continuar a olhar para o significado e interpretar o mundo à nossa volta. Precisamos de nos lembrar de que, se só olharmos para o <i>input </i>e o <i>output </i>da IA, é fácil sermos enganados. Precisamos de entrar no quarto metafórico da IA para ver o que está a acontecer. É o que está lá dentro que conta. 
Obrigada. 
(Aplausos) 
