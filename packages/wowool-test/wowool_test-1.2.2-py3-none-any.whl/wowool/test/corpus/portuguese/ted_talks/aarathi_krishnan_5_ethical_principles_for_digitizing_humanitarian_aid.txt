A socióloga Zeynep Tufekci uma vez disse que a História está repleta de imensos exemplos de danos causados por pessoas com muito poder que achavam que por terem boas intenções, não causariam danos. 
Em 2017, refugiados Roinga começaram a fugir do Mianmar para o Bangladesh devido a uma repressão do exército do Mianmar, um ato que as Nações Unidas depois chamaram de intenção genocida. À medida que começaram a chegar aos acampamentos, tiveram de se registar numa variedade de serviços. Um deles era registarem-se para um cartão de identificação biométrico digital apoiado pelo governo. Não lhes era dada a opção de recusar. Em 2021, a Human Rights Watch acusou agências humanitárias internacionais de partilharem informações recolhidas de modo impróprio sobre refugiados Roinga com o governo de Mianmar sem consentimento apropriado. As informações partilhadas não continham apenas dados biométricos. Continham informações sobre a composição das famílias, parentes no estrangeiro, de onde eram originalmente. Com medo de retaliações por parte do governo de Mianmar, alguns esconderam-se. 
A identificação específica de pessoas perseguidas há muito tempo que é uma tática de regimes genocidas. Agora que os dados estão digitalizados, significa que são mais fáceis de aceder, mais rápidos de escalar e mais prontamente acessíveis. Isto foi uma falha numa imensidão de frentes: institucional, de governação, moral. 
Passei 15 anos da minha carreira a trabalhar em ajuda humanitária. Desde o Ruanda até ao Afeganistão. O que é a ajuda humanitária, perguntam vocês? Nos termos mais simples, é o fornecimento de cuidados de emergência àqueles que precisam mais deles em momentos desesperados. Após um desastre, durante uma crise. Comida, água, abrigo. Já trabalhei em organizações humanitárias muito grandes, quer seja a liderar programas globais de vários países ou a projetar inovações de <i>drones</i> para gestão de desastres em pequenos Estados insulares. Já me sentei com comunidades nos contextos mais frágeis, onde conversas sobre o futuro foram as primeiras que eles já tiveram. E já elaborei estratégias globais para preparar organizações humanitárias para estes mesmos futuros. E algo que posso dizer é que nós, os humanitários, aceitamos a digitalização a uma velocidade incrível na última década, passando de tendas e latas de água, que ainda usamos, já agora, para IA, grandes volumes de dados, <i>drones</i>, dados biométricos. Estes podem parecer relevantes, lógicos, necessários, até atraentes para os entusiastas da tecnologia. Mas o que significa na verdade é a implementação de tecnologias não testadas em populações vulneráveis sem consentimento adequado. E isto leva-me a refletir. Reflito porque as agonias que enfrentamos hoje em dia como Humanidade global não aconteceram de um dia para o outro. Aconteceram como resultado da nossa história partilhada de colonialismo e as inovações tecnológicas humanitárias são inerentemente coloniais, muitas vezes projetadas para e em benefício de grupos de pessoas vistas como estando por fora da tecnologia, e que muitas vezes não são legitimamente reconhecidas como conseguindo conceber as suas próprias soluções. 
Por isso, como humanitária eu própria, faço esta pergunta: na nossa missão de fazermos o bem no mundo, como podemos garantir que não prendemos as pessoas em danos futuros, endividamentos futuros e iniquidade futura como resultado destas ações? É por isso que agora estudo a ética da inovação tecnológica humanitária. E não é apenas por curiosidade intelectual. É algo profundamente pessoal. Guiada pela crença que, muitas vezes, são pessoas parecidas comigo, que vêm das comunidades de onde eu vim, historicamente excluídas e marginalizadas, onde outros falam em nome delas e lhes negam ter uma opinião em termos das escolhas disponíveis para elas para o seu futuro. Estou aqui “nos ombros” daqueles que vieram antes de mim e na obrigação por todos aqueles que virão depois de mim para vos dizer que apenas boas intenções não previnem danos, e apenas boas intenções podem causar danos. 
Muitas vezes perguntam-me o que vejo no futuro neste século XXI? E se tivesse de resumir: incertezas profundas, um planeta a morrer, desconfiança, dor. E em tempos de grande volatilidade, nós como humanos, ansiamos por consolação. E os futuros digitais são exatamente isso, uma consolação. Olhamos para isso com toda a sua possibilidade como se pudesse acalmar tudo o que nos aflige, como uma inevitabilidade lógica. 
Nos últimos anos, alguns relatórios começaram a sinalizar os novos tipos de riscos que estão a surgir com as inovações tecnológicas. Um destes riscos é como os dados recolhidos sobre indivíduos vulneráveis podem ser utilizados contra eles como retaliação, representando um risco maior não só para eles como para as suas famílias, para as suas comunidades. Vimos estes riscos tornarem-se verdadeiros com os Roinga. Recentemente, em agosto de 2021, quando o Afeganistão foi tomado pelos Talibãs, também foi revelado que dados biométricos recolhidos sobre afegãos pelo exército dos EUA e pelo governo afegão e utilizados por uma variedade de agentes estavam agora nas mãos dos Talibãs. Foram revistadas casas de jornalistas. Os afegãos corriam contra o tempo para apagar o seu histórico digital <i>online</i>. As tecnologias de capacitação tornavam-se em tecnologias de exclusão. Isto acontece porque estas tecnologias são criadas com base num certo conjunto de premissas sociais, integradas no mercado e depois filtradas através de considerações capitalistas. Mas as tecnologias criadas num contexto e depois testadas noutro vão sempre falhar porque estão baseadas em premissas de como as pessoas vivem as suas vidas. E aqui, eu e vocês podemos estar relativamente confortáveis em fazer uma leitura dos dedos para talvez ir ao cinema, mas isso não se pode extrapolar aos níveis de segurança que sentiríamos ao estar numa fila, e ter de dar esse pedaço  de dados sobre nós para termos acesso a rações alimentares. Os humanitários assumem que a tecnologia vai libertar a Humanidade, sem qualquer devida consideração sobre questões de poder, exploração, danos que podem ocorrer para que isto aconteça. Ao invés, apressamo-nos em arranjar soluções, uma forma de pensamento mágico, que assume que apenas por implementarmos soluções cintilantes, podemos resolver o problema à nossa frente sem qualquer análise verdadeira das realidades subjacentes. 
No fim do dia, estas são ferramentas, e as ferramentas, como a faca de um <i>chef</i>, nas mãos de alguns, criam belas refeições, e nas mãos de outros, criam devastação. Então como garantimos que não projetamos as iniquidades do nosso passado nos nossos futuros digitais? E quero ser clara em relação a algo. Não sou anti-tecnologias. Sou anti-tecnologias parvas. 
(Risos) 
(Aplausos) 
As imaginações limitadas de alguns não devem colonizar as reimaginações radicais de muitos. 
Então, como é que garantimos que criamos uma base ética, para que a libertação que isto promete não seja apenas para alguns privilegiados, mas para todos nós? Existem alguns exemplos que podem apontar para o caminho certo. 
Adoro o trabalho de IA indígena que em vez de se basear em valores e filosofias ocidentais, baseia-se em protocolos e valores indígenas e implementa-os no código da IA. Também adoro o trabalho de Nia Tero, uma organização co-liderada por indígenas que trabalha com comunidades indígenas para traçar o seu próprio bem-estar e territórios ao contrário de outras pessoas virem fazê-lo em seu nome. Aprendi muito com o Satellite Sentinel Project em 2010, que é um exemplo ligeiramente diferente. Essencialmente, o projeto começou para traçar atrocidades através de tecnologias e satélites com teledeteção, de modo a poder prever e potencialmente evitá-las. O projeto terminou depois de alguns anos por uma variedade de razões, uma delas sendo o facto de não conseguir gerar ação de verdade. Mas a segunda, e talvez a mais importante, foi que a equipa percebeu que estava a funcionar sem uma rede ética. E sem diretrizes éticas existentes, era uma linha aberta muito ampla para se questionarem sobre se o que estavam a fazer era útil ou prejudicial. Por isso, decidiram terminar antes de causarem danos. 
Na ausência de princípios éticos juridicamente vinculativos para guiar o nosso trabalho, tenho estado a trabalhar numa série de princípios éticos para informar a inovação tecnológica humanitária, e gostaria de apresentar alguns deles hoje aqui para vocês. 
Um: Perguntar. Que grupos de humanos serão prejudicados por isto e quando? Avaliar: Quem é que esta solução beneficia? Interrogar: Foi obtido consentimento adequado dos utilizadores finais? Considerar: A que devemos renunciar para estarmos aptos para estes futuros? E imaginar: Que bem futuro podemos impedir se implementássemos esta ação hoje? 
Somos responsáveis pelos futuros que criamos. Não nos podemos absolver das responsabilidades e prestações de contas das nossas ações se as nossas ações causarem danos àqueles que alegamos proteger e servir. É absoluta e radicalmente possível existir outro mundo. 
Obrigada. 
(Aplausos) 
