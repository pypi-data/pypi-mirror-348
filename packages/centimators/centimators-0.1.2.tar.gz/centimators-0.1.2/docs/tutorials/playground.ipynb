{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from centimators.feature_transformers import (\n",
    "    RankTransformer,\n",
    "    LagTransformer,\n",
    "    MovingAverageTransformer,\n",
    "    LogReturnTransformer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [datetime.now() - timedelta(days=i) for i in range(90)]\n",
    "dates.reverse()\n",
    "\n",
    "# Generate 5 tickers\n",
    "tickers = [f\"Ticker{i}\" for i in range(1, 21)]\n",
    "\n",
    "# Generate random OHLCV data\n",
    "data = {\n",
    "    \"ticker\": [],\n",
    "    \"date\": [],\n",
    "    \"open\": [],\n",
    "    \"high\": [],\n",
    "    \"low\": [],\n",
    "    \"close\": [],\n",
    "    \"volume\": [],\n",
    "}\n",
    "\n",
    "for ticker in tickers:\n",
    "    # Start with random base price between 10 and 1000\n",
    "    base_price = np.random.uniform(10, 1000)\n",
    "    for date in dates:\n",
    "        # Generate daily price movements\n",
    "        daily_return = np.random.normal(0.005, 0.03)  # Mean 0.5%, std 3%\n",
    "        close = base_price * (1 + daily_return)\n",
    "        high = close * (1 + abs(np.random.normal(0, 0.01)))\n",
    "        low = close * (1 - abs(np.random.normal(0, 0.01)))\n",
    "        open_price = close * (1 + np.random.normal(-0.005, 0.005))\n",
    "        volume = int(np.random.lognormal(10, 1))\n",
    "\n",
    "        data[\"ticker\"].append(ticker)\n",
    "        data[\"date\"].append(date)\n",
    "        data[\"open\"].append(round(open_price, 2))\n",
    "        data[\"high\"].append(round(high, 2))\n",
    "        data[\"low\"].append(round(low, 2))\n",
    "        data[\"close\"].append(round(close, 2))\n",
    "        data[\"volume\"].append(volume)\n",
    "\n",
    "        base_price = close  # Use today's close as tomorrow's base price\n",
    "\n",
    "df_pandas = pd.DataFrame(data)\n",
    "df_polars = pl.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars.plot.line(x=\"date\", y=\"close\", color=\"ticker\").properties(\n",
    "    width=600, height=400, title=\"Stock Prices Over Time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker: RankTransformer = RankTransformer()\n",
    "ranker\n",
    "\n",
    "lag_windows = [0, 2, 4, 6, 8]\n",
    "lagger: LagTransformer = LagTransformer(windows=lag_windows)\n",
    "\n",
    "ma_windows = [5, 10, 20, 40]\n",
    "ma_transformer = MovingAverageTransformer(windows=ma_windows)\n",
    "\n",
    "log_return_transformer = LogReturnTransformer()\n",
    "\n",
    "display(log_return_transformer, ranker, lagger, ma_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use individually (dataframe agnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Pandas vs Polars performance\n",
    "import time\n",
    "\n",
    "# Test with Pandas\n",
    "start_time = time.time()\n",
    "result_pd = ranker.fit_transform(df_pandas, date_series=df_pandas[\"date\"])\n",
    "pandas_time = time.time() - start_time\n",
    "\n",
    "# Test with Polars\n",
    "start_time = time.time()\n",
    "result_pl = ranker.fit_transform(df_polars, date_series=df_polars[\"date\"])\n",
    "polars_time = time.time() - start_time\n",
    "\n",
    "print(f\"Pandas execution time: {pandas_time:.4f} seconds\")\n",
    "print(f\"Polars execution time: {polars_time:.4f} seconds\")\n",
    "print(f\"Polars Speedup: {pandas_time/polars_time:.2f}x\")\n",
    "\n",
    "# Display sample of results\n",
    "print(\"\\nSample of Pandas result:\")\n",
    "display(result_pd.head())\n",
    "print(\"\\nSample of Polars result:\")\n",
    "display(result_pl.head())\n",
    "\n",
    "# Verify results are equivalent\n",
    "pd_result = result_pd\n",
    "pl_result = result_pl.to_pandas()\n",
    "assert pd_result.equals(pl_result), \"Results should be identical!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or chain them together in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "set_config(enable_metadata_routing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn metadata routing API (i.e. set_transform_request)\n",
    "lagger = LagTransformer(windows=lag_windows).set_transform_request(ticker_series=True)\n",
    "ranker = RankTransformer().set_transform_request(date_series=True)\n",
    "ma_transformer = MovingAverageTransformer(windows=ma_windows).set_transform_request(\n",
    "    ticker_series=True\n",
    ")\n",
    "log_return_transformer = LogReturnTransformer().set_transform_request(\n",
    "    ticker_series=True\n",
    ")\n",
    "\n",
    "lagged_ranker = make_pipeline(log_return_transformer, ranker, lagger, ma_transformer)\n",
    "display(lagged_ranker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"open\", \"close\", \"volume\"]\n",
    "transformed_df = lagged_ranker.fit_transform(\n",
    "    df_polars[feature_names],\n",
    "    date_series=df_polars[\"date\"],\n",
    "    ticker_series=df_polars[\"ticker\"],\n",
    ")\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the transformation into features\n",
    "chart_df = pl.concat([df_polars, transformed_df], how=\"horizontal\")\n",
    "original_chart = chart_df.plot.line(x=\"date\", y=\"close\", color=\"ticker\").properties(\n",
    "    width=300, height=300, title=\"Input: Raw Stock Prices Over Time\"\n",
    ")\n",
    "\n",
    "transformed_chart = chart_df.plot.line(\n",
    "    x=\"date\",\n",
    "    y=\"close_logreturn_rank_lag0_ma20\",\n",
    "    color=\"ticker\",\n",
    ").properties(\n",
    "    width=300, height=300, title=\"Pipeline Output: Normalized/Smoothed Features\"\n",
    ")\n",
    "transformed_chart.encoding.y.scale = alt.Scale(domain=[0, 1])\n",
    "\n",
    "chart = original_chart | transformed_chart\n",
    "chart.interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_visualization(df, columns, title, width=300, height=300):\n",
    "    melted_df = df.unpivot(\n",
    "        index=[\"date\"],\n",
    "        on=columns,\n",
    "        variable_name=\"variable\",\n",
    "        value_name=\"value\",\n",
    "    )\n",
    "    chart = melted_df.plot.line(x=\"date\", y=\"value\", color=\"variable\").properties(\n",
    "        width=width, height=height, title=title\n",
    "    )\n",
    "    # Set y-axis scale to [0, 1] since these are normalized ranks\n",
    "    chart.encoding.y.scale = alt.Scale(domain=[0, 1])\n",
    "    return chart\n",
    "\n",
    "ticker = \"Ticker1\"\n",
    "filtered_df = chart_df.filter(pl.col(\"ticker\") == ticker)\n",
    "\n",
    "ma_columns = [f\"close_logreturn_rank_lag0_ma{w}\" for w in ma_windows]\n",
    "lag_columns = [f\"close_logreturn_rank_lag{i}_ma5\" for i in lag_windows]\n",
    "\n",
    "moving_average_chart = create_feature_visualization(\n",
    "    filtered_df,\n",
    "    ma_columns,\n",
    "    f\"Different Moving Average Windows for {ticker}\"\n",
    ")\n",
    "lagged_chart = create_feature_visualization(\n",
    "    filtered_df, \n",
    "    lag_columns,\n",
    "    f\"Different Lag Periods for {ticker}\"\n",
    ")\n",
    "\n",
    "(moving_average_chart | lagged_chart).interactive()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
