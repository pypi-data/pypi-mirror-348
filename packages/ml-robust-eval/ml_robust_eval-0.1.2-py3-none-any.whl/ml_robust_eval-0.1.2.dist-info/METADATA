Metadata-Version: 2.1
Name: ml-robust-eval
Version: 0.1.2
Summary: ML evaluation, validation, and test case generation toolkit.
Home-page: https://github.com/VikhyatChoppa18
Author: Vekata Vikhyat Choppa
Author-email: vikhyat-ch <vikhyathchoppa699@gmail.com>
License: MIT
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE

# ML Robust Eval

![ml-eval-robust-logo](./assets/ML%20Eval.png)

[![PyPI](https://img.shields.io/pypi/v/ml-eval-robust?color=blue&logo=PyPI)](https://pypi.org/project/ml-robust-eval/)
[![License](https://img.shields.io/pypi/l/ml-eval-robust)](https://github.com/VikhyatChoppa18/ml_robust_eval/blob/main/LICENSE)
[![Repo size](https://img.shields.io/github/repo-size/yourusername/ml-eval-robust)](https://github.com/VikhyatChoppa18/ml_robust_eval)
[![Last commit](https://img.shields.io/github/last-commit/yourusername/ml-eval-robust?logo=git)](https://github.com/VikhyatChoppa18/ml_robust_eval/commits/main)

---

**ML Eval Robust** is a pure Python, object-oriented library for comprehensive machine learning model evaluation, validation, and robustness testing.  
Itâ€™s is an all-in-one toolkit that features:

- ğŸ“Š **Metrics** for classification, regression, NLP, and computer vision tasks  
- ğŸ” **Cross-validation** and **A/B testing** helpers  
- ğŸ“ˆ **Visualization** tools for confusion matrices and ROC curves (stdout-based, no dependencies!)  
- ğŸ¦¾ **Automated test case generation**: edge cases, adversarial samples, and boundary value tests  
- ğŸ§© **No external dependencies** â€“ works anywhere Python runs!

---

## ğŸš€ Installation
<code>pip install ml_robust_eval</code>

> **Note:** Pure Python! No numpy, pandas, or matplotlib required.
---

## ğŸ§  Features

- **Classification, Regression, NLP, and CV Metrics**  
  - Accuracy, Precision, Recall, F1, MAE, MSE, RÂ², BLEU, IoU, and more!
- **Cross-Validation & A/B Testing**
  - K-fold splitting, group comparison, and statistical difference calculation
- **Visualization**
  - Confusion matrices and ROC curves printed directly to your console
- **Robustness Test Case Generation**
  - Edge, boundary, and adversarial sample generation for any tabular data
- **Zero Dependencies**
  - Entirely standard library, OOP-based, and lightweight

---

## ğŸ“š Documentation

- [API Reference](https://github.com/yourusername/ml-eval-robust/wiki)
- [Getting Started Guide](https://github.com/yourusername/ml-eval-robust/blob/main/docs/GettingStarted.md)
- [Examples & Tutorials](https://github.com/yourusername/ml-eval-robust/blob/main/examples)

---

## ğŸ’¡ Why ML Eval Robust?

- **Universal:** No dependencies, works in any Python environment
- **Educational:** Clear, readable OOP code for learning and teaching
- **Robust:** Covers the full ML evaluation and validation pipeline, including adversarial and edge testing

---

## ğŸ¤ Contributing

All contributions, bug reports, and suggestions are welcome!  
See the [contributing guide](https://github.com/VikhyatChoppa18/ml_robust_eval/blob/main/blob/contributing.md).

---

## ğŸ“œ License

[MIT License](https://github.com/VikhyatChoppa18/ml_robust_eval/blob/main/LICENSE)

---

## ğŸ“¬ Contact

Questions? Open an [issue](https://github.com/VikhyatChoppa18/ml_robust_eval/issues) or reach out at [vikhyathchoppa699@gmail.com].

---

**Let your models earn their confidence. Test, validate, and challenge them with ML Robust Eval!**
