{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import rtsvg\n",
    "rt = rtsvg.RACETrack()\n",
    "from xwords import XWords, XWordsSolver\n",
    "import copy\n",
    "import os\n",
    "_dir_    = '../../../data/crossword_puzzle_screenshots/'\n",
    "_files_  = os.listdir(_dir_)\n",
    "entries_file    = None\n",
    "geometries_file = None\n",
    "blockers_file   = None\n",
    "answers_file    = None\n",
    "for _file_ in _files_:\n",
    "    if   'entries'    in _file_: entries_file    = _dir_ + _file_\n",
    "    elif 'geometries' in _file_: geometries_file = _dir_ + _file_\n",
    "    elif 'blockers'   in _file_: blockers_file   = _dir_ + _file_\n",
    "    elif 'answers'    in _file_: answers_file    = _dir_ + _file_\n",
    "xwords = XWords(rt, entries_file, geometries_file, blockers_file, answers_file)\n",
    "results_lu = {} # resets the answers seen so far... don't do this or it loses all the work done so far\n",
    "xwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib.util\n",
    "import inspect\n",
    "import requests\n",
    "def getClassesFromFile(file_path):\n",
    "    classes = []\n",
    "    module_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    spec        = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "    module      = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    for name, obj in inspect.getmembers(module):\n",
    "        if inspect.isclass(obj) and obj.__module__ == module.__name__: classes.append(obj)\n",
    "    return classes\n",
    "# https://stackoverflow.com/questions/79372940/how-to-get-a-list-of-models-available-in-ollama-using-langchain\n",
    "OLLAMA_URL = \"http://127.0.0.1:11434\"\n",
    "def getInstalledModels() -> list:\n",
    "    thelist = requests.get(OLLAMA_URL+\"/api/tags\")\n",
    "    jsondata = thelist.json()\n",
    "    result = list()\n",
    "    for model in jsondata[\"models\"]: \n",
    "        _model_ = model[\"model\"]\n",
    "        if _model_.endswith(\":latest\"): _model_ = _model_[:-len(':latest')]\n",
    "        result.append(_model_)\n",
    "    return result\n",
    "all_models = set(getInstalledModels()) - set(['nomic-embed-text']) # remove embedding models\n",
    "all_models = all_models - set(['qwen3:0.6b']) # this model won't finish... \n",
    "print('total models: ', len(all_models)) # all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadResultsAndAnswers():\n",
    "    df_results_list = []\n",
    "    df_answers_list = []\n",
    "    _files_ = os.listdir(_dir_)\n",
    "    for _file_ in _files_:\n",
    "        if   _file_.endswith('_xwords_answers.parquet'): df_answers_list.append(pd.read_parquet(_dir_ + _file_))\n",
    "        elif _file_.endswith('_xwords_results.parquet'): df_results_list.append(pd.read_parquet(_dir_ + _file_))\n",
    "    return pd.concat(df_results_list), pd.concat(df_answers_list)\n",
    "df_results, df_answers = loadResultsAndAnswers()\n",
    "print(f'{len(df_results)=} {len(df_answers)=}')\n",
    "models = all_models - set(df_answers['model'])\n",
    "print('remaining models: ', len(models), models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _model_ in models:\n",
    "    print(_model_)\n",
    "    for _filename_ in os.listdir():\n",
    "        if _filename_.endswith('.py') == False: continue\n",
    "        for _class_ in getClassesFromFile(_filename_):\n",
    "            if issubclass(_class_, XWordsSolver):\n",
    "                if _class_.__name__ not in results_lu: results_lu[_class_.__name__] = {}\n",
    "                print(_class_)\n",
    "                if _model_ in results_lu[_class_.__name__]: \n",
    "                    print('skipping ', _model_)\n",
    "                    continue\n",
    "                xwords_copy = copy.deepcopy(xwords)\n",
    "                _instance_ = _class_(xwords=xwords_copy, model=_model_)\n",
    "                answer_lu, request_stats, num_of_llm_requests = _instance_.solve()\n",
    "                char_level_acc = xwords_copy.characterLevelAccuracy()\n",
    "                results_lu[_class_.__name__][_model_] = (answer_lu, request_stats, num_of_llm_requests, char_level_acc, xwords_copy)\n",
    "                print(f'\\n{_class_.__name__} {_model_} {char_level_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tiles_ = []\n",
    "for _algo_ in results_lu.keys():\n",
    "    for _model_ in models:\n",
    "        if _model_ not in results_lu[_algo_]: _xwords_ = copy.deepcopy(xwords)\n",
    "        else:                                 _xwords_ = results_lu[_algo_][_model_][4]\n",
    "        _tiles_.append(_xwords_.smallMultipleSVG())\n",
    "rt.table(_tiles_, per_row=len(models), spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_answers_ = {'algorithm':[], 'model':[], 'clue_number':[], 'orientation':[], 'answer':[]}\n",
    "_df_results_ = {'algorithm':[], 'model':[], 'char_level_accuracy':[], 'num_of_llm_requests':[], 'time':[], 'prompt_tokens':[], 'output_tokens':[]}\n",
    "for _algo_ in results_lu.keys():\n",
    "    for _model_ in results_lu[_algo_].keys():\n",
    "        _tuple_ = results_lu[_algo_][_model_]\n",
    "        _time_sum_, _prompt_sum_, _output_sum_ = 0.0, 0, 0\n",
    "        for x in _tuple_[1]:\n",
    "            _time_sum_   += x[2]\n",
    "            _prompt_sum_ += x[3]\n",
    "            _output_sum_ += x[4]\n",
    "        _num_of_llm_requests_ = _tuple_[2]\n",
    "        _char_level_accuracy_ = _tuple_[3]\n",
    "        for _clue_ in _tuple_[0].keys():\n",
    "            _df_answers_['algorithm'].append(_algo_)\n",
    "            _df_answers_['model'].append(_model_)\n",
    "            _df_answers_['clue_number'].append(_clue_[0])\n",
    "            _df_answers_['orientation'].append(_clue_[1])\n",
    "            _df_answers_['answer'].append(_tuple_[0][_clue_])\n",
    "        _df_results_['algorithm'].append(_algo_)\n",
    "        _df_results_['model'].append(_model_)\n",
    "        _df_results_['char_level_accuracy'].append(_char_level_accuracy_)\n",
    "        _df_results_['num_of_llm_requests'].append(_num_of_llm_requests_)\n",
    "        _df_results_['time'].append(_time_sum_)\n",
    "        _df_results_['prompt_tokens'].append(_prompt_sum_)\n",
    "        _df_results_['output_tokens'].append(_output_sum_)\n",
    "df_answers_new = pd.DataFrame(_df_answers_)\n",
    "df_results_new = pd.DataFrame(_df_results_)\n",
    "\n",
    "if len(df_answers_new) > 0:\n",
    "    _filename_ = _dir_ + '20250505_xwords_answers.parquet'\n",
    "    if os.path.exists(_filename_): raise Exception('file already exists')\n",
    "    df_answers_new.to_parquet(_filename_)\n",
    "    _filename_ = _dir_ + '20250505_xwords_results.parquet'\n",
    "    if os.path.exists(_filename_): raise Exception('file already exists')\n",
    "    df_results_new.to_parquet(_filename_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results, df_answers = loadResultsAndAnswers()\n",
    "\n",
    "_algorithms_ = list(set(df_results['algorithm']))\n",
    "_colors_     = rt.co_mgr.brewerColors(scale_type='qualitative', n=len(_algorithms_), alt=1)\n",
    "for i in range(len(_algorithms_)): rt.co_mgr.str_to_color_lu[_algorithms_[i]] = _colors_[i]\n",
    "\n",
    "parms = {'color_by':'algorithm', 'w':384, 'h':384}\n",
    "rt.tile([rt.xy       (df_results, x_field='time', y_field='char_level_accuracy', dot_size='large', **parms),\n",
    "         rt.histogram(df_results, bin_by='algorithm',           count_by='char_level_accuracy', color_by='algorithm', h=384, w=256),\n",
    "         rt.histogram(df_results, bin_by=['model','algorithm'], count_by='char_level_accuracy', **parms)], spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers['answer_lower'] = df_answers['answer'].str.lower()\n",
    "_orientation_, _clue_num_ = 'down', 65\n",
    "rt.tile([rt.histogram(df_answers.query('orientation == @_orientation_ and clue_number == @_clue_num_'), bin_by='answer_lower', color_by='algorithm', bar_h=20, w=384, h=670),\n",
    "         xwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Best possible w/ the small models... if the correct answer were chosen...\n",
    "# ... 0.81 character level accuracy\n",
    "#\n",
    "_sorter_ = []\n",
    "for _model_ in set(df_answers['model']):\n",
    "    xwords.clearAll()\n",
    "    for _tuple_ in xwords.entries:\n",
    "        _clue_num_, _orientation_ = _tuple_\n",
    "        _df_ = df_answers.query('clue_number == @_clue_num_ and orientation == @_orientation_ and model == @_model_')\n",
    "        if len(_df_) == 0: continue\n",
    "        if xwords.answer(_clue_num_, _orientation_).lower() in set(_df_['answer_lower']):\n",
    "            xwords.guess(_clue_num_, _orientation_, xwords.answer(_clue_num_, _orientation_))\n",
    "    _sorter_.append((xwords.characterLevelAccuracy(), _model_))\n",
    "_sorter_.sort(reverse=True)\n",
    "for _tuple_ in _sorter_:\n",
    "    print(f'{_tuple_[1]:>24} | {_tuple_[0]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
