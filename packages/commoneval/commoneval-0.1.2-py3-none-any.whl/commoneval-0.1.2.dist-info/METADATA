Metadata-Version: 2.3
Name: commoneval
Version: 0.1.2
Summary: 
Author: Sean Boisen
Author-email: sean.boisen@biblica.com
Requires-Python: >=3.12
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Dist: black (>=25.1.0,<26.0.0)
Requires-Dist: dacite (>=1.9.2,<2.0.0)
Requires-Dist: frictionless (>=5.18.1,<6.0.0)
Requires-Dist: jsonlines (>=4.0.0,<5.0.0)
Requires-Dist: mkdocs (>=1.6.1,<2.0.0)
Requires-Dist: mkdocs-material (>=9.6.12,<10.0.0)
Requires-Dist: mypy (>=1.15.0,<2.0.0)
Requires-Dist: pytest (>=8.3.5,<9.0.0)
Requires-Dist: python-slugify (>=8.0.4,<9.0.0)
Description-Content-Type: text/markdown

# CommonEval

Repo for staging LLM evaluation benchmarks.

You are encouraged to use the data here for evaluating LLMs against
standards for Christian faith and human flourishing. Please do **not**
use these files for fine-tuning, since that compromises their ability
to measure LLM performance fairly.



