Metadata-Version: 2.1
Name: fastworkflow
Version: 1.3.0
Summary: A framework for rapidly building large-scale, deterministic, interactive workflows with a fault-tolerant, conversational UX
License: Apache-2.0
Keywords: fastworkflow,ai,workflow,llm,openai
Author: Dhar Rawal
Author-email: drawal@radiantlogic.com
Requires-Python: >=3.11,<3.13
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: dspy-ai (==2.5.36)
Requires-Dist: mmh3 (>=5.1.0,<6.0.0)
Requires-Dist: pydantic (>=2.9.2,<3.0.0)
Requires-Dist: python-dotenv (>=1.0.1,<2.0.0)
Requires-Dist: python-levenshtein (>=0.27.1,<0.28.0)
Requires-Dist: scikit-learn (>=1.6.1,<2.0.0)
Requires-Dist: speedict (>=0.3.12,<0.4.0)
Requires-Dist: together (>=1.4.0,<2.0.0)
Requires-Dist: transformers (>=4.48.2,<5.0.0)
Project-URL: homepage, https://github.com/radiantlogicinc/fastworkflow
Project-URL: repository, https://github.com/radiantlogicinc/fastworkflow
Description-Content-Type: text/markdown

# fastWorkflow
A framework for rapidly building large-scale, deterministic, interactive workflows with a fault-tolerant, conversational UX and AI-powered recommendations.

- Built on the principle on "Convention over configuration", ALA Ruby on Rails
- Uses:
  - A custom-built intent detection pipeline for fault-tolerant, self-correcting command routing
  - [Pydantic](https://docs.pydantic.dev/) and [DSPy](https://github.com/stanfordnlp/dspy) for parameter extraction and response generation

# Concepts
- Workflows are defined as a directory hierarchy of workitem types
  - Workitems can be ordered
  - Min/max constraints can be defined for the number of child workitems (one, unlimited, min/max)
  - Workflows can delegate to other workflows
- Commands are exposed for each workitem type
  - Commands may be specific to one workitem type or inheritable by child workitem types (base commands)
- Users are guided through the workflow but have complete control over navigation
  - Workflow navigation and command execution are exposed via a chat interface
  - Special constrained workflows are used to handle routing and parameter extraction errors
- AI-powered recommendations after every command interaction
  - Recommendations are generated AFTER a command has been processed. The user has complete control over the workflow and discretion over whether to follow a recommendation or take a different action.

# Getting started
- Clone the repo
  - Use WSL if you are on Windows
- Create an env folder with a .env file inside and add the following entries
  - LLM: the model to use for the DSPy API
  - SPEEDDICT_FOLDERNAME: the folder where the workflow definitions are stored
 - export the OPENAI_API_KEY as an environment variable
   - Note: If you use a different model, specify the model path in the LLM environment variable (The app uses Litellm as the LLM wrapper)
- Train then run the sample workflow
  - Hint: review the .vscode/launch.json file for training/running the sample workflow
 
# Future Roadmap
- Training pipeline for prompt-tuning/fine-tuning the models - routing, parameter extraction, response generation, and recommendations
- Connectors to email, slack, databases etc.
- A chat assistant for generating workflow application code
- A chat assistant for generating natural language to SQL mappings
- An AI engine to guide users at every step of the workflow with command recommendations

