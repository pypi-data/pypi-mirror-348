"""
dataset.py
- load sn, lightcurve and spectra data from different input formats
- flag data rejected by light dr2 cuts (no time grid computations)
"""

import numpy as np
import pickle
import pandas as pd

import skysurvey
import sncosmo
from lemaitre import bandpasses

from nacl.models import salt2
from nacl import TrainingDataset
from nacl.models.salt2.salt import SALT2Like

from .utils import make_sne_nacl, make_lc_nacl


class Dataset:
    """ """

    def __init__(self):

        self.sne = None
        self.lc_data = None

    def generate(
        self, logs, N=12000, tstart=56_000, tstop=60_000, nacl_flux=True, noise=True
    ):
        """From existing logs produced by skysurvey, build a dataset at the nacl format

        logs: pickle file
        N: number of snia event

        """

        # Draw SN1a
        snia = skysurvey.SNeIa()
        data = snia.draw(size=N, tstart=tstart, tstop=tstop, inplace=True)

        # Load survey
        survey = pickle.load(open(logs, "rb"))

        # Combine to make a dataset
        dset = skysurvey.dataset.DataSet.from_targets_and_survey(
            snia, survey, incl_error=False, phase_range=[-20, 50]
        )
        # Return in nacl format
        sne = make_sne_nacl(data)
        lc_data = make_lc_nacl(dset.data)

        if nacl_flux:
            flux = self._nacl_flux()
            lc_data["flux"] = flux
        if noise:
            lc_data["flux"] = np.random.normal(flux, lc_data["fluxerr"])

        self.sne = pd.DataFrame(sne)
        self.lc_data = pd.DataFrame(dset.data)

    def _nacl_flux(self, dust_extinction_model=None):
        """Use NaCl salt2 like model to compute lc fluxes."""
        flib = bandpasses.get_filterlib()  # Initialise filters
        tds = TrainingDataset(
            self.sne.to_numpy(), lc_data=self.lc_data.to_numpy(), filterlib=flib
        )
        model = SALT2Like(tds, dust_extinction_model=dust_extinction_model)

        # Set SN param with values generated by skysurvey
        pars = model.init_pars()
        flux = model(pars)
        return flux

    def sanity_cuts(self, n_bands=2, snr=5, n_points=5):
        """cuts on number of points, bands, overlap between lc and sn dataset"""

        def filter_band_points(group):
            # snr cut
            valid_points = group[group["flux"] / group["fluxerr"] > snr]
            if (
                len(valid_points) >= n_points
                and valid_points["band"].nunique() >= n_bands
            ):
                return group
            return pd.DataFrame()

        # check that sn are have entries in lc data
        self.sne = self.sne[self.sne["sn"].isin(np.unique(self.lc_data["sn"]))]

        # at least 2 bands
        grouped = self.lc_data.groupby("sn").filter(
            lambda x: x["band"].nunique() >= n_bands
        )
        self.lc_data = (
            grouped.groupby("sn").apply(filter_band_points).reset_index(drop=True)
        )

        # self.lc_data = self.lc_data[self.lc_data.flux != 0]
        assert np.any(self.lc_data.flux == 0)
        name_unique = self.lc_data["sn"].unique()
        self.sne = self.sne[self.sne["sn"].isin(name_unique)]

    def dr2_cuts(
        self,
        det_thresh=5,
        n_detect_min=7,
        n_detect_pre_min=2,
        n_bands=2,
        n_detect_post_min=2,
        x1_lim=3,
        c_lim=[-0.2, 0.8],
    ):
        """DR2 cuts"""

        for idx, sn in enumerate(self.sne.sn):
            lc_sn = self.lc_data[self.lc_data.sn == sn]
            sne_sn = sne[sne.sn == sn]
            x1_sn = sne_sn.x1.values[0]
            c_sn = sne_sn.c.values[0]
            tmax_sn = sne_sn.tmax.values[0]

            # Cut sampling based on Tmax
            lc_detection = lc_sn[lc_sn.flux / lc_sn.fluxerr > det_thresh]

            epoch = np.unique(round(lc_detection.mjd, 0))
            if not (
                lc_detection["band"].nunique() >= n_bands
                and len(lc_detection) >= n_detect_min
                and sum(epoch < tmax_sn) >= n_detect_pre_min
                and sum(epoch > tmax_sn) >= n_detect_post_min
                and (np.abs(x1_sn) < x1_lim)
                and (c_lim[0] < c_sn < c_lim[1])
            ):

                sne.iloc[idx, sne.columns.get_loc("valid")] = 0

        name_unique = self.sne[self.sne["valid"] == 1].sn
        self.sne = self.sne[self.sne["sn"].isin(name_unique)]
        self.lc_data = self.lc_data[self.lc_data["sn"].isin(name_unique)]


if __name__ == "__main__":

    ds = Dataset()
    logs = "/work/data/ztf/ztf_survey.pkl"
    ds.generate(logs, N=300)
    print(f"{ds.sne['valid'].sum()}")
    ds.sanity_cuts()
    print(f"{ds.sne['valid'].sum()}")
    ds.dr2_cuts()
    print(f"{ds.sne['valid'].sum()}")
