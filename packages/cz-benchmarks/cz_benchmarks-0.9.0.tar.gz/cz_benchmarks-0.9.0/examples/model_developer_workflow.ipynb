{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29422990-1acc-400d-a2e6-3f3683a7a4bf",
   "metadata": {},
   "source": [
    "# Model Developer Workflow using the CZ Benchmarks Framework\\n\n",
    "\n",
    "This Jupyter Notebook provides an overview of the model developer workflow using the CZI-Benchmark Task Framework. The framework streamlines model benchmarking and evaluation, enabling efficient and reproducible assessments across various tasks. In this example, we focus on utilizing **Geneformer**, a powerful model for gene expression analysis.\n",
    "\n",
    "## Build & Run Instructions\n",
    "\n",
    "Ensure the following settings are set as follows in the beginning of the docker run script (`scripts/run_docker.sh`):\n",
    "\n",
    "```bash\n",
    "BUILD_DEV_CONTAINER=true\n",
    "EVAL_CMD=\"jupyter-lab --notebook-dir=/app/examples --port=8888 --no-browser --allow-root\"\n",
    "```\n",
    "\n",
    "The following command will launch the container and start jupyter lab.\n",
    "\n",
    "```bash\n",
    "bash scripts/run_docker.sh -m geneformer\n",
    "```\n",
    "\n",
    "The the appropriate URL (`http://127.0.0.1:8888/lab?token=<TOKEN>`) with a browser. Open the notebook and execute it. If the notebook is being run remotely, substitute the correct IP address and use either an SSH tunnel (more secure) or add `--ip 0.0.0.0` (insecure) to the Jupyter lab command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888eb05-b18e-4e96-8431-a945bd1044d7",
   "metadata": {},
   "source": [
    "### User Pre-Defined Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b9cef7-7c3c-45f3-a04b-ad0260169826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Setting the predefined paths\n",
    "os.environ[\"DATASETS_CACHE_PATH\"] = \"/raw\"\n",
    "os.environ[\"MODEL_WEIGHTS_PATH_DOCKER\"] = \"/weights\"  # - user checkpoint path,\n",
    "os.environ[\"MODEL_WEIGHTS_CACHE_PATH\"] = \"/weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae38c123-1739-4779-bb43-747c36260973",
   "metadata": {},
   "source": [
    "### Setup Benchmark Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53939f4f-efb0-44bb-b254-b7da1de831ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from czbenchmarks.datasets.utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c38411c-495b-4940-b59b-cdac9fe5337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - load benchmark dataset\n",
    "dataset_name = \"tsv2_bladder\"\n",
    "dataset = load_dataset(dataset_name=dataset_name)\n",
    "dataset.load_data()\n",
    "adata = dataset.adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee78fe3-4a2f-46e4-b13f-8ff8f1d78c94",
   "metadata": {},
   "source": [
    "### Setup User Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6349993d-53c1-41fd-9be1-87372f95d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Geneformer\n",
    "import geneformer.perturber_utils as pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d17c8-553a-431a-96b7-4329a07c5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Geneformer(model_variant=\"gf_12L_30M\")\n",
    "model.download_model_weights(dataset)\n",
    "model.model = pu.load_model(\"Pretrained\", 0, model.model_weights_dir, mode=\"eval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ac542a-d479-4d7c-a6fb-6f87c7636534",
   "metadata": {},
   "source": [
    "#### Model Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a4825-66eb-45cc-baa1-8da869eee904",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.validate_dataset(dataset)\n",
    "model._prepare_metadata(dataset)\n",
    "data_path = model._save_dataset_temp(dataset)\n",
    "tokenized_dataset_path = model._tokenize_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f8e00-b3e7-446f-88d3-8d6183c4f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = model._load_tokenized_dataset(tokenized_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6251d34-4302-4c02-b4ec-3553c30ceaa5",
   "metadata": {},
   "source": [
    "### User Defined DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632a885f-7183-447b-bf34-d2378109a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc98d5ec-ab9b-496d-9eed-c309e442b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "token_file = (\n",
    "    Path(model.model_weights_dir).parent / model.token_config.token_dictionary_file\n",
    ")\n",
    "gene_token_dict = pickle.load(open(token_file, \"rb\"))\n",
    "pad_token_id = gene_token_dict.get(\"<pad>\")\n",
    "model_input_size = model.token_config.input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7607de5-a0c9-40e7-a836-e15f963d7475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - define collate_fn\n",
    "def prepare_pad_tensor_data(dict_list):\n",
    "    lengths, cell_idx, input_ids = zip(\n",
    "        *[(d[\"length\"], d[\"cell_idx\"], torch.tensor(d[\"input_ids\"])) for d in dict_list]\n",
    "    )\n",
    "    lengths_tensor = torch.tensor(lengths, dtype=torch.int64, requires_grad=False)\n",
    "    cell_idx_tensor = torch.tensor(cell_idx, dtype=torch.int64)\n",
    "    max_len = max(lengths)\n",
    "\n",
    "    # - pad to max_len\n",
    "    input_data_minibatch = list(input_ids)\n",
    "    input_data = pu.pad_tensor_list(\n",
    "        input_data_minibatch, max_len, pad_token_id, model_input_size\n",
    "    )\n",
    "    attention_mask = torch.tensor(\n",
    "        [\n",
    "            [1] * original_len + [0] * (max_len - original_len)\n",
    "            if original_len <= max_len\n",
    "            else [1] * max_len\n",
    "            for original_len in lengths\n",
    "        ]\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": input_data,\n",
    "        \"cell_idxs\": cell_idx_tensor,\n",
    "        \"lengths\": lengths_tensor,\n",
    "        \"attention_mask\": attention_mask,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8415df3-3437-4a36-aee1-160ca8596aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    tokenized_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    collate_fn=prepare_pad_tensor_data,\n",
    "    num_workers=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e300ec56-0a70-4930-a8e7-d2563c5570a9",
   "metadata": {},
   "source": [
    "### Setup Benchmark Evaluation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f844d-6ff0-4424-beef-1387c82d6fbc",
   "metadata": {},
   "source": [
    "#### Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc41f4-b9fe-45b2-ad35-a33c307e376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\"\n",
    "model_embeddings = []\n",
    "cell_idxs = []\n",
    "# - user custom loop for extracting embeddings\n",
    "for idx, batch in tqdm(\n",
    "    enumerate(dataloader), desc=\"Extracting Embeddings..\", total=len(dataloader)\n",
    "):\n",
    "    original_lens = batch[\"lengths\"].to(device)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "    embs_i = outputs.hidden_states[-1]\n",
    "    mean_embs = pu.mean_nonpadding_embs(embs_i, original_lens).cpu().numpy()\n",
    "    model_embeddings.append(mean_embs)\n",
    "    cell_idxs += batch[\"cell_idxs\"].cpu().tolist()\n",
    "\n",
    "model_embeddings = np.concatenate(model_embeddings, axis=0)[np.argsort(cell_idxs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b544ec6d-2d86-4508-82f0-a9e430fd9921",
   "metadata": {},
   "source": [
    "#### Task Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98bb3ad-7ff9-45e4-ae0a-e187dbc63117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from czbenchmarks.tasks import ClusteringTask\n",
    "from czbenchmarks.datasets import DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee65cc2-4c10-456f-b168-3844030e58bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ClusteringTask(label_key=\"cell_type\")\n",
    "dataset.set_output(None, DataType.EMBEDDING, model_embeddings)\n",
    "result = task.run(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b5c570-9707-4c52-aba2-3895b83c949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
