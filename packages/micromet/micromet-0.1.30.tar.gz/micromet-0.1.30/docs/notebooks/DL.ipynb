{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6cb5d9c8ae57b4",
   "metadata": {},
   "source": [
    "This notebook was used to compile all of the available data from the Utah Flux Network stations.  It should only need to be used once, as other notebooks are used to comile the newer data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e587dad2",
   "metadata": {},
   "source": [
    "# Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d356450d",
   "metadata": {},
   "source": [
    "## Standard Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T15:58:21.453804Z",
     "start_time": "2025-05-17T15:58:18.782138Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "import pathlib\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.parse import quote\n",
    "from sqlalchemy import create_engine\n",
    "import configparser\n",
    "import re\n",
    "\n",
    "import statsmodels.api as sm\n",
    "#import pingouin as pg\n",
    "import plotly.express as px\n",
    "import plotly.express as px\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "1dca4ca2",
   "metadata": {},
   "source": "## Import Libraries"
  },
  {
   "cell_type": "code",
   "id": "61e3a29165852b08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T15:58:43.239073Z",
     "start_time": "2025-05-17T15:58:43.106185Z"
    }
   },
   "source": [
    "import matplotlib\n",
    "import pandas\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../../Micromet\")\n",
    "import micromet\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.ERROR)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(\n",
    "    logging.Formatter(\n",
    "        fmt=\"%(levelname)s [%(asctime)s] %(name)s – %(message)s\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    )\n",
    ")\n",
    "logger.addHandler(ch)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credentials needed\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T12:26:34.396385Z",
     "start_time": "2025-04-29T12:26:34.393522Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1b38969a9e014987",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d046c00c",
   "metadata": {},
   "source": [
    "# Run Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9e44b",
   "metadata": {},
   "source": [
    "## List Sites for Examination"
   ]
  },
  {
   "cell_type": "code",
   "id": "e506404b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T12:26:36.083449Z",
     "start_time": "2025-04-29T12:26:36.081041Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "268e03b0",
   "metadata": {},
   "source": [
    "## Compile Eddy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2245a878",
   "metadata": {},
   "source": [
    "Search folders, reformat table, and save csv files"
   ]
  },
  {
   "cell_type": "code",
   "id": "ad20f401f01ce92f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T16:13:42.754030Z",
     "start_time": "2025-05-17T16:05:51.349043Z"
    }
   },
   "source": [
    "site_folders = {'US-UTD':'Dugout_Ranch',\n",
    "                'US-UTB':'BSF',\n",
    "                'US-UTJ':'Bluff',\n",
    "                'US-UTW':'Wellington',\n",
    "                'US-UTE':'Escalante',\n",
    "                'US-UTM':'Matheson',\n",
    "                'US-UTP':'Phrag',\n",
    "                'US-CdM':'Cedar_mesa',\n",
    "                'US-UTV':'Desert_View_Myton',\n",
    "                'US-UTN':'Juab',\n",
    "                'US-UTG':'Green_River'\n",
    "                }\n",
    "\n",
    "comp_edd_df = {}\n",
    "\n",
    "am = micromet.AmerifluxDataProcessor(config_path='../../data/reformatter_vars.yml',\n",
    "                                     logger=logger)\n",
    "\n",
    "for key, value in site_folders.items():\n",
    "\n",
    "    print(key)\n",
    "    raw_fold = pathlib.Path('G:/Shared drives/UGS_Flux/Data_Downloads/')\n",
    "    pths = micromet.fix_all_in_parent(raw_fold)\n",
    "    raw_data = am.raw_file_compile(raw_fold, value, search_str = \"*Flux_AmeriFluxFormat*.dat\")\n",
    "    if raw_data is not None:\n",
    "        am_data = micromet.Reformatter(config_path=\"../../data/reformatter_vars.yml\",\n",
    "                                       var_limits_csv= \"../../data/extreme_values.csv\",\n",
    "                                       drop_soil=False,\n",
    "                                       logger=logger,\n",
    "                                       )\n",
    "        am_df = am_data.prepare(raw_data)\n",
    "        comp_edd_df[key] = am_df\n",
    "\n",
    "        am_df.to_csv(f\"../../data/station_data/{key}_HH_{am_df['TIMESTAMP_START'].values[0]:}_{am_df['TIMESTAMP_END'].values[-1]:}.csv\")\n",
    "\n",
    "    \n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US-UTD\n",
      "\n",
      "✔ All possible files have been checked.\n",
      "US-UTB\n",
      "\n",
      "✔ All possible files have been checked.\n",
      "US-UTJ\n",
      "\n",
      "✔ All possible files have been checked.\n",
      "US-UTW\n",
      "\n",
      "✔ All possible files have been checked.\n",
      "US-UTE\n",
      "\n",
      "✔ All possible files have been checked.\n",
      "US-UTM\n",
      "\n",
      "✔ All possible files have been checked.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 24\u001B[0m\n\u001B[0;32m     22\u001B[0m raw_fold \u001B[38;5;241m=\u001B[39m pathlib\u001B[38;5;241m.\u001B[39mPath(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mG:/Shared drives/UGS_Flux/Data_Downloads/\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     23\u001B[0m pths \u001B[38;5;241m=\u001B[39m micromet\u001B[38;5;241m.\u001B[39mfix_all_in_parent(raw_fold)\n\u001B[1;32m---> 24\u001B[0m raw_data \u001B[38;5;241m=\u001B[39m \u001B[43mam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_file_compile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_fold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msearch_str\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m*Flux_AmeriFluxFormat*.dat\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m raw_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     26\u001B[0m     am_data \u001B[38;5;241m=\u001B[39m micromet\u001B[38;5;241m.\u001B[39mReformatter(config_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../data/reformatter_vars.yml\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     27\u001B[0m                                    var_limits_csv\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../data/extreme_values.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     28\u001B[0m                                    drop_soil\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     29\u001B[0m                                    logger\u001B[38;5;241m=\u001B[39mlogger,\n\u001B[0;32m     30\u001B[0m                                    )\n",
      "File \u001B[1;32m~\\.conda\\envs\\py313\\Lib\\site-packages\\micromet\\converter.py:179\u001B[0m, in \u001B[0;36mAmerifluxDataProcessor.raw_file_compile\u001B[1;34m(self, main_dir, station_folder_name, search_str)\u001B[0m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcessing file: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    177\u001B[0m file_no, datalogger_number \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_file_no(file)\n\u001B[1;32m--> 179\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_dataframe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m df \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    181\u001B[0m     df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile_no\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m file_no\n",
      "File \u001B[1;32m~\\.conda\\envs\\py313\\Lib\\site-packages\\micromet\\converter.py:97\u001B[0m, in \u001B[0;36mAmerifluxDataProcessor.to_dataframe\u001B[1;34m(self, file)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mto_dataframe\u001B[39m(\u001B[38;5;28mself\u001B[39m, file: Union[\u001B[38;5;28mstr\u001B[39m, Path]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame:\n\u001B[0;32m     96\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return parsed CSV as pandas DataFrame.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 97\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_determine_header_rows\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReading \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, file)\n\u001B[0;32m     99\u001B[0m     df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\n\u001B[0;32m    100\u001B[0m         file,\n\u001B[0;32m    101\u001B[0m         skiprows\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip_rows,\n\u001B[0;32m    102\u001B[0m         names\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnames,\n\u001B[0;32m    103\u001B[0m         na_values\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mNA_VALUES,\n\u001B[0;32m    104\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\py313\\Lib\\site-packages\\micromet\\converter.py:118\u001B[0m, in \u001B[0;36mAmerifluxDataProcessor._determine_header_rows\u001B[1;34m(self, file)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;124;03mExamine the first line to decide if file is TOA5 or already processed.\u001B[39;00m\n\u001B[0;32m    113\u001B[0m \n\u001B[0;32m    114\u001B[0m \u001B[38;5;124;03mTOA5 files begin with literal 'TOA5'.\u001B[39;00m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;124;03mAmeriFlux standard Level‑2 output has no prefix, just column labels.\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m file\u001B[38;5;241m.\u001B[39mopen(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fp:\n\u001B[1;32m--> 118\u001B[0m     first_line \u001B[38;5;241m=\u001B[39m \u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    119\u001B[0m     second_line \u001B[38;5;241m=\u001B[39m fp\u001B[38;5;241m.\u001B[39mreadline()\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_line[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_HEADER_PREFIX:\n",
      "\u001B[1;31mOSError\u001B[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c61e42a183b17d77",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aaffd5fb",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8792cc9c",
   "metadata": {},
   "source": [
    "Compile files from each station into a a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "id": "00d61bf9",
   "metadata": {},
   "source": [
    "cdf = pd.concat(comp_edd_df, axis=0)\n",
    "cdf.index.set_names(['stationid','datetime_start'],inplace=True)\n",
    "#cdf.rename(columns={'level_0':'stationid'},inplace=True)\n",
    "#cdf.to_parquet('../station_data/all_data.parquet')\n",
    "for col in cdf.columns:\n",
    "    cdf.rename(columns={col:col.lower()},inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cf106f08",
   "metadata": {},
   "source": [
    "Save to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "id": "788d86dd",
   "metadata": {},
   "source": [
    "cdf.to_parquet('../../station_data/all_eddy_data.parquet')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a4f62bea",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "577962db",
   "metadata": {},
   "source": [
    "\n",
    "comp_met_df = {}\n",
    "\n",
    "am = micromet.AmerifluxDataProcessor()\n",
    "\n",
    "for key, value in site_folders.items():\n",
    "\n",
    "    print(key)\n",
    "    raw_fold = pathlib.Path('G:/Shared drives/UGS_Flux/Data_Downloads/')\n",
    "    raw_data = am.raw_file_compile(raw_fold, value, search_str = \"*Statistics_AmeriFlux*.dat\")\n",
    "    if raw_data is not None:\n",
    "        am_data = micromet.Reformatter(raw_data,\n",
    "                                       config_path=\"../../data/reformatter_vars.yml\", \n",
    "                                       drop_soil=False,\n",
    "                                       data_type='met'\n",
    "                                       )\n",
    "        am_df = am_data.et_data\n",
    "        comp_met_df[key] = am_df\n",
    "\n",
    "        #am_df.to_csv(f\"../../station_data/{key}_HH_{am_df['TIMESTAMP_START'].values[0]:}_{am_df['TIMESTAMP_END'].values[-1]:}.csv\")\n",
    "\n",
    "        \n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9b6cc956",
   "metadata": {},
   "source": [
    "mapping = {\n",
    "    \"T_100cm_N_Avg\": \"TS_3_9_1\",\n",
    "    \"BulkEC_5cm_N_Avg\": \"EC_3_1_1\",\n",
    "    \"BulkEC_10cm_N_Avg\": \"EC_3_2_1\",\n",
    "    \"BulkEC_20cm_N_Avg\": \"EC_3_3_1\",\n",
    "    \"BulkEC_30cm_N_Avg\": \"EC_3_4_1\",\n",
    "    \"BulkEC_40cm_N_Avg\": \"EC_3_5_1\",\n",
    "    \"BulkEC_50cm_N_Avg\": \"EC_3_6_1\",\n",
    "    \"BulkEC_60cm_N_Avg\": \"EC_3_7_1\",\n",
    "    \"BulkEC_75cm_N_Avg\": \"EC_3_8_1\",\n",
    "    \"BulkEC_100cm_N_Avg\": \"EC_3_9_1\",\n",
    "    \"VWC_5cm_S_Avg\": \"SWC_4_1_1\",\n",
    "    \"VWC_10cm_S_Avg\": \"SWC_4_2_1\",\n",
    "    \"VWC_20cm_S_Avg\": \"SWC_4_3_1\",\n",
    "    \"VWC_30cm_S_Avg\": \"SWC_4_4_1\",\n",
    "    \"VWC_40cm_S_Avg\": \"SWC_4_5_1\",\n",
    "    \"VWC_50cm_S_Avg\": \"SWC_4_6_1\",\n",
    "    \"VWC_60cm_S_Avg\": \"SWC_4_7_1\",\n",
    "    \"VWC_75cm_S_Avg\": \"SWC_4_8_1\",\n",
    "    \"VWC_100cm_S_Avg\": \"SWC_4_9_1\",\n",
    "    \"Ka_5cm_S_Avg\": \"K_4_1_1\",\n",
    "    \"Ka_10cm_S_Avg\": \"K_4_2_1\",\n",
    "    \"Ka_20cm_S_Avg\": \"K_4_3_1\",\n",
    "    \"Ka_30cm_S_Avg\": \"K_4_4_1\",\n",
    "    \"Ka_40cm_S_Avg\": \"K_4_5_1\",\n",
    "    \"Ka_50cm_S_Avg\": \"K_4_6_1\",\n",
    "    \"Ka_60cm_S_Avg\": \"K_4_7_1\",\n",
    "    \"Ka_75cm_S_Avg\": \"K_4_8_1\",\n",
    "    \"Ka_100cm_S_Avg\": \"K_4_9_1\",\n",
    "    \"T_5cm_S_Avg\": \"TS_4_1_1\",\n",
    "    \"T_10cm_S_Avg\": \"TS_4_2_1\",\n",
    "    \"T_20cm_S_Avg\": \"TS_4_3_1\",\n",
    "    \"T_30cm_S_Avg\": \"TS_4_4_1\",\n",
    "    \"T_40cm_S_Avg\": \"TS_4_5_1\",\n",
    "    \"T_50cm_S_Avg\": \"TS_4_6_1\",\n",
    "    \"T_60cm_S_Avg\": \"TS_4_7_1\",\n",
    "    \"T_75cm_S_Avg\": \"TS_4_8_1\",\n",
    "    \"T_100cm_S_Avg\": \"TS_4_9_1\",\n",
    "    \"BulkEC_5cm_S_Avg\": \"EC_4_1_1\",\n",
    "    \"BulkEC_10cm_S_Avg\": \"EC_4_2_1\",\n",
    "    \"BulkEC_20cm_S_Avg\": \"EC_4_3_1\",\n",
    "    \"BulkEC_30cm_S_Avg\": \"EC_4_4_1\",\n",
    "    \"BulkEC_40cm_S_Avg\": \"EC_4_5_1\",\n",
    "    \"BulkEC_50cm_S_Avg\": \"EC_4_6_1\",\n",
    "    \"BulkEC_60cm_S_Avg\": \"EC_4_7_1\",\n",
    "    \"BulkEC_75cm_S_Avg\": \"EC_4_8_1\",\n",
    "    \"BulkEC_100cm_S_Avg\": \"EC_4_9_1\",\n",
    "    \"VWC_5cm_Avg\": \"SWC_3_1_1\",\n",
    "    \"VWC_10cm_Avg\": \"SWC_3_2_1\",\n",
    "    \"VWC_20cm_Avg\": \"SWC_3_3_1\",\n",
    "    \"VWC_30cm_Avg\": \"SWC_3_4_1\",\n",
    "    \"VWC_40cm_Avg\": \"SWC_3_5_1\",\n",
    "    \"VWC_50cm_Avg\": \"SWC_3_6_1\",\n",
    "    \"VWC_60cm_Avg\": \"SWC_3_7_1\",\n",
    "    \"VWC_75cm_Avg\": \"SWC_3_8_1\",\n",
    "    \"VWC_100cm_Avg\": \"SWC_3_9_1\",\n",
    "    \"Ka_5cm_Avg\": \"K_3_1_1\",\n",
    "    \"Ka_10cm_Avg\": \"K_3_2_1\",\n",
    "    \"Ka_20cm_Avg\": \"K_3_3_1\",\n",
    "    \"Ka_30cm_Avg\": \"K_3_4_1\",\n",
    "    \"Ka_40cm_Avg\": \"K_3_5_1\",\n",
    "    \"Ka_50cm_Avg\": \"K_3_6_1\",\n",
    "    \"Ka_60cm_Avg\": \"K_3_7_1\",\n",
    "    \"Ka_75cm_Avg\": \"K_3_8_1\",\n",
    "    \"Ka_100cm_Avg\": \"K_3_9_1\",\n",
    "    \"T_5cm_Avg\": \"TS_3_1_1\",\n",
    "    \"T_10cm_Avg\": \"TS_3_2_1\",\n",
    "    \"T_20cm_Avg\": \"TS_3_3_1\",\n",
    "    \"T_30cm_Avg\": \"TS_3_4_1\",\n",
    "    \"T_40cm_Avg\": \"TS_3_5_1\",\n",
    "    \"T_50cm_Avg\": \"TS_3_6_1\",\n",
    "    \"T_60cm_Avg\": \"TS_3_7_1\",\n",
    "    \"T_75cm_Avg\": \"TS_3_8_1\",\n",
    "    \"T_100cm_Avg\": \"TS_3_9_1\",\n",
    "    \"BulkEC_5cm_Avg\": \"EC_3_1_1\",\n",
    "    \"BulkEC_10cm_Avg\": \"EC_3_2_1\",\n",
    "    \"BulkEC_20cm_Avg\": \"EC_3_3_1\",\n",
    "    \"BulkEC_30cm_Avg\": \"EC_3_4_1\",\n",
    "    \"BulkEC_40cm_Avg\": \"EC_3_5_1\",\n",
    "    \"BulkEC_50cm_Avg\": \"EC_3_6_1\",\n",
    "    \"BulkEC_60cm_Avg\": \"EC_3_7_1\",\n",
    "    \"BulkEC_75cm_Avg\": \"EC_3_8_1\",\n",
    "    \"BulkEC_100cm_Avg\": \"EC_3_9_1\",\n",
    "    \"BulkEC_3_1_1\": \"EC_3_1_1\",\n",
    "    \"BulkEC_3_2_1\": \"EC_3_2_1\",\n",
    "    \"BulkEC_3_3_1\": \"EC_3_3_1\",\n",
    "    \"BulkEC_3_4_1\": \"EC_3_4_1\",\n",
    "    \"BulkEC_3_5_1\": \"EC_3_5_1\",\n",
    "    \"BulkEC_3_6_1\": \"EC_3_6_1\",\n",
    "    \"BulkEC_3_7_1\": \"EC_3_7_1\",\n",
    "    \"BulkEC_3_8_1\": \"EC_3_8_1\",\n",
    "    \"BulkEC_3_9_1\": \"EC_3_9_1\",\n",
    "    \"KA_3_1_1\": \"K_3_1_1\",\n",
    "    \"KA_3_2_1\": \"K_3_2_1\",\n",
    "    \"KA_3_3_1\": \"K_3_3_1\",\n",
    "    \"KA_3_4_1\": \"K_3_4_1\",\n",
    "    \"KA_3_5_1\": \"K_3_5_1\",\n",
    "    \"KA_3_6_1\": \"K_3_6_1\",\n",
    "    \"KA_3_7_1\": \"K_3_7_1\",\n",
    "    \"KA_3_8_1\": \"K_3_8_1\",\n",
    "    \"KA_3_9_1\": \"K_3_9_1\",\n",
    "    \"VWC_2_1_1\": \"SWC_3_1_1\",\n",
    "    \"VWC_2_2_1\": \"SWC_3_2_1\",\n",
    "    \"VWC_2_3_1\": \"SWC_3_3_1\",\n",
    "    \"VWC_2_4_1\": \"SWC_3_4_1\",\n",
    "    \"VWC_2_5_1\": \"SWC_3_5_1\",\n",
    "    \"VWC_2_6_1\": \"SWC_3_6_1\",\n",
    "    \"VWC_2_7_1\": \"SWC_3_7_1\",\n",
    "    \"VWC_2_8_1\": \"SWC_3_8_1\",\n",
    "    \"VWC_2_9_1\": \"SWC_3_9_1\",\n",
    "    \"VWC_3_1_1\": \"SWC_4_1_1\",\n",
    "    \"VWC_3_2_1\": \"SWC_4_2_1\",\n",
    "    \"VWC_3_3_1\": \"SWC_4_3_1\",\n",
    "    \"VWC_3_4_1\": \"SWC_4_4_1\",\n",
    "    \"VWC_3_5_1\": \"SWC_4_5_1\",\n",
    "    \"VWC_3_6_1\": \"SWC_4_6_1\",\n",
    "    \"VWC_3_7_1\": \"SWC_4_7_1\",\n",
    "    \"VWC_3_8_1\": \"SWC_4_8_1\",\n",
    "    \"VWC_3_9_1\": \"SWC_4_9_1\",\n",
    "    \"T__1_8_1\": \"TS_3_8_1\",\n",
    "    \"KA_4_1_1\": \"K_4_1_1\",\n",
    "    \"KA_4_2_1\": \"K_4_2_1\",\n",
    "    \"KA_4_3_1\": \"K_4_3_1\",\n",
    "    \"KA_4_4_1\": \"K_4_4_1\",\n",
    "    \"KA_4_5_1\": \"K_4_5_1\",\n",
    "    \"KA_4_6_1\": \"K_4_6_1\",\n",
    "    \"KA_4_7_1\": \"K_4_7_1\",\n",
    "    \"KA_4_8_1\": \"K_4_8_1\",\n",
    "    \"KA_4_9_1\": \"K_4_9_1\",\n",
    "    \"BulkEC_4_1_1\": \"EC_4_1_1\",\n",
    "    \"BulkEC_4_2_1\": \"EC_4_2_1\",\n",
    "    \"BulkEC_4_3_1\": \"EC_4_3_1\",\n",
    "    \"BulkEC_4_4_1\": \"EC_4_4_1\",\n",
    "    \"BulkEC_4_5_1\": \"EC_4_5_1\",\n",
    "    \"BulkEC_4_6_1\": \"EC_4_6_1\",\n",
    "    \"BulkEC_4_7_1\": \"EC_4_7_1\",\n",
    "    \"BulkEC_4_8_1\": \"EC_4_8_1\",\n",
    "    \"BulkEC_4_9_1\": \"EC_4_9_1\",\n",
    "    \"KA_2_1_1\": \"K_4_1_1\",\n",
    "    \"KA_2_2_1\": \"K_4_2_1\",\n",
    "    \"KA_2_3_1\": \"K_4_3_1\",\n",
    "    \"KA_2_4_1\": \"K_4_4_1\",\n",
    "    \"KA_2_5_1\": \"K_4_5_1\",\n",
    "    \"KA_2_6_1\": \"K_4_6_1\",\n",
    "    \"KA_2_7_1\": \"K_4_7_1\",\n",
    "    \"KA_2_8_1\": \"K_4_8_1\",\n",
    "    \"KA_2_9_1\": \"K_4_9_1\",\n",
    "    \"BulkEC_2_1_1\": \"EC_4_1_1\",\n",
    "    \"BulkEC_2_2_1\": \"EC_4_2_1\",\n",
    "    \"BulkEC_2_3_1\": \"EC_4_3_1\",\n",
    "    \"BulkEC_2_4_1\": \"EC_4_4_1\",\n",
    "    \"BulkEC_2_5_1\": \"EC_4_5_1\",\n",
    "    \"BulkEC_2_6_1\": \"EC_4_6_1\",\n",
    "    \"BulkEC_2_7_1\": \"EC_4_7_1\",\n",
    "    \"BulkEC_2_8_1\": \"EC_4_8_1\",\n",
    "    \"BulkEC_2_9_1\": \"EC_4_9_1\",\n",
    "    \"T_2_1_1\": \"TS_4_1_1\",\n",
    "    \"T_2_2_1\": \"TS_4_2_1\",\n",
    "    \"T_2_3_1\": \"TS_4_3_1\",\n",
    "    \"T_2_4_1\": \"TS_4_4_1\",\n",
    "    \"T_2_5_1\": \"TS_4_5_1\",\n",
    "    \"T_2_6_1\": \"TS_4_6_1\",\n",
    "    \"T_2_7_1\": \"TS_4_7_1\",\n",
    "    \"T_2_8_1\": \"TS_4_8_1\",\n",
    "    \"T_2_9_1\": \"TS_4_9_1\",\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cff94ca3",
   "metadata": {},
   "source": [
    "ddf.columns = ddf.columns.str.lower()\n",
    "\n",
    "for old_col, new_col in mapping.items():\n",
    "    if str(old_col).lower() in ddf.columns.str.lower():\n",
    "        if str(new_col).lower() in ddf.columns.str.lower():\n",
    "            ddf[new_col.lower()] = ddf[[old_col.lower(), new_col.lower()]].max(axis=1)\n",
    "            ddf = ddf.drop(old_col.lower(), axis=1)\n",
    "        else:\n",
    "            ddf = ddf.rename(columns={old_col.lower(): new_col.lower()})\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "44d44a60",
   "metadata": {},
   "source": [
    "soildfs\n",
    "\n",
    "for old_col, new_col in mapping.items():\n",
    "    if str(old_col).lower() in soildfs.columns.str.lower():\n",
    "        if str(new_col).lower() in soildfs.columns.str.lower():\n",
    "            soildfs[new_col.lower()] = soildfs[[old_col.lower(), new_col.lower()]].max(axis=1)\n",
    "            soildfs = soildfs.drop(old_col.lower(), axis=1)\n",
    "        else:\n",
    "            soildfs = soildfs.rename(columns={old_col.lower(): new_col.lower()})\n",
    "    elif str(old_col).lower()+\"_eddy\" in soildfs.columns.str.lower():\n",
    "        print(f\"Found {old_col} eddy column\")\n",
    "        if str(new_col).lower()+\"_eddy\" in soildfs.columns.str.lower():\n",
    "            soildfs[new_col.lower()] = soildfs[[old_col.lower()+\"_eddy\", new_col.lower()+\"_eddy\"]].max(axis=1)\n",
    "            soildfs = soildfs.drop(old_col.lower()+\"_eddy\", axis=1)\n",
    "        else:\n",
    "            soildfs = soildfs.rename(columns={old_col.lower()+\"_eddy\": new_col.lower()})\n",
    "    elif str(new_col).lower()+\"_eddy\" in soildfs.columns.str.lower():\n",
    "        if str(new_col).lower() in soildfs.columns.str.lower():\n",
    "            soildfs[new_col.lower()] = soildfs[[new_col.lower()+\"_eddy\", new_col.lower()+\"_eddy\"]].max(axis=1)\n",
    "            soildfs = soildfs.drop(new_col.lower()+\"_eddy\", axis=1)\n",
    "            print(f\"Found {new_col} eddy column\")\n",
    "        else:\n",
    "            print(f\"Found {new_col} eddy column\")\n",
    "            soildfs = soildfs.rename(columns={new_col.lower()+\"_eddy\": new_col.lower()})\n",
    "        \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f1500060",
   "metadata": {},
   "source": [
    "for old_col, new_col in mapping.items():\n",
    "    if str(old_col).lower()+\"_eddy\" in soildfs.columns.str.lower().str.strip():\n",
    "        print(f\"Found {old_col} eddy column\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9a4122fb",
   "metadata": {},
   "source": [
    "\"swc_4_1_1\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc90f1fe",
   "metadata": {},
   "source": [
    "soildfs.iloc[0:1,:].to_clipboard()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9bf77bbb",
   "metadata": {},
   "source": [
    "ddf = ddf.replace(np.nan, 0)  "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "19154f83",
   "metadata": {},
   "source": [
    "ddf.to_parquet('../../station_data/all_met_data.parquet')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cbcc658a",
   "metadata": {},
   "source": [
    "ddf = pd.concat(comp_met_df, axis=0)\n",
    "ddf.index.set_names(['stationid','datetime_start'],inplace=True)\n",
    "#cdf.rename(columns={'level_0':'stationid'},inplace=True)\n",
    "#cdf.to_parquet('../station_data/all_data.parquet')\n",
    "for col in ddf.columns:\n",
    "    ddf.rename(columns={col:col.lower()},inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2cf042fb",
   "metadata": {},
   "source": [
    "ddf[~ddf['vwc_2_7_1'].isna()]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0ef3316a",
   "metadata": {},
   "source": [
    "ddf.iloc[0:1,:].to_clipboard()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f082e3c",
   "metadata": {},
   "source": [
    "import re\n",
    "\n",
    "soilcols = [col.lower() for col in am_data.MATH_SOILS_V2]\n",
    "pattern = re.compile(r\"2_1_1|1_2_1|1_1_2\")\n",
    "# Print matching columns\n",
    "matching_cols = [col for col in soilcols if pattern.search(col)]\n",
    "# Remove them from the original list\n",
    "soilcols = [col for col in soilcols if not pattern.search(col)]\n",
    "\n",
    "        \n",
    "soildfs = pd.merge(ddf,cdf[soilcols],how='left',on=['stationid','datetime_start'],suffixes=(None,'_eddy'))\n",
    "soildfs\n",
    "\n",
    "for col in cdf.columns:\n",
    "    if col in soilcols:\n",
    "        cdf.drop(columns=col,inplace=True)  # drop the soil columns from the main dataframe\n",
    "\n",
    "cdf.to_parquet('../../station_data/all_eddy_data.parquet')\n",
    "\n",
    "soildfs.to_parquet('../../station_data/all_soil_data.parquet')\n",
    "\n",
    "ddf.to_parquet('../../station_data/all_met_data.parquet')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "49f9e436",
   "metadata": {},
   "source": [
    "cdf = pd.read_parquet('../../station_data/all_eddy_data.parquet')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "84295da8",
   "metadata": {},
   "source": [
    "cdf.columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "54cc9ad7",
   "metadata": {},
   "source": [
    "soildfs = pd.read_parquet('../../station_data/all_soil_data.parquet')\n",
    "utd_soilt = soildfs.loc['US-UTD'][['ts_3_1_1','ts_3_2_1','ts_3_3_1']].replace(-9999,np.nan)\n",
    "utd_soilt = utd_soilt[utd_soilt.index >= '2024-07-01']#.resample('30T').mean()\n",
    "utd_soilt['ts_3_1_1'].plot()\n",
    "utd_soilt['ts_3_2_1'].shift(-1).plot()\n",
    "utd_soilt['ts_3_3_1'].shift(-5).plot()\n",
    "plt.axvline('2024-07-04 15:00',color='r')\n",
    "#plt.xlim('2024-07-01','2024-07-08')\n",
    "#plt.ylim(10,35)\n",
    "plt.grid(True, which='minor')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "57ae960d",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy.signal import correlate\n",
    "\n",
    "# Function to decompose the seasonal component\n",
    "def extract_seasonal(ts, period):\n",
    "    decomposition = seasonal_decompose(ts, model='additive', period=period)\n",
    "    return decomposition.seasonal\n",
    "\n",
    "# Function to calculate lag between two seasonal series using cross-correlation\n",
    "def calculate_lag(seasonal1, seasonal2):\n",
    "    n = len(seasonal1)\n",
    "    correlation = correlate(seasonal1 - np.mean(seasonal1), seasonal2 - np.mean(seasonal2), mode='full')\n",
    "    lags = np.arange(-n + 1, n)\n",
    "    lag = lags[np.argmax(correlation)]\n",
    "    return lag, correlation, lags\n",
    "\n",
    "ts1 = utd_soilt['ts_3_2_1']\n",
    "ts2 = utd_soilt['ts_3_3_1']\n",
    "#utd_soilt['ts_3_3_1'].shift(-5).plot()\n",
    "\n",
    "\n",
    "# Extract seasonal components\n",
    "seasonal1 = extract_seasonal(ts1, period=48)\n",
    "seasonal2 = extract_seasonal(ts2, period=48)\n",
    "\n",
    "# Calculate lag\n",
    "lag, correlation, lags = calculate_lag(seasonal1.dropna(), seasonal2.dropna())\n",
    "\n",
    "# Output\n",
    "print(f\"Calculated lag: {lag/2} hours\")\n",
    "\n",
    "# Plot seasonal components and correlation\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 8))\n",
    "\n",
    "seasonal1.plot(ax=ax[0], label='Seasonal Component 1')\n",
    "seasonal2.plot(ax=ax[0], label='Seasonal Component 2')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Seasonal Components')\n",
    "ax[0].set_xlim(pd.to_datetime('2024-07-01'),pd.to_datetime('2024-07-08'))\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(lags, correlation)\n",
    "ax[1].set_title('Cross-Correlation')\n",
    "ax[1].set_xlabel('Lag (hours)')\n",
    "ax[1].set_ylabel('Correlation')\n",
    "ax[1].set_xlim(-10, 10)\n",
    "ax[1].grid(True)\n",
    "\n",
    "ax[2].plot(seasonal1.index, seasonal1, label='Series 1')\n",
    "ax[2].plot(seasonal2.index + pd.Timedelta(hours=lag/2), seasonal2, label='Series 2 (Shifted)')\n",
    "ax[2].legend()\n",
    "ax[2].set_title(f'Series alignment (Lag: {lag/2} hours)')\n",
    "ax[2].set_xlim(pd.to_datetime('2024-07-01'),pd.to_datetime('2024-07-08'))\n",
    "ax[2].grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a04ee994",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4fc536c3",
   "metadata": {},
   "source": [
    "cdf = pd.read_parquet('../../station_data/all_eddy_data.parquet')\n",
    "ddf = pd.read_parquet('../../station_data/all_met_data.parquet')\n",
    "\n",
    "for col in cdf.columns:\n",
    "    if col in ddf.columns:\n",
    "        print(col)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0436b2a8",
   "metadata": {},
   "source": [
    "ddf.head(10).to_clipboard()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "549094d0",
   "metadata": {},
   "source": [
    "series = ddf.loc['US-UTD','t_si111_body'].replace(-9999,np.nan)\n",
    "series.plot()\n",
    "series.diff().plot()\n",
    "new_series = series[series.diff()<2].diff().cumsum()\n",
    "new_series.plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fddcebdfd6a7b51c",
   "metadata": {},
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.read('../../secrets/config.ini')\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "host = config['DEFAULT']['ip']\n",
    "pw = config['DEFAULT']['pw']\n",
    "user = config['DEFAULT']['login']\n",
    "\n",
    "encoded_password = urllib.parse.quote_plus(pw)\n",
    "\n",
    "def postconn_et(encoded_password, host='localhost',user='postgres',port='5432',db='groundwater', schema = 'groundwater'):\n",
    "    connection_text = \"postgresql+psycopg2://{:}:{:}@{:}:{:}/{:}?gssencmode=disable\".format(user,encoded_password,host,port,db)\n",
    "    return create_engine(connection_text, connect_args={'options': '-csearch_path={}'.format(schema)})\n",
    "\n",
    "\n",
    "engine = postconn_et(encoded_password, host=host, user=user)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "714ce788442a9680",
   "metadata": {},
   "source": [
    "cdf.to_sql(name = 'amfluxeddy',\n",
    "           schema='groundwater',\n",
    "           con=engine,\n",
    "           if_exists='replace',\n",
    "           chunksize=2000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f92cb2c",
   "metadata": {},
   "source": [
    "for col in soildfs.columns:\n",
    "    print(f\"amfluxmet.{col},\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c5819ddd94230e54",
   "metadata": {},
   "source": [
    "soildfs.to_sql(name = 'amfluxmet',\n",
    "           schema='groundwater',\n",
    "           con=engine,\n",
    "           if_exists='replace',\n",
    "           chunksize=2000)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
