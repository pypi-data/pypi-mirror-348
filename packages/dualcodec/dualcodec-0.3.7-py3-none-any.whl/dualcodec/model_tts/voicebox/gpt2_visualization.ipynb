{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2 Key-Value Cache Visualization\n",
    "\n",
    "This notebook visualizes how key-value caches work in GPT2-style transformer models across all layers and attention heads. We'll examine:\n",
    "1. The structure of KV caches\n",
    "2. How they're updated during generation\n",
    "3. Attention patterns with cached keys and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# For visualization\n",
    "def plot_all_attention_patterns(key_states, value_states, attention_weights, tokens, title=\"Attention Patterns\"):\n",
    "    num_layers = len(key_states)\n",
    "    num_heads = key_states[0].shape[1]\n",
    "    \n",
    "    # Create a large figure for all layers and heads\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    plt.suptitle(title, fontsize=16, y=0.95)\n",
    "    \n",
    "    # Add text showing input tokens\n",
    "    plt.figtext(0.02, 0.98, f'Input text: {tokens}', fontsize=12, wrap=True)\n",
    "    \n",
    "    # Plot matrix for each layer and head\n",
    "    num_layers = 5\n",
    "    num_heads = 6\n",
    "    for layer in range(num_layers):\n",
    "        for head in range(num_heads):\n",
    "            # Calculate subplot position\n",
    "            plt.subplot(num_layers, num_heads, layer * num_heads + head + 1)\n",
    "            \n",
    "            # Plot attention weights with token labels\n",
    "            sns.heatmap(\n",
    "                attention_weights[layer][0, head].detach().cpu().numpy(),\n",
    "                xticklabels=tokens,\n",
    "                yticklabels=tokens,\n",
    "                cmap='viridis',\n",
    "                square=True,\n",
    "                cbar=False,\n",
    "            )\n",
    "            \n",
    "            if head == 0:\n",
    "                plt.ylabel(f'Layer {layer}')\n",
    "            if layer == 0:\n",
    "                plt.title(f'Head {head}')\n",
    "            \n",
    "            # Rotate labels for better readability\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.yticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    plt.show()\n",
    "\n",
    "def plot_kv_cache_details(key_states, value_states, tokens, layer=0, head=0):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Key States\n",
    "    plt.subplot(131)\n",
    "    sns.heatmap(\n",
    "        key_states[layer][0, head].detach().cpu().numpy(),\n",
    "        xticklabels=range(key_states[layer].shape[-1]),\n",
    "        yticklabels=tokens,\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    plt.title(f'Key States (Layer {layer}, Head {head})')\n",
    "    plt.xlabel('Embedding Dimension')\n",
    "    \n",
    "    # Plot 2: Value States\n",
    "    plt.subplot(132)\n",
    "    sns.heatmap(\n",
    "        value_states[layer][0, head].detach().cpu().numpy(),\n",
    "        xticklabels=range(value_states[layer].shape[-1]),\n",
    "        yticklabels=tokens,\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    plt.title(f'Value States (Layer {layer}, Head {head})')\n",
    "    plt.xlabel('Embedding Dimension')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Extract KV cache from model\n",
    "@torch.no_grad()\n",
    "def extract_kv_cache(model, input_ids):\n",
    "    # Get model outputs with attention\n",
    "    outputs = model(input_ids, output_attentions=True, use_cache=True)\n",
    "    \n",
    "    # Extract all layers' cache\n",
    "    all_key_states = []\n",
    "    all_value_states = []\n",
    "    for layer_cache in outputs.past_key_values:\n",
    "        all_key_states.append(layer_cache[0])  # Shape: [batch, num_heads, seq_len, head_dim]\n",
    "        all_value_states.append(layer_cache[1])\n",
    "    \n",
    "    return all_key_states, all_value_states, outputs.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 8, 64])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model.generate(input_ids.to(device), do_sample=True, max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: can fish fly?\\nAssistant answer: fish.\\nAssistant answer: I mean that's a big deal.\\nAssistant answer: OK.\\nAssistant answer: So now, what are you going to do if you get caught?\\nAssistant answer: The only option is to go to Fish, and fish can fly.\\nAssistant answer: Okay.\\nAssistant answer: Ok. So you've been caught. So you have a chance, I mean, one of their chances is to catch an enormous fish.\\nAssistant answer: Ok.\\nAssistant answer: It's not a chance unless you have an experience.\\nAssistant answer: And what?\\nAssistant answer: You know, I have three fish. You can fish just about one or two fish a year, or you can catch multiple fish at once.\\nAssistant answer: OK.\\nAssistant answer: So this is, um, there was one great fish, one of them was a fish, it was, he ran,\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generated_ids)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Visualization\n",
    "\n",
    "The visualizations above show:\n",
    "1. **Attention Patterns**: How each attention head in each layer attends to different input tokens\n",
    "2. **Key-Value Cache Details**: Detailed view of how tokens are encoded in the key and value states\n",
    "\n",
    "During generation, the model:\n",
    "1. Stores computed key-value pairs in cache\n",
    "2. Reuses them for subsequent tokens\n",
    "3. Only computes new KV pairs for new tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare multiple test cases\n",
    "test_prompts = [\n",
    "    \"Article: A car crash occurred on Highway 15 today, involving three cars. Authorities were called to the scene shortly after the crash was reported, and an investigation is underway to determine the cause of the accident. Paramedics arrived on the scene, offering medical assistance to those involved in the crash, and all three individuals were taken to the nearby hospital for further treatment. TL;DR:\",\n",
    "    # \"Who was the author of the art of war?\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input prompt: Article: A car crash occurred on Highway 15 today, involving three cars. Authorities were called to the scene shortly after the crash was reported, and an investigation is underway to determine the cause of the accident. Paramedics arrived on the scene, offering medical assistance to those involved in the crash, and all three individuals were taken to the nearby hospital for further treatment. TL;DR:\n",
      "Generated response: Article: A car crash occurred on Highway 15 today, involving three cars. Authorities were called to the scene shortly after the crash was reported, and an investigation is underway to determine the cause of the accident. Paramedics arrived on the scene, offering medical assistance to those involved in the crash, and all three individuals were taken to the nearby hospital for further treatment. TL;DR: There were no injuries reported. No further information was available today.\n",
      "\n",
      "Update: A car was found lying in the roadway near Haverhill, and the driver of the car was pronounced dead at the scene.\n",
      "\n",
      "Update: A car was found in the roadway near Fayetteville, which is where the crash occurred.\n",
      "\n",
      "Update: A car was found in the roadway near Littleton, and the driver of the car was pronounced dead.\n",
      "\n",
      "Update: Police said that a car was found in the roadway near Greenville, and the driver of the car was pronounced dead at the scene.\n",
      "\n",
      "Update: A car was found in the roadway near Greenville, and the driver of the car was pronounced dead.\n",
      "\n",
      "Update: A car was found in the roadway near Greenville, and the driver of the car was pronounced dead.\n",
      "\n",
      "Update: A car was found in the roadway near Greenville, and the driver of the car was pronounced dead.\n",
      "\n",
      "Update: A car was found in the roadway near Greenville, and the driver of the car was pronounced dead at the scene.\n",
      "\n",
      "Update: A car was found in the roadway near Greenville, and the driver of the car was pronounced dead.\n",
      "\n",
      "Update: A car was found in the roadway near Greenville, and the driver of the car was pronounced dead at the scene.\n",
      "\n",
      "Update: A car was found in the roadway near Greenville, and the driver of the car was pronounced dead at the scene.\n",
      "\n",
      "Update: A car was found in the roadway near Greenville, and the driver of the car was pronounced dead at the scene.\n",
      "\n",
      "Update: A car was found in the roadway near Greenville, and the driver of the car was pronounced dead at the scene.\n",
      "\n",
      "Update: A car was found in the roadway near Greenville, and the driver of the car was pronounced dead at the scene.\n",
      "\n",
      "Update: A car was found in the roadway near Greenville, and the driver of the car was pronounced dead at the scene.\n",
      "\n",
      "Update: A\n"
     ]
    }
   ],
   "source": [
    "# Test each prompt\n",
    "for prompt in test_prompts:\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].cpu())\n",
    "    \n",
    "    # Generate continuation\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=500,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        temperature=0.7,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(\"\\nInput prompt:\", prompt)\n",
    "    print(\"Generated response:\", generated_text)\n",
    "    \n",
    "    # Extract and visualize KV cache\n",
    "    # key_states, value_states, attention = extract_kv_cache(model, input_ids)\n",
    "    # print('encoded')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
